{"cells":[{"cell_type":"markdown","metadata":{"id":"2_vKuZw9OBOd"},"source":["# `Практикум по программированию на языке Python`\n","\n","## `Задание 03. Рекуррентные Нейронные Сети. Dropout. LM`\n","\n","#### Фамилия, имя:\n","\n","Дата выдачи: <span style=\"color:red\">__18 марта 23:59__</span>.\n","\n","Мягкий дедлайн: <span style=\"color:red\">__31 марта 05:00__</span>.\n","\n","Стоимость: __10 баллов__ (основная часть заданий) + __7 баллов__ (дополнительные задания).\n","\n","<span style=\"color:red\">__В ноутбуке все клетки должны выполняться без ошибок при последовательном их выполнении.__</span>\n","\n","#### `Москва, 2025`"]},{"cell_type":"markdown","metadata":{"id":"mQLQaI5tOBOg"},"source":["Данное задание будет состоять из двух частей:\n","1. Применение рекуррентной сети для решения задачи классификации текста. Более конкретно -- предсказания рейтинга отзыва фильма.\n","2. Простейшая лингвистическая модель для генерации текста на основе LSTM."]},{"cell_type":"markdown","metadata":{"id":"QzzCftZbOBOg"},"source":["При выполнении задания вы обучите LSTM с разным уровнем \"коробочности\", а также познакомитесь с различными способами применения DropOut к рекуррентным архитектурам. В рекуррентных архитектурах вариантов, куда можно наложить бинарную маску шума, гораздо больше, чем в нейросетях прямого прохода.\n","\n","Во второй части вы попробуете реализовать простейший рекуррентный декодер для генерации текстов.\n","\n","Задание сделано так, чтобы его можно было выполнять на CPU, однако RNN - это ресурсоёмкая вещь, поэтому на GPU с ними работать приятнее. Можете попробовать использовать [https://colab.research.google.com](https://colab.research.google.com) - бесплатное облако с GPU."]},{"cell_type":"markdown","metadata":{"id":"LIFWL08FOBOg"},"source":["**Для корректного отображения картинок, вам может понадобится сделать ноутбук доверенным (Trusted) в правом верхнем углу**"]},{"cell_type":"markdown","metadata":{"id":"A8QLfnIpOBOh"},"source":["# `Часть 0. Загрузка и предобработка данных (1 балл)`"]},{"cell_type":"markdown","metadata":{"id":"GBjNIfIXOBOh"},"source":["## `Рекомендуемые гиперпараметры`"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BALdKat7OBOh"},"outputs":[],"source":["max_length = 200\n","top_n_words = 5000\n","\n","hidden_dim = 128\n","embedding_dim = 32\n","\n","num_epochs = 15\n","batch_size = 64\n","learning_rate = 1e-3"]},{"cell_type":"markdown","metadata":{"id":"ShINh1U0OBOi"},"source":["Первое, что нужно сделать — скачать, предобработать данные и организовать их таким образом, чтобы их можно было подавать в нейронную сеть.\n","\n","Для обеих частей задания мы будем использовать [**Large Movie Review Dataset**](https://ai.stanford.edu/~amaas/data/sentiment/)."]},{"cell_type":"markdown","metadata":{"id":"ReCZWSCgOBOj"},"source":["## `Загрузка и предобработка данных`"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CK2A3z0sOBOj"},"outputs":[],"source":["import os"]},{"cell_type":"markdown","metadata":{"id":"Xk9UawK2OBOj"},"source":["Загрузите данные по ссылке выше. (**tip**: используйте `wget`)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4414,"status":"ok","timestamp":1744808633633,"user":{"displayName":"ГУЩИН СТАНИСЛАВ АЛЕКСЕЕВИЧ","userId":"03202281510855514510"},"user_tz":-180},"id":"pRrbS7NtOBOj","outputId":"da5c9dde-d110-46ae-8e83-de81e2ca5528"},"outputs":[{"name":"stdout","output_type":"stream","text":["--2025-04-16 13:03:49--  https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n","Resolving ai.stanford.edu (ai.stanford.edu)... 171.64.68.10\n","Connecting to ai.stanford.edu (ai.stanford.edu)|171.64.68.10|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 84125825 (80M) [application/x-gzip]\n","Saving to: ‘aclImdb_v1.tar.gz’\n","\n","aclImdb_v1.tar.gz   100%[===================>]  80.23M  20.5MB/s    in 4.1s    \n","\n","2025-04-16 13:03:53 (19.6 MB/s) - ‘aclImdb_v1.tar.gz’ saved [84125825/84125825]\n","\n"]}],"source":["if not os.path.exists('./aclImdb_v1.tar.gz'):\n","    # YOUR CODE HERE\n","    !wget https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz"]},{"cell_type":"markdown","metadata":{"id":"65YjEvITOBOj"},"source":["Распакуйте скачанные данные в папку `aclImdb` (**tip:** используйте `tar`)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"executionInfo":{"elapsed":15720,"status":"ok","timestamp":1744808649367,"user":{"displayName":"ГУЩИН СТАНИСЛАВ АЛЕКСЕЕВИЧ","userId":"03202281510855514510"},"user_tz":-180},"id":"RcdxwQ2yOBOk","outputId":"126463bd-f136-4910-d22f-a3c1994c01fa"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[1;30;43mВыходные данные были обрезаны до нескольких последних строк (5000).\u001b[0m\n","aclImdb/train/unsup/44983_0.txt\n","aclImdb/train/unsup/44982_0.txt\n","aclImdb/train/unsup/44981_0.txt\n","aclImdb/train/unsup/44980_0.txt\n","aclImdb/train/unsup/44979_0.txt\n","aclImdb/train/unsup/44978_0.txt\n","aclImdb/train/unsup/44977_0.txt\n","aclImdb/train/unsup/44976_0.txt\n","aclImdb/train/unsup/44975_0.txt\n","aclImdb/train/unsup/44974_0.txt\n","aclImdb/train/unsup/44973_0.txt\n","aclImdb/train/unsup/44972_0.txt\n","aclImdb/train/unsup/44971_0.txt\n","aclImdb/train/unsup/44970_0.txt\n","aclImdb/train/unsup/44969_0.txt\n","aclImdb/train/unsup/44968_0.txt\n","aclImdb/train/unsup/44967_0.txt\n","aclImdb/train/unsup/44966_0.txt\n","aclImdb/train/unsup/44965_0.txt\n","aclImdb/train/unsup/44964_0.txt\n","aclImdb/train/unsup/44963_0.txt\n","aclImdb/train/unsup/44962_0.txt\n","aclImdb/train/unsup/44961_0.txt\n","aclImdb/train/unsup/44960_0.txt\n","aclImdb/train/unsup/44959_0.txt\n","aclImdb/train/unsup/44958_0.txt\n","aclImdb/train/unsup/44957_0.txt\n","aclImdb/train/unsup/44956_0.txt\n","aclImdb/train/unsup/44955_0.txt\n","aclImdb/train/unsup/44954_0.txt\n","aclImdb/train/unsup/44953_0.txt\n","aclImdb/train/unsup/44952_0.txt\n","aclImdb/train/unsup/44951_0.txt\n","aclImdb/train/unsup/44950_0.txt\n","aclImdb/train/unsup/44949_0.txt\n","aclImdb/train/unsup/44948_0.txt\n","aclImdb/train/unsup/44947_0.txt\n","aclImdb/train/unsup/44946_0.txt\n","aclImdb/train/unsup/44945_0.txt\n","aclImdb/train/unsup/44944_0.txt\n","aclImdb/train/unsup/44943_0.txt\n","aclImdb/train/unsup/44942_0.txt\n","aclImdb/train/unsup/44941_0.txt\n","aclImdb/train/unsup/44940_0.txt\n","aclImdb/train/unsup/44939_0.txt\n","aclImdb/train/unsup/44938_0.txt\n","aclImdb/train/unsup/44937_0.txt\n","aclImdb/train/unsup/44936_0.txt\n","aclImdb/train/unsup/44935_0.txt\n","aclImdb/train/unsup/44934_0.txt\n","aclImdb/train/unsup/44933_0.txt\n","aclImdb/train/unsup/44932_0.txt\n","aclImdb/train/unsup/44931_0.txt\n","aclImdb/train/unsup/44930_0.txt\n","aclImdb/train/unsup/44929_0.txt\n","aclImdb/train/unsup/44928_0.txt\n","aclImdb/train/unsup/45183_0.txt\n","aclImdb/train/unsup/45182_0.txt\n","aclImdb/train/unsup/45181_0.txt\n","aclImdb/train/unsup/45180_0.txt\n","aclImdb/train/unsup/45179_0.txt\n","aclImdb/train/unsup/45178_0.txt\n","aclImdb/train/unsup/45177_0.txt\n","aclImdb/train/unsup/45176_0.txt\n","aclImdb/train/unsup/45175_0.txt\n","aclImdb/train/unsup/45174_0.txt\n","aclImdb/train/unsup/45173_0.txt\n","aclImdb/train/unsup/45172_0.txt\n","aclImdb/train/unsup/45171_0.txt\n","aclImdb/train/unsup/45170_0.txt\n","aclImdb/train/unsup/45169_0.txt\n","aclImdb/train/unsup/45168_0.txt\n","aclImdb/train/unsup/45167_0.txt\n","aclImdb/train/unsup/45166_0.txt\n","aclImdb/train/unsup/45165_0.txt\n","aclImdb/train/unsup/45164_0.txt\n","aclImdb/train/unsup/45163_0.txt\n","aclImdb/train/unsup/45162_0.txt\n","aclImdb/train/unsup/45161_0.txt\n","aclImdb/train/unsup/45160_0.txt\n","aclImdb/train/unsup/45159_0.txt\n","aclImdb/train/unsup/45158_0.txt\n","aclImdb/train/unsup/45157_0.txt\n","aclImdb/train/unsup/45156_0.txt\n","aclImdb/train/unsup/45155_0.txt\n","aclImdb/train/unsup/45154_0.txt\n","aclImdb/train/unsup/45153_0.txt\n","aclImdb/train/unsup/45152_0.txt\n","aclImdb/train/unsup/45151_0.txt\n","aclImdb/train/unsup/45150_0.txt\n","aclImdb/train/unsup/45149_0.txt\n","aclImdb/train/unsup/45148_0.txt\n","aclImdb/train/unsup/45147_0.txt\n","aclImdb/train/unsup/45146_0.txt\n","aclImdb/train/unsup/45145_0.txt\n","aclImdb/train/unsup/45144_0.txt\n","aclImdb/train/unsup/45143_0.txt\n","aclImdb/train/unsup/45142_0.txt\n","aclImdb/train/unsup/45141_0.txt\n","aclImdb/train/unsup/45140_0.txt\n","aclImdb/train/unsup/45139_0.txt\n","aclImdb/train/unsup/45138_0.txt\n","aclImdb/train/unsup/45137_0.txt\n","aclImdb/train/unsup/45136_0.txt\n","aclImdb/train/unsup/45135_0.txt\n","aclImdb/train/unsup/45134_0.txt\n","aclImdb/train/unsup/45133_0.txt\n","aclImdb/train/unsup/45132_0.txt\n","aclImdb/train/unsup/45131_0.txt\n","aclImdb/train/unsup/45130_0.txt\n","aclImdb/train/unsup/45129_0.txt\n","aclImdb/train/unsup/45128_0.txt\n","aclImdb/train/unsup/45127_0.txt\n","aclImdb/train/unsup/45126_0.txt\n","aclImdb/train/unsup/45125_0.txt\n","aclImdb/train/unsup/45124_0.txt\n","aclImdb/train/unsup/45123_0.txt\n","aclImdb/train/unsup/45122_0.txt\n","aclImdb/train/unsup/45121_0.txt\n","aclImdb/train/unsup/45120_0.txt\n","aclImdb/train/unsup/45119_0.txt\n","aclImdb/train/unsup/45118_0.txt\n","aclImdb/train/unsup/45117_0.txt\n","aclImdb/train/unsup/45116_0.txt\n","aclImdb/train/unsup/45115_0.txt\n","aclImdb/train/unsup/45114_0.txt\n","aclImdb/train/unsup/45113_0.txt\n","aclImdb/train/unsup/45112_0.txt\n","aclImdb/train/unsup/45111_0.txt\n","aclImdb/train/unsup/45110_0.txt\n","aclImdb/train/unsup/45109_0.txt\n","aclImdb/train/unsup/45108_0.txt\n","aclImdb/train/unsup/45107_0.txt\n","aclImdb/train/unsup/45106_0.txt\n","aclImdb/train/unsup/45105_0.txt\n","aclImdb/train/unsup/45104_0.txt\n","aclImdb/train/unsup/45103_0.txt\n","aclImdb/train/unsup/45102_0.txt\n","aclImdb/train/unsup/45101_0.txt\n","aclImdb/train/unsup/45100_0.txt\n","aclImdb/train/unsup/45099_0.txt\n","aclImdb/train/unsup/45098_0.txt\n","aclImdb/train/unsup/45097_0.txt\n","aclImdb/train/unsup/45096_0.txt\n","aclImdb/train/unsup/45095_0.txt\n","aclImdb/train/unsup/45094_0.txt\n","aclImdb/train/unsup/45093_0.txt\n","aclImdb/train/unsup/45092_0.txt\n","aclImdb/train/unsup/45091_0.txt\n","aclImdb/train/unsup/45090_0.txt\n","aclImdb/train/unsup/45089_0.txt\n","aclImdb/train/unsup/45088_0.txt\n","aclImdb/train/unsup/45087_0.txt\n","aclImdb/train/unsup/45086_0.txt\n","aclImdb/train/unsup/45085_0.txt\n","aclImdb/train/unsup/45084_0.txt\n","aclImdb/train/unsup/45083_0.txt\n","aclImdb/train/unsup/45082_0.txt\n","aclImdb/train/unsup/45081_0.txt\n","aclImdb/train/unsup/45080_0.txt\n","aclImdb/train/unsup/45079_0.txt\n","aclImdb/train/unsup/45078_0.txt\n","aclImdb/train/unsup/45077_0.txt\n","aclImdb/train/unsup/45076_0.txt\n","aclImdb/train/unsup/45075_0.txt\n","aclImdb/train/unsup/45074_0.txt\n","aclImdb/train/unsup/45073_0.txt\n","aclImdb/train/unsup/45072_0.txt\n","aclImdb/train/unsup/45071_0.txt\n","aclImdb/train/unsup/45070_0.txt\n","aclImdb/train/unsup/45069_0.txt\n","aclImdb/train/unsup/45068_0.txt\n","aclImdb/train/unsup/45067_0.txt\n","aclImdb/train/unsup/45066_0.txt\n","aclImdb/train/unsup/45065_0.txt\n","aclImdb/train/unsup/45064_0.txt\n","aclImdb/train/unsup/45063_0.txt\n","aclImdb/train/unsup/45062_0.txt\n","aclImdb/train/unsup/45061_0.txt\n","aclImdb/train/unsup/45060_0.txt\n","aclImdb/train/unsup/45059_0.txt\n","aclImdb/train/unsup/45058_0.txt\n","aclImdb/train/unsup/45057_0.txt\n","aclImdb/train/unsup/45056_0.txt\n","aclImdb/train/unsup/45311_0.txt\n","aclImdb/train/unsup/45310_0.txt\n","aclImdb/train/unsup/45309_0.txt\n","aclImdb/train/unsup/45308_0.txt\n","aclImdb/train/unsup/45307_0.txt\n","aclImdb/train/unsup/45306_0.txt\n","aclImdb/train/unsup/45305_0.txt\n","aclImdb/train/unsup/45304_0.txt\n","aclImdb/train/unsup/45303_0.txt\n","aclImdb/train/unsup/45302_0.txt\n","aclImdb/train/unsup/45301_0.txt\n","aclImdb/train/unsup/45300_0.txt\n","aclImdb/train/unsup/45299_0.txt\n","aclImdb/train/unsup/45298_0.txt\n","aclImdb/train/unsup/45297_0.txt\n","aclImdb/train/unsup/45296_0.txt\n","aclImdb/train/unsup/45295_0.txt\n","aclImdb/train/unsup/45294_0.txt\n","aclImdb/train/unsup/45293_0.txt\n","aclImdb/train/unsup/45292_0.txt\n","aclImdb/train/unsup/45291_0.txt\n","aclImdb/train/unsup/45290_0.txt\n","aclImdb/train/unsup/45289_0.txt\n","aclImdb/train/unsup/45288_0.txt\n","aclImdb/train/unsup/45287_0.txt\n","aclImdb/train/unsup/45286_0.txt\n","aclImdb/train/unsup/45285_0.txt\n","aclImdb/train/unsup/45284_0.txt\n","aclImdb/train/unsup/45283_0.txt\n","aclImdb/train/unsup/45282_0.txt\n","aclImdb/train/unsup/45281_0.txt\n","aclImdb/train/unsup/45280_0.txt\n","aclImdb/train/unsup/45279_0.txt\n","aclImdb/train/unsup/45278_0.txt\n","aclImdb/train/unsup/45277_0.txt\n","aclImdb/train/unsup/45276_0.txt\n","aclImdb/train/unsup/45275_0.txt\n","aclImdb/train/unsup/45274_0.txt\n","aclImdb/train/unsup/45273_0.txt\n","aclImdb/train/unsup/45272_0.txt\n","aclImdb/train/unsup/45271_0.txt\n","aclImdb/train/unsup/45270_0.txt\n","aclImdb/train/unsup/45269_0.txt\n","aclImdb/train/unsup/45268_0.txt\n","aclImdb/train/unsup/45267_0.txt\n","aclImdb/train/unsup/45266_0.txt\n","aclImdb/train/unsup/45265_0.txt\n","aclImdb/train/unsup/45264_0.txt\n","aclImdb/train/unsup/45263_0.txt\n","aclImdb/train/unsup/45262_0.txt\n","aclImdb/train/unsup/45261_0.txt\n","aclImdb/train/unsup/45260_0.txt\n","aclImdb/train/unsup/45259_0.txt\n","aclImdb/train/unsup/45258_0.txt\n","aclImdb/train/unsup/45257_0.txt\n","aclImdb/train/unsup/45256_0.txt\n","aclImdb/train/unsup/45255_0.txt\n","aclImdb/train/unsup/45254_0.txt\n","aclImdb/train/unsup/45253_0.txt\n","aclImdb/train/unsup/45252_0.txt\n","aclImdb/train/unsup/45251_0.txt\n","aclImdb/train/unsup/45250_0.txt\n","aclImdb/train/unsup/45249_0.txt\n","aclImdb/train/unsup/45248_0.txt\n","aclImdb/train/unsup/45247_0.txt\n","aclImdb/train/unsup/45246_0.txt\n","aclImdb/train/unsup/45245_0.txt\n","aclImdb/train/unsup/45244_0.txt\n","aclImdb/train/unsup/45243_0.txt\n","aclImdb/train/unsup/45242_0.txt\n","aclImdb/train/unsup/45241_0.txt\n","aclImdb/train/unsup/45240_0.txt\n","aclImdb/train/unsup/45239_0.txt\n","aclImdb/train/unsup/45238_0.txt\n","aclImdb/train/unsup/45237_0.txt\n","aclImdb/train/unsup/45236_0.txt\n","aclImdb/train/unsup/45235_0.txt\n","aclImdb/train/unsup/45234_0.txt\n","aclImdb/train/unsup/45233_0.txt\n","aclImdb/train/unsup/45232_0.txt\n","aclImdb/train/unsup/45231_0.txt\n","aclImdb/train/unsup/45230_0.txt\n","aclImdb/train/unsup/45229_0.txt\n","aclImdb/train/unsup/45228_0.txt\n","aclImdb/train/unsup/45227_0.txt\n","aclImdb/train/unsup/45226_0.txt\n","aclImdb/train/unsup/45225_0.txt\n","aclImdb/train/unsup/45224_0.txt\n","aclImdb/train/unsup/45223_0.txt\n","aclImdb/train/unsup/45222_0.txt\n","aclImdb/train/unsup/45221_0.txt\n","aclImdb/train/unsup/45220_0.txt\n","aclImdb/train/unsup/45219_0.txt\n","aclImdb/train/unsup/45218_0.txt\n","aclImdb/train/unsup/45217_0.txt\n","aclImdb/train/unsup/45216_0.txt\n","aclImdb/train/unsup/45215_0.txt\n","aclImdb/train/unsup/45214_0.txt\n","aclImdb/train/unsup/45213_0.txt\n","aclImdb/train/unsup/45212_0.txt\n","aclImdb/train/unsup/45211_0.txt\n","aclImdb/train/unsup/45210_0.txt\n","aclImdb/train/unsup/45209_0.txt\n","aclImdb/train/unsup/45208_0.txt\n","aclImdb/train/unsup/45207_0.txt\n","aclImdb/train/unsup/45206_0.txt\n","aclImdb/train/unsup/45205_0.txt\n","aclImdb/train/unsup/45204_0.txt\n","aclImdb/train/unsup/45203_0.txt\n","aclImdb/train/unsup/45202_0.txt\n","aclImdb/train/unsup/45201_0.txt\n","aclImdb/train/unsup/45200_0.txt\n","aclImdb/train/unsup/45199_0.txt\n","aclImdb/train/unsup/45198_0.txt\n","aclImdb/train/unsup/45197_0.txt\n","aclImdb/train/unsup/45196_0.txt\n","aclImdb/train/unsup/45195_0.txt\n","aclImdb/train/unsup/45194_0.txt\n","aclImdb/train/unsup/45193_0.txt\n","aclImdb/train/unsup/45192_0.txt\n","aclImdb/train/unsup/45191_0.txt\n","aclImdb/train/unsup/45190_0.txt\n","aclImdb/train/unsup/45189_0.txt\n","aclImdb/train/unsup/45188_0.txt\n","aclImdb/train/unsup/45187_0.txt\n","aclImdb/train/unsup/45186_0.txt\n","aclImdb/train/unsup/45185_0.txt\n","aclImdb/train/unsup/45184_0.txt\n","aclImdb/train/unsup/45439_0.txt\n","aclImdb/train/unsup/45438_0.txt\n","aclImdb/train/unsup/45437_0.txt\n","aclImdb/train/unsup/45436_0.txt\n","aclImdb/train/unsup/45435_0.txt\n","aclImdb/train/unsup/45434_0.txt\n","aclImdb/train/unsup/45433_0.txt\n","aclImdb/train/unsup/45432_0.txt\n","aclImdb/train/unsup/45431_0.txt\n","aclImdb/train/unsup/45430_0.txt\n","aclImdb/train/unsup/45429_0.txt\n","aclImdb/train/unsup/45428_0.txt\n","aclImdb/train/unsup/45427_0.txt\n","aclImdb/train/unsup/45426_0.txt\n","aclImdb/train/unsup/45425_0.txt\n","aclImdb/train/unsup/45424_0.txt\n","aclImdb/train/unsup/45423_0.txt\n","aclImdb/train/unsup/45422_0.txt\n","aclImdb/train/unsup/45421_0.txt\n","aclImdb/train/unsup/45420_0.txt\n","aclImdb/train/unsup/45419_0.txt\n","aclImdb/train/unsup/45418_0.txt\n","aclImdb/train/unsup/45417_0.txt\n","aclImdb/train/unsup/45416_0.txt\n","aclImdb/train/unsup/45415_0.txt\n","aclImdb/train/unsup/45414_0.txt\n","aclImdb/train/unsup/45413_0.txt\n","aclImdb/train/unsup/45412_0.txt\n","aclImdb/train/unsup/45411_0.txt\n","aclImdb/train/unsup/45410_0.txt\n","aclImdb/train/unsup/45409_0.txt\n","aclImdb/train/unsup/45408_0.txt\n","aclImdb/train/unsup/45407_0.txt\n","aclImdb/train/unsup/45406_0.txt\n","aclImdb/train/unsup/45405_0.txt\n","aclImdb/train/unsup/45404_0.txt\n","aclImdb/train/unsup/45403_0.txt\n","aclImdb/train/unsup/45402_0.txt\n","aclImdb/train/unsup/45401_0.txt\n","aclImdb/train/unsup/45400_0.txt\n","aclImdb/train/unsup/45399_0.txt\n","aclImdb/train/unsup/45398_0.txt\n","aclImdb/train/unsup/45397_0.txt\n","aclImdb/train/unsup/45396_0.txt\n","aclImdb/train/unsup/45395_0.txt\n","aclImdb/train/unsup/45394_0.txt\n","aclImdb/train/unsup/45393_0.txt\n","aclImdb/train/unsup/45392_0.txt\n","aclImdb/train/unsup/45391_0.txt\n","aclImdb/train/unsup/45390_0.txt\n","aclImdb/train/unsup/45389_0.txt\n","aclImdb/train/unsup/45388_0.txt\n","aclImdb/train/unsup/45387_0.txt\n","aclImdb/train/unsup/45386_0.txt\n","aclImdb/train/unsup/45385_0.txt\n","aclImdb/train/unsup/45384_0.txt\n","aclImdb/train/unsup/45383_0.txt\n","aclImdb/train/unsup/45382_0.txt\n","aclImdb/train/unsup/45381_0.txt\n","aclImdb/train/unsup/45380_0.txt\n","aclImdb/train/unsup/45379_0.txt\n","aclImdb/train/unsup/45378_0.txt\n","aclImdb/train/unsup/45377_0.txt\n","aclImdb/train/unsup/45376_0.txt\n","aclImdb/train/unsup/45375_0.txt\n","aclImdb/train/unsup/45374_0.txt\n","aclImdb/train/unsup/45373_0.txt\n","aclImdb/train/unsup/45372_0.txt\n","aclImdb/train/unsup/45371_0.txt\n","aclImdb/train/unsup/45370_0.txt\n","aclImdb/train/unsup/45369_0.txt\n","aclImdb/train/unsup/45368_0.txt\n","aclImdb/train/unsup/45367_0.txt\n","aclImdb/train/unsup/45366_0.txt\n","aclImdb/train/unsup/45365_0.txt\n","aclImdb/train/unsup/45364_0.txt\n","aclImdb/train/unsup/45363_0.txt\n","aclImdb/train/unsup/45362_0.txt\n","aclImdb/train/unsup/45361_0.txt\n","aclImdb/train/unsup/45360_0.txt\n","aclImdb/train/unsup/45359_0.txt\n","aclImdb/train/unsup/45358_0.txt\n","aclImdb/train/unsup/45357_0.txt\n","aclImdb/train/unsup/45356_0.txt\n","aclImdb/train/unsup/45355_0.txt\n","aclImdb/train/unsup/45354_0.txt\n","aclImdb/train/unsup/45353_0.txt\n","aclImdb/train/unsup/45352_0.txt\n","aclImdb/train/unsup/45351_0.txt\n","aclImdb/train/unsup/45350_0.txt\n","aclImdb/train/unsup/45349_0.txt\n","aclImdb/train/unsup/45348_0.txt\n","aclImdb/train/unsup/45347_0.txt\n","aclImdb/train/unsup/45346_0.txt\n","aclImdb/train/unsup/45345_0.txt\n","aclImdb/train/unsup/45344_0.txt\n","aclImdb/train/unsup/45343_0.txt\n","aclImdb/train/unsup/45342_0.txt\n","aclImdb/train/unsup/45341_0.txt\n","aclImdb/train/unsup/45340_0.txt\n","aclImdb/train/unsup/45339_0.txt\n","aclImdb/train/unsup/45338_0.txt\n","aclImdb/train/unsup/45337_0.txt\n","aclImdb/train/unsup/45336_0.txt\n","aclImdb/train/unsup/45335_0.txt\n","aclImdb/train/unsup/45334_0.txt\n","aclImdb/train/unsup/45333_0.txt\n","aclImdb/train/unsup/45332_0.txt\n","aclImdb/train/unsup/45331_0.txt\n","aclImdb/train/unsup/45330_0.txt\n","aclImdb/train/unsup/45329_0.txt\n","aclImdb/train/unsup/45328_0.txt\n","aclImdb/train/unsup/45327_0.txt\n","aclImdb/train/unsup/45326_0.txt\n","aclImdb/train/unsup/45325_0.txt\n","aclImdb/train/unsup/45324_0.txt\n","aclImdb/train/unsup/45323_0.txt\n","aclImdb/train/unsup/45322_0.txt\n","aclImdb/train/unsup/45321_0.txt\n","aclImdb/train/unsup/45320_0.txt\n","aclImdb/train/unsup/45319_0.txt\n","aclImdb/train/unsup/45318_0.txt\n","aclImdb/train/unsup/45317_0.txt\n","aclImdb/train/unsup/45316_0.txt\n","aclImdb/train/unsup/45315_0.txt\n","aclImdb/train/unsup/45314_0.txt\n","aclImdb/train/unsup/45313_0.txt\n","aclImdb/train/unsup/45312_0.txt\n","aclImdb/train/unsup/45567_0.txt\n","aclImdb/train/unsup/45566_0.txt\n","aclImdb/train/unsup/45565_0.txt\n","aclImdb/train/unsup/45564_0.txt\n","aclImdb/train/unsup/45563_0.txt\n","aclImdb/train/unsup/45562_0.txt\n","aclImdb/train/unsup/45561_0.txt\n","aclImdb/train/unsup/45560_0.txt\n","aclImdb/train/unsup/45559_0.txt\n","aclImdb/train/unsup/45558_0.txt\n","aclImdb/train/unsup/45557_0.txt\n","aclImdb/train/unsup/45556_0.txt\n","aclImdb/train/unsup/45555_0.txt\n","aclImdb/train/unsup/45554_0.txt\n","aclImdb/train/unsup/45553_0.txt\n","aclImdb/train/unsup/45552_0.txt\n","aclImdb/train/unsup/45551_0.txt\n","aclImdb/train/unsup/45550_0.txt\n","aclImdb/train/unsup/45549_0.txt\n","aclImdb/train/unsup/45548_0.txt\n","aclImdb/train/unsup/45547_0.txt\n","aclImdb/train/unsup/45546_0.txt\n","aclImdb/train/unsup/45545_0.txt\n","aclImdb/train/unsup/45544_0.txt\n","aclImdb/train/unsup/45543_0.txt\n","aclImdb/train/unsup/45542_0.txt\n","aclImdb/train/unsup/45541_0.txt\n","aclImdb/train/unsup/45540_0.txt\n","aclImdb/train/unsup/45539_0.txt\n","aclImdb/train/unsup/45538_0.txt\n","aclImdb/train/unsup/45537_0.txt\n","aclImdb/train/unsup/45536_0.txt\n","aclImdb/train/unsup/45535_0.txt\n","aclImdb/train/unsup/45534_0.txt\n","aclImdb/train/unsup/45533_0.txt\n","aclImdb/train/unsup/45532_0.txt\n","aclImdb/train/unsup/45531_0.txt\n","aclImdb/train/unsup/45530_0.txt\n","aclImdb/train/unsup/45529_0.txt\n","aclImdb/train/unsup/45528_0.txt\n","aclImdb/train/unsup/45527_0.txt\n","aclImdb/train/unsup/45526_0.txt\n","aclImdb/train/unsup/45525_0.txt\n","aclImdb/train/unsup/45524_0.txt\n","aclImdb/train/unsup/45523_0.txt\n","aclImdb/train/unsup/45522_0.txt\n","aclImdb/train/unsup/45521_0.txt\n","aclImdb/train/unsup/45520_0.txt\n","aclImdb/train/unsup/45519_0.txt\n","aclImdb/train/unsup/45518_0.txt\n","aclImdb/train/unsup/45517_0.txt\n","aclImdb/train/unsup/45516_0.txt\n","aclImdb/train/unsup/45515_0.txt\n","aclImdb/train/unsup/45514_0.txt\n","aclImdb/train/unsup/45513_0.txt\n","aclImdb/train/unsup/45512_0.txt\n","aclImdb/train/unsup/45511_0.txt\n","aclImdb/train/unsup/45510_0.txt\n","aclImdb/train/unsup/45509_0.txt\n","aclImdb/train/unsup/45508_0.txt\n","aclImdb/train/unsup/45507_0.txt\n","aclImdb/train/unsup/45506_0.txt\n","aclImdb/train/unsup/45505_0.txt\n","aclImdb/train/unsup/45504_0.txt\n","aclImdb/train/unsup/45503_0.txt\n","aclImdb/train/unsup/45502_0.txt\n","aclImdb/train/unsup/45501_0.txt\n","aclImdb/train/unsup/45500_0.txt\n","aclImdb/train/unsup/45499_0.txt\n","aclImdb/train/unsup/45498_0.txt\n","aclImdb/train/unsup/45497_0.txt\n","aclImdb/train/unsup/45496_0.txt\n","aclImdb/train/unsup/45495_0.txt\n","aclImdb/train/unsup/45494_0.txt\n","aclImdb/train/unsup/45493_0.txt\n","aclImdb/train/unsup/45492_0.txt\n","aclImdb/train/unsup/45491_0.txt\n","aclImdb/train/unsup/45490_0.txt\n","aclImdb/train/unsup/45489_0.txt\n","aclImdb/train/unsup/45488_0.txt\n","aclImdb/train/unsup/45487_0.txt\n","aclImdb/train/unsup/45486_0.txt\n","aclImdb/train/unsup/45485_0.txt\n","aclImdb/train/unsup/45484_0.txt\n","aclImdb/train/unsup/45483_0.txt\n","aclImdb/train/unsup/45482_0.txt\n","aclImdb/train/unsup/45481_0.txt\n","aclImdb/train/unsup/45480_0.txt\n","aclImdb/train/unsup/45479_0.txt\n","aclImdb/train/unsup/45478_0.txt\n","aclImdb/train/unsup/45477_0.txt\n","aclImdb/train/unsup/45476_0.txt\n","aclImdb/train/unsup/45475_0.txt\n","aclImdb/train/unsup/45474_0.txt\n","aclImdb/train/unsup/45473_0.txt\n","aclImdb/train/unsup/45472_0.txt\n","aclImdb/train/unsup/45471_0.txt\n","aclImdb/train/unsup/45470_0.txt\n","aclImdb/train/unsup/45469_0.txt\n","aclImdb/train/unsup/45468_0.txt\n","aclImdb/train/unsup/45467_0.txt\n","aclImdb/train/unsup/45466_0.txt\n","aclImdb/train/unsup/45465_0.txt\n","aclImdb/train/unsup/45464_0.txt\n","aclImdb/train/unsup/45463_0.txt\n","aclImdb/train/unsup/45462_0.txt\n","aclImdb/train/unsup/45461_0.txt\n","aclImdb/train/unsup/45460_0.txt\n","aclImdb/train/unsup/45459_0.txt\n","aclImdb/train/unsup/45458_0.txt\n","aclImdb/train/unsup/45457_0.txt\n","aclImdb/train/unsup/45456_0.txt\n","aclImdb/train/unsup/45455_0.txt\n","aclImdb/train/unsup/45454_0.txt\n","aclImdb/train/unsup/45453_0.txt\n","aclImdb/train/unsup/45452_0.txt\n","aclImdb/train/unsup/45451_0.txt\n","aclImdb/train/unsup/45450_0.txt\n","aclImdb/train/unsup/45449_0.txt\n","aclImdb/train/unsup/45448_0.txt\n","aclImdb/train/unsup/45447_0.txt\n","aclImdb/train/unsup/45446_0.txt\n","aclImdb/train/unsup/45445_0.txt\n","aclImdb/train/unsup/45444_0.txt\n","aclImdb/train/unsup/45443_0.txt\n","aclImdb/train/unsup/45442_0.txt\n","aclImdb/train/unsup/45441_0.txt\n","aclImdb/train/unsup/45440_0.txt\n","aclImdb/train/unsup/45695_0.txt\n","aclImdb/train/unsup/45694_0.txt\n","aclImdb/train/unsup/45693_0.txt\n","aclImdb/train/unsup/45692_0.txt\n","aclImdb/train/unsup/45691_0.txt\n","aclImdb/train/unsup/45690_0.txt\n","aclImdb/train/unsup/45689_0.txt\n","aclImdb/train/unsup/45688_0.txt\n","aclImdb/train/unsup/45687_0.txt\n","aclImdb/train/unsup/45686_0.txt\n","aclImdb/train/unsup/45685_0.txt\n","aclImdb/train/unsup/45684_0.txt\n","aclImdb/train/unsup/45683_0.txt\n","aclImdb/train/unsup/45682_0.txt\n","aclImdb/train/unsup/45681_0.txt\n","aclImdb/train/unsup/45680_0.txt\n","aclImdb/train/unsup/45679_0.txt\n","aclImdb/train/unsup/45678_0.txt\n","aclImdb/train/unsup/45677_0.txt\n","aclImdb/train/unsup/45676_0.txt\n","aclImdb/train/unsup/45675_0.txt\n","aclImdb/train/unsup/45674_0.txt\n","aclImdb/train/unsup/45673_0.txt\n","aclImdb/train/unsup/45672_0.txt\n","aclImdb/train/unsup/45671_0.txt\n","aclImdb/train/unsup/45670_0.txt\n","aclImdb/train/unsup/45669_0.txt\n","aclImdb/train/unsup/45668_0.txt\n","aclImdb/train/unsup/45667_0.txt\n","aclImdb/train/unsup/45666_0.txt\n","aclImdb/train/unsup/45665_0.txt\n","aclImdb/train/unsup/45664_0.txt\n","aclImdb/train/unsup/45663_0.txt\n","aclImdb/train/unsup/45662_0.txt\n","aclImdb/train/unsup/45661_0.txt\n","aclImdb/train/unsup/45660_0.txt\n","aclImdb/train/unsup/45659_0.txt\n","aclImdb/train/unsup/45658_0.txt\n","aclImdb/train/unsup/45657_0.txt\n","aclImdb/train/unsup/45656_0.txt\n","aclImdb/train/unsup/45655_0.txt\n","aclImdb/train/unsup/45654_0.txt\n","aclImdb/train/unsup/45653_0.txt\n","aclImdb/train/unsup/45652_0.txt\n","aclImdb/train/unsup/45651_0.txt\n","aclImdb/train/unsup/45650_0.txt\n","aclImdb/train/unsup/45649_0.txt\n","aclImdb/train/unsup/45648_0.txt\n","aclImdb/train/unsup/45647_0.txt\n","aclImdb/train/unsup/45646_0.txt\n","aclImdb/train/unsup/45645_0.txt\n","aclImdb/train/unsup/45644_0.txt\n","aclImdb/train/unsup/45643_0.txt\n","aclImdb/train/unsup/45642_0.txt\n","aclImdb/train/unsup/45641_0.txt\n","aclImdb/train/unsup/45640_0.txt\n","aclImdb/train/unsup/45639_0.txt\n","aclImdb/train/unsup/45638_0.txt\n","aclImdb/train/unsup/45637_0.txt\n","aclImdb/train/unsup/45636_0.txt\n","aclImdb/train/unsup/45635_0.txt\n","aclImdb/train/unsup/45634_0.txt\n","aclImdb/train/unsup/45633_0.txt\n","aclImdb/train/unsup/45632_0.txt\n","aclImdb/train/unsup/45631_0.txt\n","aclImdb/train/unsup/45630_0.txt\n","aclImdb/train/unsup/45629_0.txt\n","aclImdb/train/unsup/45628_0.txt\n","aclImdb/train/unsup/45627_0.txt\n","aclImdb/train/unsup/45626_0.txt\n","aclImdb/train/unsup/45625_0.txt\n","aclImdb/train/unsup/45624_0.txt\n","aclImdb/train/unsup/45623_0.txt\n","aclImdb/train/unsup/45622_0.txt\n","aclImdb/train/unsup/45621_0.txt\n","aclImdb/train/unsup/45620_0.txt\n","aclImdb/train/unsup/45619_0.txt\n","aclImdb/train/unsup/45618_0.txt\n","aclImdb/train/unsup/45617_0.txt\n","aclImdb/train/unsup/45616_0.txt\n","aclImdb/train/unsup/45615_0.txt\n","aclImdb/train/unsup/45614_0.txt\n","aclImdb/train/unsup/45613_0.txt\n","aclImdb/train/unsup/45612_0.txt\n","aclImdb/train/unsup/45611_0.txt\n","aclImdb/train/unsup/45610_0.txt\n","aclImdb/train/unsup/45609_0.txt\n","aclImdb/train/unsup/45608_0.txt\n","aclImdb/train/unsup/45607_0.txt\n","aclImdb/train/unsup/45606_0.txt\n","aclImdb/train/unsup/45605_0.txt\n","aclImdb/train/unsup/45604_0.txt\n","aclImdb/train/unsup/45603_0.txt\n","aclImdb/train/unsup/45602_0.txt\n","aclImdb/train/unsup/45601_0.txt\n","aclImdb/train/unsup/45600_0.txt\n","aclImdb/train/unsup/45599_0.txt\n","aclImdb/train/unsup/45598_0.txt\n","aclImdb/train/unsup/45597_0.txt\n","aclImdb/train/unsup/45596_0.txt\n","aclImdb/train/unsup/45595_0.txt\n","aclImdb/train/unsup/45594_0.txt\n","aclImdb/train/unsup/45593_0.txt\n","aclImdb/train/unsup/45592_0.txt\n","aclImdb/train/unsup/45591_0.txt\n","aclImdb/train/unsup/45590_0.txt\n","aclImdb/train/unsup/45589_0.txt\n","aclImdb/train/unsup/45588_0.txt\n","aclImdb/train/unsup/45587_0.txt\n","aclImdb/train/unsup/45586_0.txt\n","aclImdb/train/unsup/45585_0.txt\n","aclImdb/train/unsup/45584_0.txt\n","aclImdb/train/unsup/45583_0.txt\n","aclImdb/train/unsup/45582_0.txt\n","aclImdb/train/unsup/45581_0.txt\n","aclImdb/train/unsup/45580_0.txt\n","aclImdb/train/unsup/45579_0.txt\n","aclImdb/train/unsup/45578_0.txt\n","aclImdb/train/unsup/45577_0.txt\n","aclImdb/train/unsup/45576_0.txt\n","aclImdb/train/unsup/45575_0.txt\n","aclImdb/train/unsup/45574_0.txt\n","aclImdb/train/unsup/45573_0.txt\n","aclImdb/train/unsup/45572_0.txt\n","aclImdb/train/unsup/45571_0.txt\n","aclImdb/train/unsup/45570_0.txt\n","aclImdb/train/unsup/45569_0.txt\n","aclImdb/train/unsup/45568_0.txt\n","aclImdb/train/unsup/45823_0.txt\n","aclImdb/train/unsup/45822_0.txt\n","aclImdb/train/unsup/45821_0.txt\n","aclImdb/train/unsup/45820_0.txt\n","aclImdb/train/unsup/45819_0.txt\n","aclImdb/train/unsup/45818_0.txt\n","aclImdb/train/unsup/45817_0.txt\n","aclImdb/train/unsup/45816_0.txt\n","aclImdb/train/unsup/45815_0.txt\n","aclImdb/train/unsup/45814_0.txt\n","aclImdb/train/unsup/45813_0.txt\n","aclImdb/train/unsup/45812_0.txt\n","aclImdb/train/unsup/45811_0.txt\n","aclImdb/train/unsup/45810_0.txt\n","aclImdb/train/unsup/45809_0.txt\n","aclImdb/train/unsup/45808_0.txt\n","aclImdb/train/unsup/45807_0.txt\n","aclImdb/train/unsup/45806_0.txt\n","aclImdb/train/unsup/45805_0.txt\n","aclImdb/train/unsup/45804_0.txt\n","aclImdb/train/unsup/45803_0.txt\n","aclImdb/train/unsup/45802_0.txt\n","aclImdb/train/unsup/45801_0.txt\n","aclImdb/train/unsup/45800_0.txt\n","aclImdb/train/unsup/45799_0.txt\n","aclImdb/train/unsup/45798_0.txt\n","aclImdb/train/unsup/45797_0.txt\n","aclImdb/train/unsup/45796_0.txt\n","aclImdb/train/unsup/45795_0.txt\n","aclImdb/train/unsup/45794_0.txt\n","aclImdb/train/unsup/45793_0.txt\n","aclImdb/train/unsup/45792_0.txt\n","aclImdb/train/unsup/45791_0.txt\n","aclImdb/train/unsup/45790_0.txt\n","aclImdb/train/unsup/45789_0.txt\n","aclImdb/train/unsup/45788_0.txt\n","aclImdb/train/unsup/45787_0.txt\n","aclImdb/train/unsup/45786_0.txt\n","aclImdb/train/unsup/45785_0.txt\n","aclImdb/train/unsup/45784_0.txt\n","aclImdb/train/unsup/45783_0.txt\n","aclImdb/train/unsup/45782_0.txt\n","aclImdb/train/unsup/45781_0.txt\n","aclImdb/train/unsup/45780_0.txt\n","aclImdb/train/unsup/45779_0.txt\n","aclImdb/train/unsup/45778_0.txt\n","aclImdb/train/unsup/45777_0.txt\n","aclImdb/train/unsup/45776_0.txt\n","aclImdb/train/unsup/45775_0.txt\n","aclImdb/train/unsup/45774_0.txt\n","aclImdb/train/unsup/45773_0.txt\n","aclImdb/train/unsup/45772_0.txt\n","aclImdb/train/unsup/45771_0.txt\n","aclImdb/train/unsup/45770_0.txt\n","aclImdb/train/unsup/45769_0.txt\n","aclImdb/train/unsup/45768_0.txt\n","aclImdb/train/unsup/45767_0.txt\n","aclImdb/train/unsup/45766_0.txt\n","aclImdb/train/unsup/45765_0.txt\n","aclImdb/train/unsup/45764_0.txt\n","aclImdb/train/unsup/45763_0.txt\n","aclImdb/train/unsup/45762_0.txt\n","aclImdb/train/unsup/45761_0.txt\n","aclImdb/train/unsup/45760_0.txt\n","aclImdb/train/unsup/45759_0.txt\n","aclImdb/train/unsup/45758_0.txt\n","aclImdb/train/unsup/45757_0.txt\n","aclImdb/train/unsup/45756_0.txt\n","aclImdb/train/unsup/45755_0.txt\n","aclImdb/train/unsup/45754_0.txt\n","aclImdb/train/unsup/45753_0.txt\n","aclImdb/train/unsup/45752_0.txt\n","aclImdb/train/unsup/45751_0.txt\n","aclImdb/train/unsup/45750_0.txt\n","aclImdb/train/unsup/45749_0.txt\n","aclImdb/train/unsup/45748_0.txt\n","aclImdb/train/unsup/45747_0.txt\n","aclImdb/train/unsup/45746_0.txt\n","aclImdb/train/unsup/45745_0.txt\n","aclImdb/train/unsup/45744_0.txt\n","aclImdb/train/unsup/45743_0.txt\n","aclImdb/train/unsup/45742_0.txt\n","aclImdb/train/unsup/45741_0.txt\n","aclImdb/train/unsup/45740_0.txt\n","aclImdb/train/unsup/45739_0.txt\n","aclImdb/train/unsup/45738_0.txt\n","aclImdb/train/unsup/45737_0.txt\n","aclImdb/train/unsup/45736_0.txt\n","aclImdb/train/unsup/45735_0.txt\n","aclImdb/train/unsup/45734_0.txt\n","aclImdb/train/unsup/45733_0.txt\n","aclImdb/train/unsup/45732_0.txt\n","aclImdb/train/unsup/45731_0.txt\n","aclImdb/train/unsup/45730_0.txt\n","aclImdb/train/unsup/45729_0.txt\n","aclImdb/train/unsup/45728_0.txt\n","aclImdb/train/unsup/45727_0.txt\n","aclImdb/train/unsup/45726_0.txt\n","aclImdb/train/unsup/45725_0.txt\n","aclImdb/train/unsup/45724_0.txt\n","aclImdb/train/unsup/45723_0.txt\n","aclImdb/train/unsup/45722_0.txt\n","aclImdb/train/unsup/45721_0.txt\n","aclImdb/train/unsup/45720_0.txt\n","aclImdb/train/unsup/45719_0.txt\n","aclImdb/train/unsup/45718_0.txt\n","aclImdb/train/unsup/45717_0.txt\n","aclImdb/train/unsup/45716_0.txt\n","aclImdb/train/unsup/45715_0.txt\n","aclImdb/train/unsup/45714_0.txt\n","aclImdb/train/unsup/45713_0.txt\n","aclImdb/train/unsup/45712_0.txt\n","aclImdb/train/unsup/45711_0.txt\n","aclImdb/train/unsup/45710_0.txt\n","aclImdb/train/unsup/45709_0.txt\n","aclImdb/train/unsup/45708_0.txt\n","aclImdb/train/unsup/45707_0.txt\n","aclImdb/train/unsup/45706_0.txt\n","aclImdb/train/unsup/45705_0.txt\n","aclImdb/train/unsup/45704_0.txt\n","aclImdb/train/unsup/45703_0.txt\n","aclImdb/train/unsup/45702_0.txt\n","aclImdb/train/unsup/45701_0.txt\n","aclImdb/train/unsup/45700_0.txt\n","aclImdb/train/unsup/45699_0.txt\n","aclImdb/train/unsup/45698_0.txt\n","aclImdb/train/unsup/45697_0.txt\n","aclImdb/train/unsup/45696_0.txt\n","aclImdb/train/unsup/45951_0.txt\n","aclImdb/train/unsup/45950_0.txt\n","aclImdb/train/unsup/45949_0.txt\n","aclImdb/train/unsup/45948_0.txt\n","aclImdb/train/unsup/45947_0.txt\n","aclImdb/train/unsup/45946_0.txt\n","aclImdb/train/unsup/45945_0.txt\n","aclImdb/train/unsup/45944_0.txt\n","aclImdb/train/unsup/45943_0.txt\n","aclImdb/train/unsup/45942_0.txt\n","aclImdb/train/unsup/45941_0.txt\n","aclImdb/train/unsup/45940_0.txt\n","aclImdb/train/unsup/45939_0.txt\n","aclImdb/train/unsup/45938_0.txt\n","aclImdb/train/unsup/45937_0.txt\n","aclImdb/train/unsup/45936_0.txt\n","aclImdb/train/unsup/45935_0.txt\n","aclImdb/train/unsup/45934_0.txt\n","aclImdb/train/unsup/45933_0.txt\n","aclImdb/train/unsup/45932_0.txt\n","aclImdb/train/unsup/45931_0.txt\n","aclImdb/train/unsup/45930_0.txt\n","aclImdb/train/unsup/45929_0.txt\n","aclImdb/train/unsup/45928_0.txt\n","aclImdb/train/unsup/45927_0.txt\n","aclImdb/train/unsup/45926_0.txt\n","aclImdb/train/unsup/45925_0.txt\n","aclImdb/train/unsup/45924_0.txt\n","aclImdb/train/unsup/45923_0.txt\n","aclImdb/train/unsup/45922_0.txt\n","aclImdb/train/unsup/45921_0.txt\n","aclImdb/train/unsup/45920_0.txt\n","aclImdb/train/unsup/45919_0.txt\n","aclImdb/train/unsup/45918_0.txt\n","aclImdb/train/unsup/45917_0.txt\n","aclImdb/train/unsup/45916_0.txt\n","aclImdb/train/unsup/45915_0.txt\n","aclImdb/train/unsup/45914_0.txt\n","aclImdb/train/unsup/45913_0.txt\n","aclImdb/train/unsup/45912_0.txt\n","aclImdb/train/unsup/45911_0.txt\n","aclImdb/train/unsup/45910_0.txt\n","aclImdb/train/unsup/45909_0.txt\n","aclImdb/train/unsup/45908_0.txt\n","aclImdb/train/unsup/45907_0.txt\n","aclImdb/train/unsup/45906_0.txt\n","aclImdb/train/unsup/45905_0.txt\n","aclImdb/train/unsup/45904_0.txt\n","aclImdb/train/unsup/45903_0.txt\n","aclImdb/train/unsup/45902_0.txt\n","aclImdb/train/unsup/45901_0.txt\n","aclImdb/train/unsup/45900_0.txt\n","aclImdb/train/unsup/45899_0.txt\n","aclImdb/train/unsup/45898_0.txt\n","aclImdb/train/unsup/45897_0.txt\n","aclImdb/train/unsup/45896_0.txt\n","aclImdb/train/unsup/45895_0.txt\n","aclImdb/train/unsup/45894_0.txt\n","aclImdb/train/unsup/45893_0.txt\n","aclImdb/train/unsup/45892_0.txt\n","aclImdb/train/unsup/45891_0.txt\n","aclImdb/train/unsup/45890_0.txt\n","aclImdb/train/unsup/45889_0.txt\n","aclImdb/train/unsup/45888_0.txt\n","aclImdb/train/unsup/45887_0.txt\n","aclImdb/train/unsup/45886_0.txt\n","aclImdb/train/unsup/45885_0.txt\n","aclImdb/train/unsup/45884_0.txt\n","aclImdb/train/unsup/45883_0.txt\n","aclImdb/train/unsup/45882_0.txt\n","aclImdb/train/unsup/45881_0.txt\n","aclImdb/train/unsup/45880_0.txt\n","aclImdb/train/unsup/45879_0.txt\n","aclImdb/train/unsup/45878_0.txt\n","aclImdb/train/unsup/45877_0.txt\n","aclImdb/train/unsup/45876_0.txt\n","aclImdb/train/unsup/45875_0.txt\n","aclImdb/train/unsup/45874_0.txt\n","aclImdb/train/unsup/45873_0.txt\n","aclImdb/train/unsup/45872_0.txt\n","aclImdb/train/unsup/45871_0.txt\n","aclImdb/train/unsup/45870_0.txt\n","aclImdb/train/unsup/45869_0.txt\n","aclImdb/train/unsup/45868_0.txt\n","aclImdb/train/unsup/45867_0.txt\n","aclImdb/train/unsup/45866_0.txt\n","aclImdb/train/unsup/45865_0.txt\n","aclImdb/train/unsup/45864_0.txt\n","aclImdb/train/unsup/45863_0.txt\n","aclImdb/train/unsup/45862_0.txt\n","aclImdb/train/unsup/45861_0.txt\n","aclImdb/train/unsup/45860_0.txt\n","aclImdb/train/unsup/45859_0.txt\n","aclImdb/train/unsup/45858_0.txt\n","aclImdb/train/unsup/45857_0.txt\n","aclImdb/train/unsup/45856_0.txt\n","aclImdb/train/unsup/45855_0.txt\n","aclImdb/train/unsup/45854_0.txt\n","aclImdb/train/unsup/45853_0.txt\n","aclImdb/train/unsup/45852_0.txt\n","aclImdb/train/unsup/45851_0.txt\n","aclImdb/train/unsup/45850_0.txt\n","aclImdb/train/unsup/45849_0.txt\n","aclImdb/train/unsup/45848_0.txt\n","aclImdb/train/unsup/45847_0.txt\n","aclImdb/train/unsup/45846_0.txt\n","aclImdb/train/unsup/45845_0.txt\n","aclImdb/train/unsup/45844_0.txt\n","aclImdb/train/unsup/45843_0.txt\n","aclImdb/train/unsup/45842_0.txt\n","aclImdb/train/unsup/45841_0.txt\n","aclImdb/train/unsup/45840_0.txt\n","aclImdb/train/unsup/45839_0.txt\n","aclImdb/train/unsup/45838_0.txt\n","aclImdb/train/unsup/45837_0.txt\n","aclImdb/train/unsup/45836_0.txt\n","aclImdb/train/unsup/45835_0.txt\n","aclImdb/train/unsup/45834_0.txt\n","aclImdb/train/unsup/45833_0.txt\n","aclImdb/train/unsup/45832_0.txt\n","aclImdb/train/unsup/45831_0.txt\n","aclImdb/train/unsup/45830_0.txt\n","aclImdb/train/unsup/45829_0.txt\n","aclImdb/train/unsup/45828_0.txt\n","aclImdb/train/unsup/45827_0.txt\n","aclImdb/train/unsup/45826_0.txt\n","aclImdb/train/unsup/45825_0.txt\n","aclImdb/train/unsup/45824_0.txt\n","aclImdb/train/unsup/46079_0.txt\n","aclImdb/train/unsup/46078_0.txt\n","aclImdb/train/unsup/46077_0.txt\n","aclImdb/train/unsup/46076_0.txt\n","aclImdb/train/unsup/46075_0.txt\n","aclImdb/train/unsup/46074_0.txt\n","aclImdb/train/unsup/46073_0.txt\n","aclImdb/train/unsup/46072_0.txt\n","aclImdb/train/unsup/46071_0.txt\n","aclImdb/train/unsup/46070_0.txt\n","aclImdb/train/unsup/46069_0.txt\n","aclImdb/train/unsup/46068_0.txt\n","aclImdb/train/unsup/46067_0.txt\n","aclImdb/train/unsup/46066_0.txt\n","aclImdb/train/unsup/46065_0.txt\n","aclImdb/train/unsup/46064_0.txt\n","aclImdb/train/unsup/46063_0.txt\n","aclImdb/train/unsup/46062_0.txt\n","aclImdb/train/unsup/46061_0.txt\n","aclImdb/train/unsup/46060_0.txt\n","aclImdb/train/unsup/46059_0.txt\n","aclImdb/train/unsup/46058_0.txt\n","aclImdb/train/unsup/46057_0.txt\n","aclImdb/train/unsup/46056_0.txt\n","aclImdb/train/unsup/46055_0.txt\n","aclImdb/train/unsup/46054_0.txt\n","aclImdb/train/unsup/46053_0.txt\n","aclImdb/train/unsup/46052_0.txt\n","aclImdb/train/unsup/46051_0.txt\n","aclImdb/train/unsup/46050_0.txt\n","aclImdb/train/unsup/46049_0.txt\n","aclImdb/train/unsup/46048_0.txt\n","aclImdb/train/unsup/46047_0.txt\n","aclImdb/train/unsup/46046_0.txt\n","aclImdb/train/unsup/46045_0.txt\n","aclImdb/train/unsup/46044_0.txt\n","aclImdb/train/unsup/46043_0.txt\n","aclImdb/train/unsup/46042_0.txt\n","aclImdb/train/unsup/46041_0.txt\n","aclImdb/train/unsup/46040_0.txt\n","aclImdb/train/unsup/46039_0.txt\n","aclImdb/train/unsup/46038_0.txt\n","aclImdb/train/unsup/46037_0.txt\n","aclImdb/train/unsup/46036_0.txt\n","aclImdb/train/unsup/46035_0.txt\n","aclImdb/train/unsup/46034_0.txt\n","aclImdb/train/unsup/46033_0.txt\n","aclImdb/train/unsup/46032_0.txt\n","aclImdb/train/unsup/46031_0.txt\n","aclImdb/train/unsup/46030_0.txt\n","aclImdb/train/unsup/46029_0.txt\n","aclImdb/train/unsup/46028_0.txt\n","aclImdb/train/unsup/46027_0.txt\n","aclImdb/train/unsup/46026_0.txt\n","aclImdb/train/unsup/46025_0.txt\n","aclImdb/train/unsup/46024_0.txt\n","aclImdb/train/unsup/46023_0.txt\n","aclImdb/train/unsup/46022_0.txt\n","aclImdb/train/unsup/46021_0.txt\n","aclImdb/train/unsup/46020_0.txt\n","aclImdb/train/unsup/46019_0.txt\n","aclImdb/train/unsup/46018_0.txt\n","aclImdb/train/unsup/46017_0.txt\n","aclImdb/train/unsup/46016_0.txt\n","aclImdb/train/unsup/46015_0.txt\n","aclImdb/train/unsup/46014_0.txt\n","aclImdb/train/unsup/46013_0.txt\n","aclImdb/train/unsup/46012_0.txt\n","aclImdb/train/unsup/46011_0.txt\n","aclImdb/train/unsup/46010_0.txt\n","aclImdb/train/unsup/46009_0.txt\n","aclImdb/train/unsup/46008_0.txt\n","aclImdb/train/unsup/46007_0.txt\n","aclImdb/train/unsup/46006_0.txt\n","aclImdb/train/unsup/46005_0.txt\n","aclImdb/train/unsup/46004_0.txt\n","aclImdb/train/unsup/46003_0.txt\n","aclImdb/train/unsup/46002_0.txt\n","aclImdb/train/unsup/46001_0.txt\n","aclImdb/train/unsup/46000_0.txt\n","aclImdb/train/unsup/45999_0.txt\n","aclImdb/train/unsup/45998_0.txt\n","aclImdb/train/unsup/45997_0.txt\n","aclImdb/train/unsup/45996_0.txt\n","aclImdb/train/unsup/45995_0.txt\n","aclImdb/train/unsup/45994_0.txt\n","aclImdb/train/unsup/45993_0.txt\n","aclImdb/train/unsup/45992_0.txt\n","aclImdb/train/unsup/45991_0.txt\n","aclImdb/train/unsup/45990_0.txt\n","aclImdb/train/unsup/45989_0.txt\n","aclImdb/train/unsup/45988_0.txt\n","aclImdb/train/unsup/45987_0.txt\n","aclImdb/train/unsup/45986_0.txt\n","aclImdb/train/unsup/45985_0.txt\n","aclImdb/train/unsup/45984_0.txt\n","aclImdb/train/unsup/45983_0.txt\n","aclImdb/train/unsup/45982_0.txt\n","aclImdb/train/unsup/45981_0.txt\n","aclImdb/train/unsup/45980_0.txt\n","aclImdb/train/unsup/45979_0.txt\n","aclImdb/train/unsup/45978_0.txt\n","aclImdb/train/unsup/45977_0.txt\n","aclImdb/train/unsup/45976_0.txt\n","aclImdb/train/unsup/45975_0.txt\n","aclImdb/train/unsup/45974_0.txt\n","aclImdb/train/unsup/45973_0.txt\n","aclImdb/train/unsup/45972_0.txt\n","aclImdb/train/unsup/45971_0.txt\n","aclImdb/train/unsup/45970_0.txt\n","aclImdb/train/unsup/45969_0.txt\n","aclImdb/train/unsup/45968_0.txt\n","aclImdb/train/unsup/45967_0.txt\n","aclImdb/train/unsup/45966_0.txt\n","aclImdb/train/unsup/45965_0.txt\n","aclImdb/train/unsup/45964_0.txt\n","aclImdb/train/unsup/45963_0.txt\n","aclImdb/train/unsup/45962_0.txt\n","aclImdb/train/unsup/45961_0.txt\n","aclImdb/train/unsup/45960_0.txt\n","aclImdb/train/unsup/45959_0.txt\n","aclImdb/train/unsup/45958_0.txt\n","aclImdb/train/unsup/45957_0.txt\n","aclImdb/train/unsup/45956_0.txt\n","aclImdb/train/unsup/45955_0.txt\n","aclImdb/train/unsup/45954_0.txt\n","aclImdb/train/unsup/45953_0.txt\n","aclImdb/train/unsup/45952_0.txt\n","aclImdb/train/unsup/46207_0.txt\n","aclImdb/train/unsup/46206_0.txt\n","aclImdb/train/unsup/46205_0.txt\n","aclImdb/train/unsup/46204_0.txt\n","aclImdb/train/unsup/46203_0.txt\n","aclImdb/train/unsup/46202_0.txt\n","aclImdb/train/unsup/46201_0.txt\n","aclImdb/train/unsup/46200_0.txt\n","aclImdb/train/unsup/46199_0.txt\n","aclImdb/train/unsup/46198_0.txt\n","aclImdb/train/unsup/46197_0.txt\n","aclImdb/train/unsup/46196_0.txt\n","aclImdb/train/unsup/46195_0.txt\n","aclImdb/train/unsup/46194_0.txt\n","aclImdb/train/unsup/46193_0.txt\n","aclImdb/train/unsup/46192_0.txt\n","aclImdb/train/unsup/46191_0.txt\n","aclImdb/train/unsup/46190_0.txt\n","aclImdb/train/unsup/46189_0.txt\n","aclImdb/train/unsup/46188_0.txt\n","aclImdb/train/unsup/46187_0.txt\n","aclImdb/train/unsup/46186_0.txt\n","aclImdb/train/unsup/46185_0.txt\n","aclImdb/train/unsup/46184_0.txt\n","aclImdb/train/unsup/46183_0.txt\n","aclImdb/train/unsup/46182_0.txt\n","aclImdb/train/unsup/46181_0.txt\n","aclImdb/train/unsup/46180_0.txt\n","aclImdb/train/unsup/46179_0.txt\n","aclImdb/train/unsup/46178_0.txt\n","aclImdb/train/unsup/46177_0.txt\n","aclImdb/train/unsup/46176_0.txt\n","aclImdb/train/unsup/46175_0.txt\n","aclImdb/train/unsup/46174_0.txt\n","aclImdb/train/unsup/46173_0.txt\n","aclImdb/train/unsup/46172_0.txt\n","aclImdb/train/unsup/46171_0.txt\n","aclImdb/train/unsup/46170_0.txt\n","aclImdb/train/unsup/46169_0.txt\n","aclImdb/train/unsup/46168_0.txt\n","aclImdb/train/unsup/46167_0.txt\n","aclImdb/train/unsup/46166_0.txt\n","aclImdb/train/unsup/46165_0.txt\n","aclImdb/train/unsup/46164_0.txt\n","aclImdb/train/unsup/46163_0.txt\n","aclImdb/train/unsup/46162_0.txt\n","aclImdb/train/unsup/46161_0.txt\n","aclImdb/train/unsup/46160_0.txt\n","aclImdb/train/unsup/46159_0.txt\n","aclImdb/train/unsup/46158_0.txt\n","aclImdb/train/unsup/46157_0.txt\n","aclImdb/train/unsup/46156_0.txt\n","aclImdb/train/unsup/46155_0.txt\n","aclImdb/train/unsup/46154_0.txt\n","aclImdb/train/unsup/46153_0.txt\n","aclImdb/train/unsup/46152_0.txt\n","aclImdb/train/unsup/46151_0.txt\n","aclImdb/train/unsup/46150_0.txt\n","aclImdb/train/unsup/46149_0.txt\n","aclImdb/train/unsup/46148_0.txt\n","aclImdb/train/unsup/46147_0.txt\n","aclImdb/train/unsup/46146_0.txt\n","aclImdb/train/unsup/46145_0.txt\n","aclImdb/train/unsup/46144_0.txt\n","aclImdb/train/unsup/46143_0.txt\n","aclImdb/train/unsup/46142_0.txt\n","aclImdb/train/unsup/46141_0.txt\n","aclImdb/train/unsup/46140_0.txt\n","aclImdb/train/unsup/46139_0.txt\n","aclImdb/train/unsup/46138_0.txt\n","aclImdb/train/unsup/46137_0.txt\n","aclImdb/train/unsup/46136_0.txt\n","aclImdb/train/unsup/46135_0.txt\n","aclImdb/train/unsup/46134_0.txt\n","aclImdb/train/unsup/46133_0.txt\n","aclImdb/train/unsup/46132_0.txt\n","aclImdb/train/unsup/46131_0.txt\n","aclImdb/train/unsup/46130_0.txt\n","aclImdb/train/unsup/46129_0.txt\n","aclImdb/train/unsup/46128_0.txt\n","aclImdb/train/unsup/46127_0.txt\n","aclImdb/train/unsup/46126_0.txt\n","aclImdb/train/unsup/46125_0.txt\n","aclImdb/train/unsup/46124_0.txt\n","aclImdb/train/unsup/46123_0.txt\n","aclImdb/train/unsup/46122_0.txt\n","aclImdb/train/unsup/46121_0.txt\n","aclImdb/train/unsup/46120_0.txt\n","aclImdb/train/unsup/46119_0.txt\n","aclImdb/train/unsup/46118_0.txt\n","aclImdb/train/unsup/46117_0.txt\n","aclImdb/train/unsup/46116_0.txt\n","aclImdb/train/unsup/46115_0.txt\n","aclImdb/train/unsup/46114_0.txt\n","aclImdb/train/unsup/46113_0.txt\n","aclImdb/train/unsup/46112_0.txt\n","aclImdb/train/unsup/46111_0.txt\n","aclImdb/train/unsup/46110_0.txt\n","aclImdb/train/unsup/46109_0.txt\n","aclImdb/train/unsup/46108_0.txt\n","aclImdb/train/unsup/46107_0.txt\n","aclImdb/train/unsup/46106_0.txt\n","aclImdb/train/unsup/46105_0.txt\n","aclImdb/train/unsup/46104_0.txt\n","aclImdb/train/unsup/46103_0.txt\n","aclImdb/train/unsup/46102_0.txt\n","aclImdb/train/unsup/46101_0.txt\n","aclImdb/train/unsup/46100_0.txt\n","aclImdb/train/unsup/46099_0.txt\n","aclImdb/train/unsup/46098_0.txt\n","aclImdb/train/unsup/46097_0.txt\n","aclImdb/train/unsup/46096_0.txt\n","aclImdb/train/unsup/46095_0.txt\n","aclImdb/train/unsup/46094_0.txt\n","aclImdb/train/unsup/46093_0.txt\n","aclImdb/train/unsup/46092_0.txt\n","aclImdb/train/unsup/46091_0.txt\n","aclImdb/train/unsup/46090_0.txt\n","aclImdb/train/unsup/46089_0.txt\n","aclImdb/train/unsup/46088_0.txt\n","aclImdb/train/unsup/46087_0.txt\n","aclImdb/train/unsup/46086_0.txt\n","aclImdb/train/unsup/46085_0.txt\n","aclImdb/train/unsup/46084_0.txt\n","aclImdb/train/unsup/46083_0.txt\n","aclImdb/train/unsup/46082_0.txt\n","aclImdb/train/unsup/46081_0.txt\n","aclImdb/train/unsup/46080_0.txt\n","aclImdb/train/unsup/46335_0.txt\n","aclImdb/train/unsup/46334_0.txt\n","aclImdb/train/unsup/46333_0.txt\n","aclImdb/train/unsup/46332_0.txt\n","aclImdb/train/unsup/46331_0.txt\n","aclImdb/train/unsup/46330_0.txt\n","aclImdb/train/unsup/46329_0.txt\n","aclImdb/train/unsup/46328_0.txt\n","aclImdb/train/unsup/46327_0.txt\n","aclImdb/train/unsup/46326_0.txt\n","aclImdb/train/unsup/46325_0.txt\n","aclImdb/train/unsup/46324_0.txt\n","aclImdb/train/unsup/46323_0.txt\n","aclImdb/train/unsup/46322_0.txt\n","aclImdb/train/unsup/46321_0.txt\n","aclImdb/train/unsup/46320_0.txt\n","aclImdb/train/unsup/46319_0.txt\n","aclImdb/train/unsup/46318_0.txt\n","aclImdb/train/unsup/46317_0.txt\n","aclImdb/train/unsup/46316_0.txt\n","aclImdb/train/unsup/46315_0.txt\n","aclImdb/train/unsup/46314_0.txt\n","aclImdb/train/unsup/46313_0.txt\n","aclImdb/train/unsup/46312_0.txt\n","aclImdb/train/unsup/46311_0.txt\n","aclImdb/train/unsup/46310_0.txt\n","aclImdb/train/unsup/46309_0.txt\n","aclImdb/train/unsup/46308_0.txt\n","aclImdb/train/unsup/46307_0.txt\n","aclImdb/train/unsup/46306_0.txt\n","aclImdb/train/unsup/46305_0.txt\n","aclImdb/train/unsup/46304_0.txt\n","aclImdb/train/unsup/46303_0.txt\n","aclImdb/train/unsup/46302_0.txt\n","aclImdb/train/unsup/46301_0.txt\n","aclImdb/train/unsup/46300_0.txt\n","aclImdb/train/unsup/46299_0.txt\n","aclImdb/train/unsup/46298_0.txt\n","aclImdb/train/unsup/46297_0.txt\n","aclImdb/train/unsup/46296_0.txt\n","aclImdb/train/unsup/46295_0.txt\n","aclImdb/train/unsup/46294_0.txt\n","aclImdb/train/unsup/46293_0.txt\n","aclImdb/train/unsup/46292_0.txt\n","aclImdb/train/unsup/46291_0.txt\n","aclImdb/train/unsup/46290_0.txt\n","aclImdb/train/unsup/46289_0.txt\n","aclImdb/train/unsup/46288_0.txt\n","aclImdb/train/unsup/46287_0.txt\n","aclImdb/train/unsup/46286_0.txt\n","aclImdb/train/unsup/46285_0.txt\n","aclImdb/train/unsup/46284_0.txt\n","aclImdb/train/unsup/46283_0.txt\n","aclImdb/train/unsup/46282_0.txt\n","aclImdb/train/unsup/46281_0.txt\n","aclImdb/train/unsup/46280_0.txt\n","aclImdb/train/unsup/46279_0.txt\n","aclImdb/train/unsup/46278_0.txt\n","aclImdb/train/unsup/46277_0.txt\n","aclImdb/train/unsup/46276_0.txt\n","aclImdb/train/unsup/46275_0.txt\n","aclImdb/train/unsup/46274_0.txt\n","aclImdb/train/unsup/46273_0.txt\n","aclImdb/train/unsup/46272_0.txt\n","aclImdb/train/unsup/46271_0.txt\n","aclImdb/train/unsup/46270_0.txt\n","aclImdb/train/unsup/46269_0.txt\n","aclImdb/train/unsup/46268_0.txt\n","aclImdb/train/unsup/46267_0.txt\n","aclImdb/train/unsup/46266_0.txt\n","aclImdb/train/unsup/46265_0.txt\n","aclImdb/train/unsup/46264_0.txt\n","aclImdb/train/unsup/46263_0.txt\n","aclImdb/train/unsup/46262_0.txt\n","aclImdb/train/unsup/46261_0.txt\n","aclImdb/train/unsup/46260_0.txt\n","aclImdb/train/unsup/46259_0.txt\n","aclImdb/train/unsup/46258_0.txt\n","aclImdb/train/unsup/46257_0.txt\n","aclImdb/train/unsup/46256_0.txt\n","aclImdb/train/unsup/46255_0.txt\n","aclImdb/train/unsup/46254_0.txt\n","aclImdb/train/unsup/46253_0.txt\n","aclImdb/train/unsup/46252_0.txt\n","aclImdb/train/unsup/46251_0.txt\n","aclImdb/train/unsup/46250_0.txt\n","aclImdb/train/unsup/46249_0.txt\n","aclImdb/train/unsup/46248_0.txt\n","aclImdb/train/unsup/46247_0.txt\n","aclImdb/train/unsup/46246_0.txt\n","aclImdb/train/unsup/46245_0.txt\n","aclImdb/train/unsup/46244_0.txt\n","aclImdb/train/unsup/46243_0.txt\n","aclImdb/train/unsup/46242_0.txt\n","aclImdb/train/unsup/46241_0.txt\n","aclImdb/train/unsup/46240_0.txt\n","aclImdb/train/unsup/46239_0.txt\n","aclImdb/train/unsup/46238_0.txt\n","aclImdb/train/unsup/46237_0.txt\n","aclImdb/train/unsup/46236_0.txt\n","aclImdb/train/unsup/46235_0.txt\n","aclImdb/train/unsup/46234_0.txt\n","aclImdb/train/unsup/46233_0.txt\n","aclImdb/train/unsup/46232_0.txt\n","aclImdb/train/unsup/46231_0.txt\n","aclImdb/train/unsup/46230_0.txt\n","aclImdb/train/unsup/46229_0.txt\n","aclImdb/train/unsup/46228_0.txt\n","aclImdb/train/unsup/46227_0.txt\n","aclImdb/train/unsup/46226_0.txt\n","aclImdb/train/unsup/46225_0.txt\n","aclImdb/train/unsup/46224_0.txt\n","aclImdb/train/unsup/46223_0.txt\n","aclImdb/train/unsup/46222_0.txt\n","aclImdb/train/unsup/46221_0.txt\n","aclImdb/train/unsup/46220_0.txt\n","aclImdb/train/unsup/46219_0.txt\n","aclImdb/train/unsup/46218_0.txt\n","aclImdb/train/unsup/46217_0.txt\n","aclImdb/train/unsup/46216_0.txt\n","aclImdb/train/unsup/46215_0.txt\n","aclImdb/train/unsup/46214_0.txt\n","aclImdb/train/unsup/46213_0.txt\n","aclImdb/train/unsup/46212_0.txt\n","aclImdb/train/unsup/46211_0.txt\n","aclImdb/train/unsup/46210_0.txt\n","aclImdb/train/unsup/46209_0.txt\n","aclImdb/train/unsup/46208_0.txt\n","aclImdb/train/unsup/46463_0.txt\n","aclImdb/train/unsup/46462_0.txt\n","aclImdb/train/unsup/46461_0.txt\n","aclImdb/train/unsup/46460_0.txt\n","aclImdb/train/unsup/46459_0.txt\n","aclImdb/train/unsup/46458_0.txt\n","aclImdb/train/unsup/46457_0.txt\n","aclImdb/train/unsup/46456_0.txt\n","aclImdb/train/unsup/46455_0.txt\n","aclImdb/train/unsup/46454_0.txt\n","aclImdb/train/unsup/46453_0.txt\n","aclImdb/train/unsup/46452_0.txt\n","aclImdb/train/unsup/46451_0.txt\n","aclImdb/train/unsup/46450_0.txt\n","aclImdb/train/unsup/46449_0.txt\n","aclImdb/train/unsup/46448_0.txt\n","aclImdb/train/unsup/46447_0.txt\n","aclImdb/train/unsup/46446_0.txt\n","aclImdb/train/unsup/46445_0.txt\n","aclImdb/train/unsup/46444_0.txt\n","aclImdb/train/unsup/46443_0.txt\n","aclImdb/train/unsup/46442_0.txt\n","aclImdb/train/unsup/46441_0.txt\n","aclImdb/train/unsup/46440_0.txt\n","aclImdb/train/unsup/46439_0.txt\n","aclImdb/train/unsup/46438_0.txt\n","aclImdb/train/unsup/46437_0.txt\n","aclImdb/train/unsup/46436_0.txt\n","aclImdb/train/unsup/46435_0.txt\n","aclImdb/train/unsup/46434_0.txt\n","aclImdb/train/unsup/46433_0.txt\n","aclImdb/train/unsup/46432_0.txt\n","aclImdb/train/unsup/46431_0.txt\n","aclImdb/train/unsup/46430_0.txt\n","aclImdb/train/unsup/46429_0.txt\n","aclImdb/train/unsup/46428_0.txt\n","aclImdb/train/unsup/46427_0.txt\n","aclImdb/train/unsup/46426_0.txt\n","aclImdb/train/unsup/46425_0.txt\n","aclImdb/train/unsup/46424_0.txt\n","aclImdb/train/unsup/46423_0.txt\n","aclImdb/train/unsup/46422_0.txt\n","aclImdb/train/unsup/46421_0.txt\n","aclImdb/train/unsup/46420_0.txt\n","aclImdb/train/unsup/46419_0.txt\n","aclImdb/train/unsup/46418_0.txt\n","aclImdb/train/unsup/46417_0.txt\n","aclImdb/train/unsup/46416_0.txt\n","aclImdb/train/unsup/46415_0.txt\n","aclImdb/train/unsup/46414_0.txt\n","aclImdb/train/unsup/46413_0.txt\n","aclImdb/train/unsup/46412_0.txt\n","aclImdb/train/unsup/46411_0.txt\n","aclImdb/train/unsup/46410_0.txt\n","aclImdb/train/unsup/46409_0.txt\n","aclImdb/train/unsup/46408_0.txt\n","aclImdb/train/unsup/46407_0.txt\n","aclImdb/train/unsup/46406_0.txt\n","aclImdb/train/unsup/46405_0.txt\n","aclImdb/train/unsup/46404_0.txt\n","aclImdb/train/unsup/46403_0.txt\n","aclImdb/train/unsup/46402_0.txt\n","aclImdb/train/unsup/46401_0.txt\n","aclImdb/train/unsup/46400_0.txt\n","aclImdb/train/unsup/46399_0.txt\n","aclImdb/train/unsup/46398_0.txt\n","aclImdb/train/unsup/46397_0.txt\n","aclImdb/train/unsup/46396_0.txt\n","aclImdb/train/unsup/46395_0.txt\n","aclImdb/train/unsup/46394_0.txt\n","aclImdb/train/unsup/46393_0.txt\n","aclImdb/train/unsup/46392_0.txt\n","aclImdb/train/unsup/46391_0.txt\n","aclImdb/train/unsup/46390_0.txt\n","aclImdb/train/unsup/46389_0.txt\n","aclImdb/train/unsup/46388_0.txt\n","aclImdb/train/unsup/46387_0.txt\n","aclImdb/train/unsup/46386_0.txt\n","aclImdb/train/unsup/46385_0.txt\n","aclImdb/train/unsup/46384_0.txt\n","aclImdb/train/unsup/46383_0.txt\n","aclImdb/train/unsup/46382_0.txt\n","aclImdb/train/unsup/46381_0.txt\n","aclImdb/train/unsup/46380_0.txt\n","aclImdb/train/unsup/46379_0.txt\n","aclImdb/train/unsup/46378_0.txt\n","aclImdb/train/unsup/46377_0.txt\n","aclImdb/train/unsup/46376_0.txt\n","aclImdb/train/unsup/46375_0.txt\n","aclImdb/train/unsup/46374_0.txt\n","aclImdb/train/unsup/46373_0.txt\n","aclImdb/train/unsup/46372_0.txt\n","aclImdb/train/unsup/46371_0.txt\n","aclImdb/train/unsup/46370_0.txt\n","aclImdb/train/unsup/46369_0.txt\n","aclImdb/train/unsup/46368_0.txt\n","aclImdb/train/unsup/46367_0.txt\n","aclImdb/train/unsup/46366_0.txt\n","aclImdb/train/unsup/46365_0.txt\n","aclImdb/train/unsup/46364_0.txt\n","aclImdb/train/unsup/46363_0.txt\n","aclImdb/train/unsup/46362_0.txt\n","aclImdb/train/unsup/46361_0.txt\n","aclImdb/train/unsup/46360_0.txt\n","aclImdb/train/unsup/46359_0.txt\n","aclImdb/train/unsup/46358_0.txt\n","aclImdb/train/unsup/46357_0.txt\n","aclImdb/train/unsup/46356_0.txt\n","aclImdb/train/unsup/46355_0.txt\n","aclImdb/train/unsup/46354_0.txt\n","aclImdb/train/unsup/46353_0.txt\n","aclImdb/train/unsup/46352_0.txt\n","aclImdb/train/unsup/46351_0.txt\n","aclImdb/train/unsup/46350_0.txt\n","aclImdb/train/unsup/46349_0.txt\n","aclImdb/train/unsup/46348_0.txt\n","aclImdb/train/unsup/46347_0.txt\n","aclImdb/train/unsup/46346_0.txt\n","aclImdb/train/unsup/46345_0.txt\n","aclImdb/train/unsup/46344_0.txt\n","aclImdb/train/unsup/46343_0.txt\n","aclImdb/train/unsup/46342_0.txt\n","aclImdb/train/unsup/46341_0.txt\n","aclImdb/train/unsup/46340_0.txt\n","aclImdb/train/unsup/46339_0.txt\n","aclImdb/train/unsup/46338_0.txt\n","aclImdb/train/unsup/46337_0.txt\n","aclImdb/train/unsup/46336_0.txt\n","aclImdb/train/unsup/46591_0.txt\n","aclImdb/train/unsup/46590_0.txt\n","aclImdb/train/unsup/46589_0.txt\n","aclImdb/train/unsup/46588_0.txt\n","aclImdb/train/unsup/46587_0.txt\n","aclImdb/train/unsup/46586_0.txt\n","aclImdb/train/unsup/46585_0.txt\n","aclImdb/train/unsup/46584_0.txt\n","aclImdb/train/unsup/46583_0.txt\n","aclImdb/train/unsup/46582_0.txt\n","aclImdb/train/unsup/46581_0.txt\n","aclImdb/train/unsup/46580_0.txt\n","aclImdb/train/unsup/46579_0.txt\n","aclImdb/train/unsup/46578_0.txt\n","aclImdb/train/unsup/46577_0.txt\n","aclImdb/train/unsup/46576_0.txt\n","aclImdb/train/unsup/46575_0.txt\n","aclImdb/train/unsup/46574_0.txt\n","aclImdb/train/unsup/46573_0.txt\n","aclImdb/train/unsup/46572_0.txt\n","aclImdb/train/unsup/46571_0.txt\n","aclImdb/train/unsup/46570_0.txt\n","aclImdb/train/unsup/46569_0.txt\n","aclImdb/train/unsup/46568_0.txt\n","aclImdb/train/unsup/46567_0.txt\n","aclImdb/train/unsup/46566_0.txt\n","aclImdb/train/unsup/46565_0.txt\n","aclImdb/train/unsup/46564_0.txt\n","aclImdb/train/unsup/46563_0.txt\n","aclImdb/train/unsup/46562_0.txt\n","aclImdb/train/unsup/46561_0.txt\n","aclImdb/train/unsup/46560_0.txt\n","aclImdb/train/unsup/46559_0.txt\n","aclImdb/train/unsup/46558_0.txt\n","aclImdb/train/unsup/46557_0.txt\n","aclImdb/train/unsup/46556_0.txt\n","aclImdb/train/unsup/46555_0.txt\n","aclImdb/train/unsup/46554_0.txt\n","aclImdb/train/unsup/46553_0.txt\n","aclImdb/train/unsup/46552_0.txt\n","aclImdb/train/unsup/46551_0.txt\n","aclImdb/train/unsup/46550_0.txt\n","aclImdb/train/unsup/46549_0.txt\n","aclImdb/train/unsup/46548_0.txt\n","aclImdb/train/unsup/46547_0.txt\n","aclImdb/train/unsup/46546_0.txt\n","aclImdb/train/unsup/46545_0.txt\n","aclImdb/train/unsup/46544_0.txt\n","aclImdb/train/unsup/46543_0.txt\n","aclImdb/train/unsup/46542_0.txt\n","aclImdb/train/unsup/46541_0.txt\n","aclImdb/train/unsup/46540_0.txt\n","aclImdb/train/unsup/46539_0.txt\n","aclImdb/train/unsup/46538_0.txt\n","aclImdb/train/unsup/46537_0.txt\n","aclImdb/train/unsup/46536_0.txt\n","aclImdb/train/unsup/46535_0.txt\n","aclImdb/train/unsup/46534_0.txt\n","aclImdb/train/unsup/46533_0.txt\n","aclImdb/train/unsup/46532_0.txt\n","aclImdb/train/unsup/46531_0.txt\n","aclImdb/train/unsup/46530_0.txt\n","aclImdb/train/unsup/46529_0.txt\n","aclImdb/train/unsup/46528_0.txt\n","aclImdb/train/unsup/46527_0.txt\n","aclImdb/train/unsup/46526_0.txt\n","aclImdb/train/unsup/46525_0.txt\n","aclImdb/train/unsup/46524_0.txt\n","aclImdb/train/unsup/46523_0.txt\n","aclImdb/train/unsup/46522_0.txt\n","aclImdb/train/unsup/46521_0.txt\n","aclImdb/train/unsup/46520_0.txt\n","aclImdb/train/unsup/46519_0.txt\n","aclImdb/train/unsup/46518_0.txt\n","aclImdb/train/unsup/46517_0.txt\n","aclImdb/train/unsup/46516_0.txt\n","aclImdb/train/unsup/46515_0.txt\n","aclImdb/train/unsup/46514_0.txt\n","aclImdb/train/unsup/46513_0.txt\n","aclImdb/train/unsup/46512_0.txt\n","aclImdb/train/unsup/46511_0.txt\n","aclImdb/train/unsup/46510_0.txt\n","aclImdb/train/unsup/46509_0.txt\n","aclImdb/train/unsup/46508_0.txt\n","aclImdb/train/unsup/46507_0.txt\n","aclImdb/train/unsup/46506_0.txt\n","aclImdb/train/unsup/46505_0.txt\n","aclImdb/train/unsup/46504_0.txt\n","aclImdb/train/unsup/46503_0.txt\n","aclImdb/train/unsup/46502_0.txt\n","aclImdb/train/unsup/46501_0.txt\n","aclImdb/train/unsup/46500_0.txt\n","aclImdb/train/unsup/46499_0.txt\n","aclImdb/train/unsup/46498_0.txt\n","aclImdb/train/unsup/46497_0.txt\n","aclImdb/train/unsup/46496_0.txt\n","aclImdb/train/unsup/46495_0.txt\n","aclImdb/train/unsup/46494_0.txt\n","aclImdb/train/unsup/46493_0.txt\n","aclImdb/train/unsup/46492_0.txt\n","aclImdb/train/unsup/46491_0.txt\n","aclImdb/train/unsup/46490_0.txt\n","aclImdb/train/unsup/46489_0.txt\n","aclImdb/train/unsup/46488_0.txt\n","aclImdb/train/unsup/46487_0.txt\n","aclImdb/train/unsup/46486_0.txt\n","aclImdb/train/unsup/46485_0.txt\n","aclImdb/train/unsup/46484_0.txt\n","aclImdb/train/unsup/46483_0.txt\n","aclImdb/train/unsup/46482_0.txt\n","aclImdb/train/unsup/46481_0.txt\n","aclImdb/train/unsup/46480_0.txt\n","aclImdb/train/unsup/46479_0.txt\n","aclImdb/train/unsup/46478_0.txt\n","aclImdb/train/unsup/46477_0.txt\n","aclImdb/train/unsup/46476_0.txt\n","aclImdb/train/unsup/46475_0.txt\n","aclImdb/train/unsup/46474_0.txt\n","aclImdb/train/unsup/46473_0.txt\n","aclImdb/train/unsup/46472_0.txt\n","aclImdb/train/unsup/46471_0.txt\n","aclImdb/train/unsup/46470_0.txt\n","aclImdb/train/unsup/46469_0.txt\n","aclImdb/train/unsup/46468_0.txt\n","aclImdb/train/unsup/46467_0.txt\n","aclImdb/train/unsup/46466_0.txt\n","aclImdb/train/unsup/46465_0.txt\n","aclImdb/train/unsup/46464_0.txt\n","aclImdb/train/unsup/46719_0.txt\n","aclImdb/train/unsup/46718_0.txt\n","aclImdb/train/unsup/46717_0.txt\n","aclImdb/train/unsup/46716_0.txt\n","aclImdb/train/unsup/46715_0.txt\n","aclImdb/train/unsup/46714_0.txt\n","aclImdb/train/unsup/46713_0.txt\n","aclImdb/train/unsup/46712_0.txt\n","aclImdb/train/unsup/46711_0.txt\n","aclImdb/train/unsup/46710_0.txt\n","aclImdb/train/unsup/46709_0.txt\n","aclImdb/train/unsup/46708_0.txt\n","aclImdb/train/unsup/46707_0.txt\n","aclImdb/train/unsup/46706_0.txt\n","aclImdb/train/unsup/46705_0.txt\n","aclImdb/train/unsup/46704_0.txt\n","aclImdb/train/unsup/46703_0.txt\n","aclImdb/train/unsup/46702_0.txt\n","aclImdb/train/unsup/46701_0.txt\n","aclImdb/train/unsup/46700_0.txt\n","aclImdb/train/unsup/46699_0.txt\n","aclImdb/train/unsup/46698_0.txt\n","aclImdb/train/unsup/46697_0.txt\n","aclImdb/train/unsup/46696_0.txt\n","aclImdb/train/unsup/46695_0.txt\n","aclImdb/train/unsup/46694_0.txt\n","aclImdb/train/unsup/46693_0.txt\n","aclImdb/train/unsup/46692_0.txt\n","aclImdb/train/unsup/46691_0.txt\n","aclImdb/train/unsup/46690_0.txt\n","aclImdb/train/unsup/46689_0.txt\n","aclImdb/train/unsup/46688_0.txt\n","aclImdb/train/unsup/46687_0.txt\n","aclImdb/train/unsup/46686_0.txt\n","aclImdb/train/unsup/46685_0.txt\n","aclImdb/train/unsup/46684_0.txt\n","aclImdb/train/unsup/46683_0.txt\n","aclImdb/train/unsup/46682_0.txt\n","aclImdb/train/unsup/46681_0.txt\n","aclImdb/train/unsup/46680_0.txt\n","aclImdb/train/unsup/46679_0.txt\n","aclImdb/train/unsup/46678_0.txt\n","aclImdb/train/unsup/46677_0.txt\n","aclImdb/train/unsup/46676_0.txt\n","aclImdb/train/unsup/46675_0.txt\n","aclImdb/train/unsup/46674_0.txt\n","aclImdb/train/unsup/46673_0.txt\n","aclImdb/train/unsup/46672_0.txt\n","aclImdb/train/unsup/46671_0.txt\n","aclImdb/train/unsup/46670_0.txt\n","aclImdb/train/unsup/46669_0.txt\n","aclImdb/train/unsup/46668_0.txt\n","aclImdb/train/unsup/46667_0.txt\n","aclImdb/train/unsup/46666_0.txt\n","aclImdb/train/unsup/46665_0.txt\n","aclImdb/train/unsup/46664_0.txt\n","aclImdb/train/unsup/46663_0.txt\n","aclImdb/train/unsup/46662_0.txt\n","aclImdb/train/unsup/46661_0.txt\n","aclImdb/train/unsup/46660_0.txt\n","aclImdb/train/unsup/46659_0.txt\n","aclImdb/train/unsup/46658_0.txt\n","aclImdb/train/unsup/46657_0.txt\n","aclImdb/train/unsup/46656_0.txt\n","aclImdb/train/unsup/46655_0.txt\n","aclImdb/train/unsup/46654_0.txt\n","aclImdb/train/unsup/46653_0.txt\n","aclImdb/train/unsup/46652_0.txt\n","aclImdb/train/unsup/46651_0.txt\n","aclImdb/train/unsup/46650_0.txt\n","aclImdb/train/unsup/46649_0.txt\n","aclImdb/train/unsup/46648_0.txt\n","aclImdb/train/unsup/46647_0.txt\n","aclImdb/train/unsup/46646_0.txt\n","aclImdb/train/unsup/46645_0.txt\n","aclImdb/train/unsup/46644_0.txt\n","aclImdb/train/unsup/46643_0.txt\n","aclImdb/train/unsup/46642_0.txt\n","aclImdb/train/unsup/46641_0.txt\n","aclImdb/train/unsup/46640_0.txt\n","aclImdb/train/unsup/46639_0.txt\n","aclImdb/train/unsup/46638_0.txt\n","aclImdb/train/unsup/46637_0.txt\n","aclImdb/train/unsup/46636_0.txt\n","aclImdb/train/unsup/46635_0.txt\n","aclImdb/train/unsup/46634_0.txt\n","aclImdb/train/unsup/46633_0.txt\n","aclImdb/train/unsup/46632_0.txt\n","aclImdb/train/unsup/46631_0.txt\n","aclImdb/train/unsup/46630_0.txt\n","aclImdb/train/unsup/46629_0.txt\n","aclImdb/train/unsup/46628_0.txt\n","aclImdb/train/unsup/46627_0.txt\n","aclImdb/train/unsup/46626_0.txt\n","aclImdb/train/unsup/46625_0.txt\n","aclImdb/train/unsup/46624_0.txt\n","aclImdb/train/unsup/46623_0.txt\n","aclImdb/train/unsup/46622_0.txt\n","aclImdb/train/unsup/46621_0.txt\n","aclImdb/train/unsup/46620_0.txt\n","aclImdb/train/unsup/46619_0.txt\n","aclImdb/train/unsup/46618_0.txt\n","aclImdb/train/unsup/46617_0.txt\n","aclImdb/train/unsup/46616_0.txt\n","aclImdb/train/unsup/46615_0.txt\n","aclImdb/train/unsup/46614_0.txt\n","aclImdb/train/unsup/46613_0.txt\n","aclImdb/train/unsup/46612_0.txt\n","aclImdb/train/unsup/46611_0.txt\n","aclImdb/train/unsup/46610_0.txt\n","aclImdb/train/unsup/46609_0.txt\n","aclImdb/train/unsup/46608_0.txt\n","aclImdb/train/unsup/46607_0.txt\n","aclImdb/train/unsup/46606_0.txt\n","aclImdb/train/unsup/46605_0.txt\n","aclImdb/train/unsup/46604_0.txt\n","aclImdb/train/unsup/46603_0.txt\n","aclImdb/train/unsup/46602_0.txt\n","aclImdb/train/unsup/46601_0.txt\n","aclImdb/train/unsup/46600_0.txt\n","aclImdb/train/unsup/46599_0.txt\n","aclImdb/train/unsup/46598_0.txt\n","aclImdb/train/unsup/46597_0.txt\n","aclImdb/train/unsup/46596_0.txt\n","aclImdb/train/unsup/46595_0.txt\n","aclImdb/train/unsup/46594_0.txt\n","aclImdb/train/unsup/46593_0.txt\n","aclImdb/train/unsup/46592_0.txt\n","aclImdb/train/unsup/46847_0.txt\n","aclImdb/train/unsup/46846_0.txt\n","aclImdb/train/unsup/46845_0.txt\n","aclImdb/train/unsup/46844_0.txt\n","aclImdb/train/unsup/46843_0.txt\n","aclImdb/train/unsup/46842_0.txt\n","aclImdb/train/unsup/46841_0.txt\n","aclImdb/train/unsup/46840_0.txt\n","aclImdb/train/unsup/46839_0.txt\n","aclImdb/train/unsup/46838_0.txt\n","aclImdb/train/unsup/46837_0.txt\n","aclImdb/train/unsup/46836_0.txt\n","aclImdb/train/unsup/46835_0.txt\n","aclImdb/train/unsup/46834_0.txt\n","aclImdb/train/unsup/46833_0.txt\n","aclImdb/train/unsup/46832_0.txt\n","aclImdb/train/unsup/46831_0.txt\n","aclImdb/train/unsup/46830_0.txt\n","aclImdb/train/unsup/46829_0.txt\n","aclImdb/train/unsup/46828_0.txt\n","aclImdb/train/unsup/46827_0.txt\n","aclImdb/train/unsup/46826_0.txt\n","aclImdb/train/unsup/46825_0.txt\n","aclImdb/train/unsup/46824_0.txt\n","aclImdb/train/unsup/46823_0.txt\n","aclImdb/train/unsup/46822_0.txt\n","aclImdb/train/unsup/46821_0.txt\n","aclImdb/train/unsup/46820_0.txt\n","aclImdb/train/unsup/46819_0.txt\n","aclImdb/train/unsup/46818_0.txt\n","aclImdb/train/unsup/46817_0.txt\n","aclImdb/train/unsup/46816_0.txt\n","aclImdb/train/unsup/46815_0.txt\n","aclImdb/train/unsup/46814_0.txt\n","aclImdb/train/unsup/46813_0.txt\n","aclImdb/train/unsup/46812_0.txt\n","aclImdb/train/unsup/46811_0.txt\n","aclImdb/train/unsup/46810_0.txt\n","aclImdb/train/unsup/46809_0.txt\n","aclImdb/train/unsup/46808_0.txt\n","aclImdb/train/unsup/46807_0.txt\n","aclImdb/train/unsup/46806_0.txt\n","aclImdb/train/unsup/46805_0.txt\n","aclImdb/train/unsup/46804_0.txt\n","aclImdb/train/unsup/46803_0.txt\n","aclImdb/train/unsup/46802_0.txt\n","aclImdb/train/unsup/46801_0.txt\n","aclImdb/train/unsup/46800_0.txt\n","aclImdb/train/unsup/46799_0.txt\n","aclImdb/train/unsup/46798_0.txt\n","aclImdb/train/unsup/46797_0.txt\n","aclImdb/train/unsup/46796_0.txt\n","aclImdb/train/unsup/46795_0.txt\n","aclImdb/train/unsup/46794_0.txt\n","aclImdb/train/unsup/46793_0.txt\n","aclImdb/train/unsup/46792_0.txt\n","aclImdb/train/unsup/46791_0.txt\n","aclImdb/train/unsup/46790_0.txt\n","aclImdb/train/unsup/46789_0.txt\n","aclImdb/train/unsup/46788_0.txt\n","aclImdb/train/unsup/46787_0.txt\n","aclImdb/train/unsup/46786_0.txt\n","aclImdb/train/unsup/46785_0.txt\n","aclImdb/train/unsup/46784_0.txt\n","aclImdb/train/unsup/46783_0.txt\n","aclImdb/train/unsup/46782_0.txt\n","aclImdb/train/unsup/46781_0.txt\n","aclImdb/train/unsup/46780_0.txt\n","aclImdb/train/unsup/46779_0.txt\n","aclImdb/train/unsup/46778_0.txt\n","aclImdb/train/unsup/46777_0.txt\n","aclImdb/train/unsup/46776_0.txt\n","aclImdb/train/unsup/46775_0.txt\n","aclImdb/train/unsup/46774_0.txt\n","aclImdb/train/unsup/46773_0.txt\n","aclImdb/train/unsup/46772_0.txt\n","aclImdb/train/unsup/46771_0.txt\n","aclImdb/train/unsup/46770_0.txt\n","aclImdb/train/unsup/46769_0.txt\n","aclImdb/train/unsup/46768_0.txt\n","aclImdb/train/unsup/46767_0.txt\n","aclImdb/train/unsup/46766_0.txt\n","aclImdb/train/unsup/46765_0.txt\n","aclImdb/train/unsup/46764_0.txt\n","aclImdb/train/unsup/46763_0.txt\n","aclImdb/train/unsup/46762_0.txt\n","aclImdb/train/unsup/46761_0.txt\n","aclImdb/train/unsup/46760_0.txt\n","aclImdb/train/unsup/46759_0.txt\n","aclImdb/train/unsup/46758_0.txt\n","aclImdb/train/unsup/46757_0.txt\n","aclImdb/train/unsup/46756_0.txt\n","aclImdb/train/unsup/46755_0.txt\n","aclImdb/train/unsup/46754_0.txt\n","aclImdb/train/unsup/46753_0.txt\n","aclImdb/train/unsup/46752_0.txt\n","aclImdb/train/unsup/46751_0.txt\n","aclImdb/train/unsup/46750_0.txt\n","aclImdb/train/unsup/46749_0.txt\n","aclImdb/train/unsup/46748_0.txt\n","aclImdb/train/unsup/46747_0.txt\n","aclImdb/train/unsup/46746_0.txt\n","aclImdb/train/unsup/46745_0.txt\n","aclImdb/train/unsup/46744_0.txt\n","aclImdb/train/unsup/46743_0.txt\n","aclImdb/train/unsup/46742_0.txt\n","aclImdb/train/unsup/46741_0.txt\n","aclImdb/train/unsup/46740_0.txt\n","aclImdb/train/unsup/46739_0.txt\n","aclImdb/train/unsup/46738_0.txt\n","aclImdb/train/unsup/46737_0.txt\n","aclImdb/train/unsup/46736_0.txt\n","aclImdb/train/unsup/46735_0.txt\n","aclImdb/train/unsup/46734_0.txt\n","aclImdb/train/unsup/46733_0.txt\n","aclImdb/train/unsup/46732_0.txt\n","aclImdb/train/unsup/46731_0.txt\n","aclImdb/train/unsup/46730_0.txt\n","aclImdb/train/unsup/46729_0.txt\n","aclImdb/train/unsup/46728_0.txt\n","aclImdb/train/unsup/46727_0.txt\n","aclImdb/train/unsup/46726_0.txt\n","aclImdb/train/unsup/46725_0.txt\n","aclImdb/train/unsup/46724_0.txt\n","aclImdb/train/unsup/46723_0.txt\n","aclImdb/train/unsup/46722_0.txt\n","aclImdb/train/unsup/46721_0.txt\n","aclImdb/train/unsup/46720_0.txt\n","aclImdb/train/unsup/46975_0.txt\n","aclImdb/train/unsup/46974_0.txt\n","aclImdb/train/unsup/46973_0.txt\n","aclImdb/train/unsup/46972_0.txt\n","aclImdb/train/unsup/46971_0.txt\n","aclImdb/train/unsup/46970_0.txt\n","aclImdb/train/unsup/46969_0.txt\n","aclImdb/train/unsup/46968_0.txt\n","aclImdb/train/unsup/46967_0.txt\n","aclImdb/train/unsup/46966_0.txt\n","aclImdb/train/unsup/46965_0.txt\n","aclImdb/train/unsup/46964_0.txt\n","aclImdb/train/unsup/46963_0.txt\n","aclImdb/train/unsup/46962_0.txt\n","aclImdb/train/unsup/46961_0.txt\n","aclImdb/train/unsup/46960_0.txt\n","aclImdb/train/unsup/46959_0.txt\n","aclImdb/train/unsup/46958_0.txt\n","aclImdb/train/unsup/46957_0.txt\n","aclImdb/train/unsup/46956_0.txt\n","aclImdb/train/unsup/46955_0.txt\n","aclImdb/train/unsup/46954_0.txt\n","aclImdb/train/unsup/46953_0.txt\n","aclImdb/train/unsup/46952_0.txt\n","aclImdb/train/unsup/46951_0.txt\n","aclImdb/train/unsup/46950_0.txt\n","aclImdb/train/unsup/46949_0.txt\n","aclImdb/train/unsup/46948_0.txt\n","aclImdb/train/unsup/46947_0.txt\n","aclImdb/train/unsup/46946_0.txt\n","aclImdb/train/unsup/46945_0.txt\n","aclImdb/train/unsup/46944_0.txt\n","aclImdb/train/unsup/46943_0.txt\n","aclImdb/train/unsup/46942_0.txt\n","aclImdb/train/unsup/46941_0.txt\n","aclImdb/train/unsup/46940_0.txt\n","aclImdb/train/unsup/46939_0.txt\n","aclImdb/train/unsup/46938_0.txt\n","aclImdb/train/unsup/46937_0.txt\n","aclImdb/train/unsup/46936_0.txt\n","aclImdb/train/unsup/46935_0.txt\n","aclImdb/train/unsup/46934_0.txt\n","aclImdb/train/unsup/46933_0.txt\n","aclImdb/train/unsup/46932_0.txt\n","aclImdb/train/unsup/46931_0.txt\n","aclImdb/train/unsup/46930_0.txt\n","aclImdb/train/unsup/46929_0.txt\n","aclImdb/train/unsup/46928_0.txt\n","aclImdb/train/unsup/46927_0.txt\n","aclImdb/train/unsup/46926_0.txt\n","aclImdb/train/unsup/46925_0.txt\n","aclImdb/train/unsup/46924_0.txt\n","aclImdb/train/unsup/46923_0.txt\n","aclImdb/train/unsup/46922_0.txt\n","aclImdb/train/unsup/46921_0.txt\n","aclImdb/train/unsup/46920_0.txt\n","aclImdb/train/unsup/46919_0.txt\n","aclImdb/train/unsup/46918_0.txt\n","aclImdb/train/unsup/46917_0.txt\n","aclImdb/train/unsup/46916_0.txt\n","aclImdb/train/unsup/46915_0.txt\n","aclImdb/train/unsup/46914_0.txt\n","aclImdb/train/unsup/46913_0.txt\n","aclImdb/train/unsup/46912_0.txt\n","aclImdb/train/unsup/46911_0.txt\n","aclImdb/train/unsup/46910_0.txt\n","aclImdb/train/unsup/46909_0.txt\n","aclImdb/train/unsup/46908_0.txt\n","aclImdb/train/unsup/46907_0.txt\n","aclImdb/train/unsup/46906_0.txt\n","aclImdb/train/unsup/46905_0.txt\n","aclImdb/train/unsup/46904_0.txt\n","aclImdb/train/unsup/46903_0.txt\n","aclImdb/train/unsup/46902_0.txt\n","aclImdb/train/unsup/46901_0.txt\n","aclImdb/train/unsup/46900_0.txt\n","aclImdb/train/unsup/46899_0.txt\n","aclImdb/train/unsup/46898_0.txt\n","aclImdb/train/unsup/46897_0.txt\n","aclImdb/train/unsup/46896_0.txt\n","aclImdb/train/unsup/46895_0.txt\n","aclImdb/train/unsup/46894_0.txt\n","aclImdb/train/unsup/46893_0.txt\n","aclImdb/train/unsup/46892_0.txt\n","aclImdb/train/unsup/46891_0.txt\n","aclImdb/train/unsup/46890_0.txt\n","aclImdb/train/unsup/46889_0.txt\n","aclImdb/train/unsup/46888_0.txt\n","aclImdb/train/unsup/46887_0.txt\n","aclImdb/train/unsup/46886_0.txt\n","aclImdb/train/unsup/46885_0.txt\n","aclImdb/train/unsup/46884_0.txt\n","aclImdb/train/unsup/46883_0.txt\n","aclImdb/train/unsup/46882_0.txt\n","aclImdb/train/unsup/46881_0.txt\n","aclImdb/train/unsup/46880_0.txt\n","aclImdb/train/unsup/46879_0.txt\n","aclImdb/train/unsup/46878_0.txt\n","aclImdb/train/unsup/46877_0.txt\n","aclImdb/train/unsup/46876_0.txt\n","aclImdb/train/unsup/46875_0.txt\n","aclImdb/train/unsup/46874_0.txt\n","aclImdb/train/unsup/46873_0.txt\n","aclImdb/train/unsup/46872_0.txt\n","aclImdb/train/unsup/46871_0.txt\n","aclImdb/train/unsup/46870_0.txt\n","aclImdb/train/unsup/46869_0.txt\n","aclImdb/train/unsup/46868_0.txt\n","aclImdb/train/unsup/46867_0.txt\n","aclImdb/train/unsup/46866_0.txt\n","aclImdb/train/unsup/46865_0.txt\n","aclImdb/train/unsup/46864_0.txt\n","aclImdb/train/unsup/46863_0.txt\n","aclImdb/train/unsup/46862_0.txt\n","aclImdb/train/unsup/46861_0.txt\n","aclImdb/train/unsup/46860_0.txt\n","aclImdb/train/unsup/46859_0.txt\n","aclImdb/train/unsup/46858_0.txt\n","aclImdb/train/unsup/46857_0.txt\n","aclImdb/train/unsup/46856_0.txt\n","aclImdb/train/unsup/46855_0.txt\n","aclImdb/train/unsup/46854_0.txt\n","aclImdb/train/unsup/46853_0.txt\n","aclImdb/train/unsup/46852_0.txt\n","aclImdb/train/unsup/46851_0.txt\n","aclImdb/train/unsup/46850_0.txt\n","aclImdb/train/unsup/46849_0.txt\n","aclImdb/train/unsup/46848_0.txt\n","aclImdb/train/unsup/47103_0.txt\n","aclImdb/train/unsup/47102_0.txt\n","aclImdb/train/unsup/47101_0.txt\n","aclImdb/train/unsup/47100_0.txt\n","aclImdb/train/unsup/47099_0.txt\n","aclImdb/train/unsup/47098_0.txt\n","aclImdb/train/unsup/47097_0.txt\n","aclImdb/train/unsup/47096_0.txt\n","aclImdb/train/unsup/47095_0.txt\n","aclImdb/train/unsup/47094_0.txt\n","aclImdb/train/unsup/47093_0.txt\n","aclImdb/train/unsup/47092_0.txt\n","aclImdb/train/unsup/47091_0.txt\n","aclImdb/train/unsup/47090_0.txt\n","aclImdb/train/unsup/47089_0.txt\n","aclImdb/train/unsup/47088_0.txt\n","aclImdb/train/unsup/47087_0.txt\n","aclImdb/train/unsup/47086_0.txt\n","aclImdb/train/unsup/47085_0.txt\n","aclImdb/train/unsup/47084_0.txt\n","aclImdb/train/unsup/47083_0.txt\n","aclImdb/train/unsup/47082_0.txt\n","aclImdb/train/unsup/47081_0.txt\n","aclImdb/train/unsup/47080_0.txt\n","aclImdb/train/unsup/47079_0.txt\n","aclImdb/train/unsup/47078_0.txt\n","aclImdb/train/unsup/47077_0.txt\n","aclImdb/train/unsup/47076_0.txt\n","aclImdb/train/unsup/47075_0.txt\n","aclImdb/train/unsup/47074_0.txt\n","aclImdb/train/unsup/47073_0.txt\n","aclImdb/train/unsup/47072_0.txt\n","aclImdb/train/unsup/47071_0.txt\n","aclImdb/train/unsup/47070_0.txt\n","aclImdb/train/unsup/47069_0.txt\n","aclImdb/train/unsup/47068_0.txt\n","aclImdb/train/unsup/47067_0.txt\n","aclImdb/train/unsup/47066_0.txt\n","aclImdb/train/unsup/47065_0.txt\n","aclImdb/train/unsup/47064_0.txt\n","aclImdb/train/unsup/47063_0.txt\n","aclImdb/train/unsup/47062_0.txt\n","aclImdb/train/unsup/47061_0.txt\n","aclImdb/train/unsup/47060_0.txt\n","aclImdb/train/unsup/47059_0.txt\n","aclImdb/train/unsup/47058_0.txt\n","aclImdb/train/unsup/47057_0.txt\n","aclImdb/train/unsup/47056_0.txt\n","aclImdb/train/unsup/47055_0.txt\n","aclImdb/train/unsup/47054_0.txt\n","aclImdb/train/unsup/47053_0.txt\n","aclImdb/train/unsup/47052_0.txt\n","aclImdb/train/unsup/47051_0.txt\n","aclImdb/train/unsup/47050_0.txt\n","aclImdb/train/unsup/47049_0.txt\n","aclImdb/train/unsup/47048_0.txt\n","aclImdb/train/unsup/47047_0.txt\n","aclImdb/train/unsup/47046_0.txt\n","aclImdb/train/unsup/47045_0.txt\n","aclImdb/train/unsup/47044_0.txt\n","aclImdb/train/unsup/47043_0.txt\n","aclImdb/train/unsup/47042_0.txt\n","aclImdb/train/unsup/47041_0.txt\n","aclImdb/train/unsup/47040_0.txt\n","aclImdb/train/unsup/47039_0.txt\n","aclImdb/train/unsup/47038_0.txt\n","aclImdb/train/unsup/47037_0.txt\n","aclImdb/train/unsup/47036_0.txt\n","aclImdb/train/unsup/47035_0.txt\n","aclImdb/train/unsup/47034_0.txt\n","aclImdb/train/unsup/47033_0.txt\n","aclImdb/train/unsup/47032_0.txt\n","aclImdb/train/unsup/47031_0.txt\n","aclImdb/train/unsup/47030_0.txt\n","aclImdb/train/unsup/47029_0.txt\n","aclImdb/train/unsup/47028_0.txt\n","aclImdb/train/unsup/47027_0.txt\n","aclImdb/train/unsup/47026_0.txt\n","aclImdb/train/unsup/47025_0.txt\n","aclImdb/train/unsup/47024_0.txt\n","aclImdb/train/unsup/47023_0.txt\n","aclImdb/train/unsup/47022_0.txt\n","aclImdb/train/unsup/47021_0.txt\n","aclImdb/train/unsup/47020_0.txt\n","aclImdb/train/unsup/47019_0.txt\n","aclImdb/train/unsup/47018_0.txt\n","aclImdb/train/unsup/47017_0.txt\n","aclImdb/train/unsup/47016_0.txt\n","aclImdb/train/unsup/47015_0.txt\n","aclImdb/train/unsup/47014_0.txt\n","aclImdb/train/unsup/47013_0.txt\n","aclImdb/train/unsup/47012_0.txt\n","aclImdb/train/unsup/47011_0.txt\n","aclImdb/train/unsup/47010_0.txt\n","aclImdb/train/unsup/47009_0.txt\n","aclImdb/train/unsup/47008_0.txt\n","aclImdb/train/unsup/47007_0.txt\n","aclImdb/train/unsup/47006_0.txt\n","aclImdb/train/unsup/47005_0.txt\n","aclImdb/train/unsup/47004_0.txt\n","aclImdb/train/unsup/47003_0.txt\n","aclImdb/train/unsup/47002_0.txt\n","aclImdb/train/unsup/47001_0.txt\n","aclImdb/train/unsup/47000_0.txt\n","aclImdb/train/unsup/46999_0.txt\n","aclImdb/train/unsup/46998_0.txt\n","aclImdb/train/unsup/46997_0.txt\n","aclImdb/train/unsup/46996_0.txt\n","aclImdb/train/unsup/46995_0.txt\n","aclImdb/train/unsup/46994_0.txt\n","aclImdb/train/unsup/46993_0.txt\n","aclImdb/train/unsup/46992_0.txt\n","aclImdb/train/unsup/46991_0.txt\n","aclImdb/train/unsup/46990_0.txt\n","aclImdb/train/unsup/46989_0.txt\n","aclImdb/train/unsup/46988_0.txt\n","aclImdb/train/unsup/46987_0.txt\n","aclImdb/train/unsup/46986_0.txt\n","aclImdb/train/unsup/46985_0.txt\n","aclImdb/train/unsup/46984_0.txt\n","aclImdb/train/unsup/46983_0.txt\n","aclImdb/train/unsup/46982_0.txt\n","aclImdb/train/unsup/46981_0.txt\n","aclImdb/train/unsup/46980_0.txt\n","aclImdb/train/unsup/46979_0.txt\n","aclImdb/train/unsup/46978_0.txt\n","aclImdb/train/unsup/46977_0.txt\n","aclImdb/train/unsup/46976_0.txt\n","aclImdb/train/unsup/47231_0.txt\n","aclImdb/train/unsup/47230_0.txt\n","aclImdb/train/unsup/47229_0.txt\n","aclImdb/train/unsup/47228_0.txt\n","aclImdb/train/unsup/47227_0.txt\n","aclImdb/train/unsup/47226_0.txt\n","aclImdb/train/unsup/47225_0.txt\n","aclImdb/train/unsup/47224_0.txt\n","aclImdb/train/unsup/47223_0.txt\n","aclImdb/train/unsup/47222_0.txt\n","aclImdb/train/unsup/47221_0.txt\n","aclImdb/train/unsup/47220_0.txt\n","aclImdb/train/unsup/47219_0.txt\n","aclImdb/train/unsup/47218_0.txt\n","aclImdb/train/unsup/47217_0.txt\n","aclImdb/train/unsup/47216_0.txt\n","aclImdb/train/unsup/47215_0.txt\n","aclImdb/train/unsup/47214_0.txt\n","aclImdb/train/unsup/47213_0.txt\n","aclImdb/train/unsup/47212_0.txt\n","aclImdb/train/unsup/47211_0.txt\n","aclImdb/train/unsup/47210_0.txt\n","aclImdb/train/unsup/47209_0.txt\n","aclImdb/train/unsup/47208_0.txt\n","aclImdb/train/unsup/47207_0.txt\n","aclImdb/train/unsup/47206_0.txt\n","aclImdb/train/unsup/47205_0.txt\n","aclImdb/train/unsup/47204_0.txt\n","aclImdb/train/unsup/47203_0.txt\n","aclImdb/train/unsup/47202_0.txt\n","aclImdb/train/unsup/47201_0.txt\n","aclImdb/train/unsup/47200_0.txt\n","aclImdb/train/unsup/47199_0.txt\n","aclImdb/train/unsup/47198_0.txt\n","aclImdb/train/unsup/47197_0.txt\n","aclImdb/train/unsup/47196_0.txt\n","aclImdb/train/unsup/47195_0.txt\n","aclImdb/train/unsup/47194_0.txt\n","aclImdb/train/unsup/47193_0.txt\n","aclImdb/train/unsup/47192_0.txt\n","aclImdb/train/unsup/47191_0.txt\n","aclImdb/train/unsup/47190_0.txt\n","aclImdb/train/unsup/47189_0.txt\n","aclImdb/train/unsup/47188_0.txt\n","aclImdb/train/unsup/47187_0.txt\n","aclImdb/train/unsup/47186_0.txt\n","aclImdb/train/unsup/47185_0.txt\n","aclImdb/train/unsup/47184_0.txt\n","aclImdb/train/unsup/47183_0.txt\n","aclImdb/train/unsup/47182_0.txt\n","aclImdb/train/unsup/47181_0.txt\n","aclImdb/train/unsup/47180_0.txt\n","aclImdb/train/unsup/47179_0.txt\n","aclImdb/train/unsup/47178_0.txt\n","aclImdb/train/unsup/47177_0.txt\n","aclImdb/train/unsup/47176_0.txt\n","aclImdb/train/unsup/47175_0.txt\n","aclImdb/train/unsup/47174_0.txt\n","aclImdb/train/unsup/47173_0.txt\n","aclImdb/train/unsup/47172_0.txt\n","aclImdb/train/unsup/47171_0.txt\n","aclImdb/train/unsup/47170_0.txt\n","aclImdb/train/unsup/47169_0.txt\n","aclImdb/train/unsup/47168_0.txt\n","aclImdb/train/unsup/47167_0.txt\n","aclImdb/train/unsup/47166_0.txt\n","aclImdb/train/unsup/47165_0.txt\n","aclImdb/train/unsup/47164_0.txt\n","aclImdb/train/unsup/47163_0.txt\n","aclImdb/train/unsup/47162_0.txt\n","aclImdb/train/unsup/47161_0.txt\n","aclImdb/train/unsup/47160_0.txt\n","aclImdb/train/unsup/47159_0.txt\n","aclImdb/train/unsup/47158_0.txt\n","aclImdb/train/unsup/47157_0.txt\n","aclImdb/train/unsup/47156_0.txt\n","aclImdb/train/unsup/47155_0.txt\n","aclImdb/train/unsup/47154_0.txt\n","aclImdb/train/unsup/47153_0.txt\n","aclImdb/train/unsup/47152_0.txt\n","aclImdb/train/unsup/47151_0.txt\n","aclImdb/train/unsup/47150_0.txt\n","aclImdb/train/unsup/47149_0.txt\n","aclImdb/train/unsup/47148_0.txt\n","aclImdb/train/unsup/47147_0.txt\n","aclImdb/train/unsup/47146_0.txt\n","aclImdb/train/unsup/47145_0.txt\n","aclImdb/train/unsup/47144_0.txt\n","aclImdb/train/unsup/47143_0.txt\n","aclImdb/train/unsup/47142_0.txt\n","aclImdb/train/unsup/47141_0.txt\n","aclImdb/train/unsup/47140_0.txt\n","aclImdb/train/unsup/47139_0.txt\n","aclImdb/train/unsup/47138_0.txt\n","aclImdb/train/unsup/47137_0.txt\n","aclImdb/train/unsup/47136_0.txt\n","aclImdb/train/unsup/47135_0.txt\n","aclImdb/train/unsup/47134_0.txt\n","aclImdb/train/unsup/47133_0.txt\n","aclImdb/train/unsup/47132_0.txt\n","aclImdb/train/unsup/47131_0.txt\n","aclImdb/train/unsup/47130_0.txt\n","aclImdb/train/unsup/47129_0.txt\n","aclImdb/train/unsup/47128_0.txt\n","aclImdb/train/unsup/47127_0.txt\n","aclImdb/train/unsup/47126_0.txt\n","aclImdb/train/unsup/47125_0.txt\n","aclImdb/train/unsup/47124_0.txt\n","aclImdb/train/unsup/47123_0.txt\n","aclImdb/train/unsup/47122_0.txt\n","aclImdb/train/unsup/47121_0.txt\n","aclImdb/train/unsup/47120_0.txt\n","aclImdb/train/unsup/47119_0.txt\n","aclImdb/train/unsup/47118_0.txt\n","aclImdb/train/unsup/47117_0.txt\n","aclImdb/train/unsup/47116_0.txt\n","aclImdb/train/unsup/47115_0.txt\n","aclImdb/train/unsup/47114_0.txt\n","aclImdb/train/unsup/47113_0.txt\n","aclImdb/train/unsup/47112_0.txt\n","aclImdb/train/unsup/47111_0.txt\n","aclImdb/train/unsup/47110_0.txt\n","aclImdb/train/unsup/47109_0.txt\n","aclImdb/train/unsup/47108_0.txt\n","aclImdb/train/unsup/47107_0.txt\n","aclImdb/train/unsup/47106_0.txt\n","aclImdb/train/unsup/47105_0.txt\n","aclImdb/train/unsup/47104_0.txt\n","aclImdb/train/unsup/47359_0.txt\n","aclImdb/train/unsup/47358_0.txt\n","aclImdb/train/unsup/47357_0.txt\n","aclImdb/train/unsup/47356_0.txt\n","aclImdb/train/unsup/47355_0.txt\n","aclImdb/train/unsup/47354_0.txt\n","aclImdb/train/unsup/47353_0.txt\n","aclImdb/train/unsup/47352_0.txt\n","aclImdb/train/unsup/47351_0.txt\n","aclImdb/train/unsup/47350_0.txt\n","aclImdb/train/unsup/47349_0.txt\n","aclImdb/train/unsup/47348_0.txt\n","aclImdb/train/unsup/47347_0.txt\n","aclImdb/train/unsup/47346_0.txt\n","aclImdb/train/unsup/47345_0.txt\n","aclImdb/train/unsup/47344_0.txt\n","aclImdb/train/unsup/47343_0.txt\n","aclImdb/train/unsup/47342_0.txt\n","aclImdb/train/unsup/47341_0.txt\n","aclImdb/train/unsup/47340_0.txt\n","aclImdb/train/unsup/47339_0.txt\n","aclImdb/train/unsup/47338_0.txt\n","aclImdb/train/unsup/47337_0.txt\n","aclImdb/train/unsup/47336_0.txt\n","aclImdb/train/unsup/47335_0.txt\n","aclImdb/train/unsup/47334_0.txt\n","aclImdb/train/unsup/47333_0.txt\n","aclImdb/train/unsup/47332_0.txt\n","aclImdb/train/unsup/47331_0.txt\n","aclImdb/train/unsup/47330_0.txt\n","aclImdb/train/unsup/47329_0.txt\n","aclImdb/train/unsup/47328_0.txt\n","aclImdb/train/unsup/47327_0.txt\n","aclImdb/train/unsup/47326_0.txt\n","aclImdb/train/unsup/47325_0.txt\n","aclImdb/train/unsup/47324_0.txt\n","aclImdb/train/unsup/47323_0.txt\n","aclImdb/train/unsup/47322_0.txt\n","aclImdb/train/unsup/47321_0.txt\n","aclImdb/train/unsup/47320_0.txt\n","aclImdb/train/unsup/47319_0.txt\n","aclImdb/train/unsup/47318_0.txt\n","aclImdb/train/unsup/47317_0.txt\n","aclImdb/train/unsup/47316_0.txt\n","aclImdb/train/unsup/47315_0.txt\n","aclImdb/train/unsup/47314_0.txt\n","aclImdb/train/unsup/47313_0.txt\n","aclImdb/train/unsup/47312_0.txt\n","aclImdb/train/unsup/47311_0.txt\n","aclImdb/train/unsup/47310_0.txt\n","aclImdb/train/unsup/47309_0.txt\n","aclImdb/train/unsup/47308_0.txt\n","aclImdb/train/unsup/47307_0.txt\n","aclImdb/train/unsup/47306_0.txt\n","aclImdb/train/unsup/47305_0.txt\n","aclImdb/train/unsup/47304_0.txt\n","aclImdb/train/unsup/47303_0.txt\n","aclImdb/train/unsup/47302_0.txt\n","aclImdb/train/unsup/47301_0.txt\n","aclImdb/train/unsup/47300_0.txt\n","aclImdb/train/unsup/47299_0.txt\n","aclImdb/train/unsup/47298_0.txt\n","aclImdb/train/unsup/47297_0.txt\n","aclImdb/train/unsup/47296_0.txt\n","aclImdb/train/unsup/47295_0.txt\n","aclImdb/train/unsup/47294_0.txt\n","aclImdb/train/unsup/47293_0.txt\n","aclImdb/train/unsup/47292_0.txt\n","aclImdb/train/unsup/47291_0.txt\n","aclImdb/train/unsup/47290_0.txt\n","aclImdb/train/unsup/47289_0.txt\n","aclImdb/train/unsup/47288_0.txt\n","aclImdb/train/unsup/47287_0.txt\n","aclImdb/train/unsup/47286_0.txt\n","aclImdb/train/unsup/47285_0.txt\n","aclImdb/train/unsup/47284_0.txt\n","aclImdb/train/unsup/47283_0.txt\n","aclImdb/train/unsup/47282_0.txt\n","aclImdb/train/unsup/47281_0.txt\n","aclImdb/train/unsup/47280_0.txt\n","aclImdb/train/unsup/47279_0.txt\n","aclImdb/train/unsup/47278_0.txt\n","aclImdb/train/unsup/47277_0.txt\n","aclImdb/train/unsup/47276_0.txt\n","aclImdb/train/unsup/47275_0.txt\n","aclImdb/train/unsup/47274_0.txt\n","aclImdb/train/unsup/47273_0.txt\n","aclImdb/train/unsup/47272_0.txt\n","aclImdb/train/unsup/47271_0.txt\n","aclImdb/train/unsup/47270_0.txt\n","aclImdb/train/unsup/47269_0.txt\n","aclImdb/train/unsup/47268_0.txt\n","aclImdb/train/unsup/47267_0.txt\n","aclImdb/train/unsup/47266_0.txt\n","aclImdb/train/unsup/47265_0.txt\n","aclImdb/train/unsup/47264_0.txt\n","aclImdb/train/unsup/47263_0.txt\n","aclImdb/train/unsup/47262_0.txt\n","aclImdb/train/unsup/47261_0.txt\n","aclImdb/train/unsup/47260_0.txt\n","aclImdb/train/unsup/47259_0.txt\n","aclImdb/train/unsup/47258_0.txt\n","aclImdb/train/unsup/47257_0.txt\n","aclImdb/train/unsup/47256_0.txt\n","aclImdb/train/unsup/47255_0.txt\n","aclImdb/train/unsup/47254_0.txt\n","aclImdb/train/unsup/47253_0.txt\n","aclImdb/train/unsup/47252_0.txt\n","aclImdb/train/unsup/47251_0.txt\n","aclImdb/train/unsup/47250_0.txt\n","aclImdb/train/unsup/47249_0.txt\n","aclImdb/train/unsup/47248_0.txt\n","aclImdb/train/unsup/47247_0.txt\n","aclImdb/train/unsup/47246_0.txt\n","aclImdb/train/unsup/47245_0.txt\n","aclImdb/train/unsup/47244_0.txt\n","aclImdb/train/unsup/47243_0.txt\n","aclImdb/train/unsup/47242_0.txt\n","aclImdb/train/unsup/47241_0.txt\n","aclImdb/train/unsup/47240_0.txt\n","aclImdb/train/unsup/47239_0.txt\n","aclImdb/train/unsup/47238_0.txt\n","aclImdb/train/unsup/47237_0.txt\n","aclImdb/train/unsup/47236_0.txt\n","aclImdb/train/unsup/47235_0.txt\n","aclImdb/train/unsup/47234_0.txt\n","aclImdb/train/unsup/47233_0.txt\n","aclImdb/train/unsup/47232_0.txt\n","aclImdb/train/unsup/47487_0.txt\n","aclImdb/train/unsup/47486_0.txt\n","aclImdb/train/unsup/47485_0.txt\n","aclImdb/train/unsup/47484_0.txt\n","aclImdb/train/unsup/47483_0.txt\n","aclImdb/train/unsup/47482_0.txt\n","aclImdb/train/unsup/47481_0.txt\n","aclImdb/train/unsup/47480_0.txt\n","aclImdb/train/unsup/47479_0.txt\n","aclImdb/train/unsup/47478_0.txt\n","aclImdb/train/unsup/47477_0.txt\n","aclImdb/train/unsup/47476_0.txt\n","aclImdb/train/unsup/47475_0.txt\n","aclImdb/train/unsup/47474_0.txt\n","aclImdb/train/unsup/47473_0.txt\n","aclImdb/train/unsup/47472_0.txt\n","aclImdb/train/unsup/47471_0.txt\n","aclImdb/train/unsup/47470_0.txt\n","aclImdb/train/unsup/47469_0.txt\n","aclImdb/train/unsup/47468_0.txt\n","aclImdb/train/unsup/47467_0.txt\n","aclImdb/train/unsup/47466_0.txt\n","aclImdb/train/unsup/47465_0.txt\n","aclImdb/train/unsup/47464_0.txt\n","aclImdb/train/unsup/47463_0.txt\n","aclImdb/train/unsup/47462_0.txt\n","aclImdb/train/unsup/47461_0.txt\n","aclImdb/train/unsup/47460_0.txt\n","aclImdb/train/unsup/47459_0.txt\n","aclImdb/train/unsup/47458_0.txt\n","aclImdb/train/unsup/47457_0.txt\n","aclImdb/train/unsup/47456_0.txt\n","aclImdb/train/unsup/47455_0.txt\n","aclImdb/train/unsup/47454_0.txt\n","aclImdb/train/unsup/47453_0.txt\n","aclImdb/train/unsup/47452_0.txt\n","aclImdb/train/unsup/47451_0.txt\n","aclImdb/train/unsup/47450_0.txt\n","aclImdb/train/unsup/47449_0.txt\n","aclImdb/train/unsup/47448_0.txt\n","aclImdb/train/unsup/47447_0.txt\n","aclImdb/train/unsup/47446_0.txt\n","aclImdb/train/unsup/47445_0.txt\n","aclImdb/train/unsup/47444_0.txt\n","aclImdb/train/unsup/47443_0.txt\n","aclImdb/train/unsup/47442_0.txt\n","aclImdb/train/unsup/47441_0.txt\n","aclImdb/train/unsup/47440_0.txt\n","aclImdb/train/unsup/47439_0.txt\n","aclImdb/train/unsup/47438_0.txt\n","aclImdb/train/unsup/47437_0.txt\n","aclImdb/train/unsup/47436_0.txt\n","aclImdb/train/unsup/47435_0.txt\n","aclImdb/train/unsup/47434_0.txt\n","aclImdb/train/unsup/47433_0.txt\n","aclImdb/train/unsup/47432_0.txt\n","aclImdb/train/unsup/47431_0.txt\n","aclImdb/train/unsup/47430_0.txt\n","aclImdb/train/unsup/47429_0.txt\n","aclImdb/train/unsup/47428_0.txt\n","aclImdb/train/unsup/47427_0.txt\n","aclImdb/train/unsup/47426_0.txt\n","aclImdb/train/unsup/47425_0.txt\n","aclImdb/train/unsup/47424_0.txt\n","aclImdb/train/unsup/47423_0.txt\n","aclImdb/train/unsup/47422_0.txt\n","aclImdb/train/unsup/47421_0.txt\n","aclImdb/train/unsup/47420_0.txt\n","aclImdb/train/unsup/47419_0.txt\n","aclImdb/train/unsup/47418_0.txt\n","aclImdb/train/unsup/47417_0.txt\n","aclImdb/train/unsup/47416_0.txt\n","aclImdb/train/unsup/47415_0.txt\n","aclImdb/train/unsup/47414_0.txt\n","aclImdb/train/unsup/47413_0.txt\n","aclImdb/train/unsup/47412_0.txt\n","aclImdb/train/unsup/47411_0.txt\n","aclImdb/train/unsup/47410_0.txt\n","aclImdb/train/unsup/47409_0.txt\n","aclImdb/train/unsup/47408_0.txt\n","aclImdb/train/unsup/47407_0.txt\n","aclImdb/train/unsup/47406_0.txt\n","aclImdb/train/unsup/47405_0.txt\n","aclImdb/train/unsup/47404_0.txt\n","aclImdb/train/unsup/47403_0.txt\n","aclImdb/train/unsup/47402_0.txt\n","aclImdb/train/unsup/47401_0.txt\n","aclImdb/train/unsup/47400_0.txt\n","aclImdb/train/unsup/47399_0.txt\n","aclImdb/train/unsup/47398_0.txt\n","aclImdb/train/unsup/47397_0.txt\n","aclImdb/train/unsup/47396_0.txt\n","aclImdb/train/unsup/47395_0.txt\n","aclImdb/train/unsup/47394_0.txt\n","aclImdb/train/unsup/47393_0.txt\n","aclImdb/train/unsup/47392_0.txt\n","aclImdb/train/unsup/47391_0.txt\n","aclImdb/train/unsup/47390_0.txt\n","aclImdb/train/unsup/47389_0.txt\n","aclImdb/train/unsup/47388_0.txt\n","aclImdb/train/unsup/47387_0.txt\n","aclImdb/train/unsup/47386_0.txt\n","aclImdb/train/unsup/47385_0.txt\n","aclImdb/train/unsup/47384_0.txt\n","aclImdb/train/unsup/47383_0.txt\n","aclImdb/train/unsup/47382_0.txt\n","aclImdb/train/unsup/47381_0.txt\n","aclImdb/train/unsup/47380_0.txt\n","aclImdb/train/unsup/47379_0.txt\n","aclImdb/train/unsup/47378_0.txt\n","aclImdb/train/unsup/47377_0.txt\n","aclImdb/train/unsup/47376_0.txt\n","aclImdb/train/unsup/47375_0.txt\n","aclImdb/train/unsup/47374_0.txt\n","aclImdb/train/unsup/47373_0.txt\n","aclImdb/train/unsup/47372_0.txt\n","aclImdb/train/unsup/47371_0.txt\n","aclImdb/train/unsup/47370_0.txt\n","aclImdb/train/unsup/47369_0.txt\n","aclImdb/train/unsup/47368_0.txt\n","aclImdb/train/unsup/47367_0.txt\n","aclImdb/train/unsup/47366_0.txt\n","aclImdb/train/unsup/47365_0.txt\n","aclImdb/train/unsup/47364_0.txt\n","aclImdb/train/unsup/47363_0.txt\n","aclImdb/train/unsup/47362_0.txt\n","aclImdb/train/unsup/47361_0.txt\n","aclImdb/train/unsup/47360_0.txt\n","aclImdb/train/unsup/47615_0.txt\n","aclImdb/train/unsup/47614_0.txt\n","aclImdb/train/unsup/47613_0.txt\n","aclImdb/train/unsup/47612_0.txt\n","aclImdb/train/unsup/47611_0.txt\n","aclImdb/train/unsup/47610_0.txt\n","aclImdb/train/unsup/47609_0.txt\n","aclImdb/train/unsup/47608_0.txt\n","aclImdb/train/unsup/47607_0.txt\n","aclImdb/train/unsup/47606_0.txt\n","aclImdb/train/unsup/47605_0.txt\n","aclImdb/train/unsup/47604_0.txt\n","aclImdb/train/unsup/47603_0.txt\n","aclImdb/train/unsup/47602_0.txt\n","aclImdb/train/unsup/47601_0.txt\n","aclImdb/train/unsup/47600_0.txt\n","aclImdb/train/unsup/47599_0.txt\n","aclImdb/train/unsup/47598_0.txt\n","aclImdb/train/unsup/47597_0.txt\n","aclImdb/train/unsup/47596_0.txt\n","aclImdb/train/unsup/47595_0.txt\n","aclImdb/train/unsup/47594_0.txt\n","aclImdb/train/unsup/47593_0.txt\n","aclImdb/train/unsup/47592_0.txt\n","aclImdb/train/unsup/47591_0.txt\n","aclImdb/train/unsup/47590_0.txt\n","aclImdb/train/unsup/47589_0.txt\n","aclImdb/train/unsup/47588_0.txt\n","aclImdb/train/unsup/47587_0.txt\n","aclImdb/train/unsup/47586_0.txt\n","aclImdb/train/unsup/47585_0.txt\n","aclImdb/train/unsup/47584_0.txt\n","aclImdb/train/unsup/47583_0.txt\n","aclImdb/train/unsup/47582_0.txt\n","aclImdb/train/unsup/47581_0.txt\n","aclImdb/train/unsup/47580_0.txt\n","aclImdb/train/unsup/47579_0.txt\n","aclImdb/train/unsup/47578_0.txt\n","aclImdb/train/unsup/47577_0.txt\n","aclImdb/train/unsup/47576_0.txt\n","aclImdb/train/unsup/47575_0.txt\n","aclImdb/train/unsup/47574_0.txt\n","aclImdb/train/unsup/47573_0.txt\n","aclImdb/train/unsup/47572_0.txt\n","aclImdb/train/unsup/47571_0.txt\n","aclImdb/train/unsup/47570_0.txt\n","aclImdb/train/unsup/47569_0.txt\n","aclImdb/train/unsup/47568_0.txt\n","aclImdb/train/unsup/47567_0.txt\n","aclImdb/train/unsup/47566_0.txt\n","aclImdb/train/unsup/47565_0.txt\n","aclImdb/train/unsup/47564_0.txt\n","aclImdb/train/unsup/47563_0.txt\n","aclImdb/train/unsup/47562_0.txt\n","aclImdb/train/unsup/47561_0.txt\n","aclImdb/train/unsup/47560_0.txt\n","aclImdb/train/unsup/47559_0.txt\n","aclImdb/train/unsup/47558_0.txt\n","aclImdb/train/unsup/47557_0.txt\n","aclImdb/train/unsup/47556_0.txt\n","aclImdb/train/unsup/47555_0.txt\n","aclImdb/train/unsup/47554_0.txt\n","aclImdb/train/unsup/47553_0.txt\n","aclImdb/train/unsup/47552_0.txt\n","aclImdb/train/unsup/47551_0.txt\n","aclImdb/train/unsup/47550_0.txt\n","aclImdb/train/unsup/47549_0.txt\n","aclImdb/train/unsup/47548_0.txt\n","aclImdb/train/unsup/47547_0.txt\n","aclImdb/train/unsup/47546_0.txt\n","aclImdb/train/unsup/47545_0.txt\n","aclImdb/train/unsup/47544_0.txt\n","aclImdb/train/unsup/47543_0.txt\n","aclImdb/train/unsup/47542_0.txt\n","aclImdb/train/unsup/47541_0.txt\n","aclImdb/train/unsup/47540_0.txt\n","aclImdb/train/unsup/47539_0.txt\n","aclImdb/train/unsup/47538_0.txt\n","aclImdb/train/unsup/47537_0.txt\n","aclImdb/train/unsup/47536_0.txt\n","aclImdb/train/unsup/47535_0.txt\n","aclImdb/train/unsup/47534_0.txt\n","aclImdb/train/unsup/47533_0.txt\n","aclImdb/train/unsup/47532_0.txt\n","aclImdb/train/unsup/47531_0.txt\n","aclImdb/train/unsup/47530_0.txt\n","aclImdb/train/unsup/47529_0.txt\n","aclImdb/train/unsup/47528_0.txt\n","aclImdb/train/unsup/47527_0.txt\n","aclImdb/train/unsup/47526_0.txt\n","aclImdb/train/unsup/47525_0.txt\n","aclImdb/train/unsup/47524_0.txt\n","aclImdb/train/unsup/47523_0.txt\n","aclImdb/train/unsup/47522_0.txt\n","aclImdb/train/unsup/47521_0.txt\n","aclImdb/train/unsup/47520_0.txt\n","aclImdb/train/unsup/47519_0.txt\n","aclImdb/train/unsup/47518_0.txt\n","aclImdb/train/unsup/47517_0.txt\n","aclImdb/train/unsup/47516_0.txt\n","aclImdb/train/unsup/47515_0.txt\n","aclImdb/train/unsup/47514_0.txt\n","aclImdb/train/unsup/47513_0.txt\n","aclImdb/train/unsup/47512_0.txt\n","aclImdb/train/unsup/47511_0.txt\n","aclImdb/train/unsup/47510_0.txt\n","aclImdb/train/unsup/47509_0.txt\n","aclImdb/train/unsup/47508_0.txt\n","aclImdb/train/unsup/47507_0.txt\n","aclImdb/train/unsup/47506_0.txt\n","aclImdb/train/unsup/47505_0.txt\n","aclImdb/train/unsup/47504_0.txt\n","aclImdb/train/unsup/47503_0.txt\n","aclImdb/train/unsup/47502_0.txt\n","aclImdb/train/unsup/47501_0.txt\n","aclImdb/train/unsup/47500_0.txt\n","aclImdb/train/unsup/47499_0.txt\n","aclImdb/train/unsup/47498_0.txt\n","aclImdb/train/unsup/47497_0.txt\n","aclImdb/train/unsup/47496_0.txt\n","aclImdb/train/unsup/47495_0.txt\n","aclImdb/train/unsup/47494_0.txt\n","aclImdb/train/unsup/47493_0.txt\n","aclImdb/train/unsup/47492_0.txt\n","aclImdb/train/unsup/47491_0.txt\n","aclImdb/train/unsup/47490_0.txt\n","aclImdb/train/unsup/47489_0.txt\n","aclImdb/train/unsup/47488_0.txt\n","aclImdb/train/unsup/47743_0.txt\n","aclImdb/train/unsup/47742_0.txt\n","aclImdb/train/unsup/47741_0.txt\n","aclImdb/train/unsup/47740_0.txt\n","aclImdb/train/unsup/47739_0.txt\n","aclImdb/train/unsup/47738_0.txt\n","aclImdb/train/unsup/47737_0.txt\n","aclImdb/train/unsup/47736_0.txt\n","aclImdb/train/unsup/47735_0.txt\n","aclImdb/train/unsup/47734_0.txt\n","aclImdb/train/unsup/47733_0.txt\n","aclImdb/train/unsup/47732_0.txt\n","aclImdb/train/unsup/47731_0.txt\n","aclImdb/train/unsup/47730_0.txt\n","aclImdb/train/unsup/47729_0.txt\n","aclImdb/train/unsup/47728_0.txt\n","aclImdb/train/unsup/47727_0.txt\n","aclImdb/train/unsup/47726_0.txt\n","aclImdb/train/unsup/47725_0.txt\n","aclImdb/train/unsup/47724_0.txt\n","aclImdb/train/unsup/47723_0.txt\n","aclImdb/train/unsup/47722_0.txt\n","aclImdb/train/unsup/47721_0.txt\n","aclImdb/train/unsup/47720_0.txt\n","aclImdb/train/unsup/47719_0.txt\n","aclImdb/train/unsup/47718_0.txt\n","aclImdb/train/unsup/47717_0.txt\n","aclImdb/train/unsup/47716_0.txt\n","aclImdb/train/unsup/47715_0.txt\n","aclImdb/train/unsup/47714_0.txt\n","aclImdb/train/unsup/47713_0.txt\n","aclImdb/train/unsup/47712_0.txt\n","aclImdb/train/unsup/47711_0.txt\n","aclImdb/train/unsup/47710_0.txt\n","aclImdb/train/unsup/47709_0.txt\n","aclImdb/train/unsup/47708_0.txt\n","aclImdb/train/unsup/47707_0.txt\n","aclImdb/train/unsup/47706_0.txt\n","aclImdb/train/unsup/47705_0.txt\n","aclImdb/train/unsup/47704_0.txt\n","aclImdb/train/unsup/47703_0.txt\n","aclImdb/train/unsup/47702_0.txt\n","aclImdb/train/unsup/47701_0.txt\n","aclImdb/train/unsup/47700_0.txt\n","aclImdb/train/unsup/47699_0.txt\n","aclImdb/train/unsup/47698_0.txt\n","aclImdb/train/unsup/47697_0.txt\n","aclImdb/train/unsup/47696_0.txt\n","aclImdb/train/unsup/47695_0.txt\n","aclImdb/train/unsup/47694_0.txt\n","aclImdb/train/unsup/47693_0.txt\n","aclImdb/train/unsup/47692_0.txt\n","aclImdb/train/unsup/47691_0.txt\n","aclImdb/train/unsup/47690_0.txt\n","aclImdb/train/unsup/47689_0.txt\n","aclImdb/train/unsup/47688_0.txt\n","aclImdb/train/unsup/47687_0.txt\n","aclImdb/train/unsup/47686_0.txt\n","aclImdb/train/unsup/47685_0.txt\n","aclImdb/train/unsup/47684_0.txt\n","aclImdb/train/unsup/47683_0.txt\n","aclImdb/train/unsup/47682_0.txt\n","aclImdb/train/unsup/47681_0.txt\n","aclImdb/train/unsup/47680_0.txt\n","aclImdb/train/unsup/47679_0.txt\n","aclImdb/train/unsup/47678_0.txt\n","aclImdb/train/unsup/47677_0.txt\n","aclImdb/train/unsup/47676_0.txt\n","aclImdb/train/unsup/47675_0.txt\n","aclImdb/train/unsup/47674_0.txt\n","aclImdb/train/unsup/47673_0.txt\n","aclImdb/train/unsup/47672_0.txt\n","aclImdb/train/unsup/47671_0.txt\n","aclImdb/train/unsup/47670_0.txt\n","aclImdb/train/unsup/47669_0.txt\n","aclImdb/train/unsup/47668_0.txt\n","aclImdb/train/unsup/47667_0.txt\n","aclImdb/train/unsup/47666_0.txt\n","aclImdb/train/unsup/47665_0.txt\n","aclImdb/train/unsup/47664_0.txt\n","aclImdb/train/unsup/47663_0.txt\n","aclImdb/train/unsup/47662_0.txt\n","aclImdb/train/unsup/47661_0.txt\n","aclImdb/train/unsup/47660_0.txt\n","aclImdb/train/unsup/47659_0.txt\n","aclImdb/train/unsup/47658_0.txt\n","aclImdb/train/unsup/47657_0.txt\n","aclImdb/train/unsup/47656_0.txt\n","aclImdb/train/unsup/47655_0.txt\n","aclImdb/train/unsup/47654_0.txt\n","aclImdb/train/unsup/47653_0.txt\n","aclImdb/train/unsup/47652_0.txt\n","aclImdb/train/unsup/47651_0.txt\n","aclImdb/train/unsup/47650_0.txt\n","aclImdb/train/unsup/47649_0.txt\n","aclImdb/train/unsup/47648_0.txt\n","aclImdb/train/unsup/47647_0.txt\n","aclImdb/train/unsup/47646_0.txt\n","aclImdb/train/unsup/47645_0.txt\n","aclImdb/train/unsup/47644_0.txt\n","aclImdb/train/unsup/47643_0.txt\n","aclImdb/train/unsup/47642_0.txt\n","aclImdb/train/unsup/47641_0.txt\n","aclImdb/train/unsup/47640_0.txt\n","aclImdb/train/unsup/47639_0.txt\n","aclImdb/train/unsup/47638_0.txt\n","aclImdb/train/unsup/47637_0.txt\n","aclImdb/train/unsup/47636_0.txt\n","aclImdb/train/unsup/47635_0.txt\n","aclImdb/train/unsup/47634_0.txt\n","aclImdb/train/unsup/47633_0.txt\n","aclImdb/train/unsup/47632_0.txt\n","aclImdb/train/unsup/47631_0.txt\n","aclImdb/train/unsup/47630_0.txt\n","aclImdb/train/unsup/47629_0.txt\n","aclImdb/train/unsup/47628_0.txt\n","aclImdb/train/unsup/47627_0.txt\n","aclImdb/train/unsup/47626_0.txt\n","aclImdb/train/unsup/47625_0.txt\n","aclImdb/train/unsup/47624_0.txt\n","aclImdb/train/unsup/47623_0.txt\n","aclImdb/train/unsup/47622_0.txt\n","aclImdb/train/unsup/47621_0.txt\n","aclImdb/train/unsup/47620_0.txt\n","aclImdb/train/unsup/47619_0.txt\n","aclImdb/train/unsup/47618_0.txt\n","aclImdb/train/unsup/47617_0.txt\n","aclImdb/train/unsup/47616_0.txt\n","aclImdb/train/unsup/47871_0.txt\n","aclImdb/train/unsup/47870_0.txt\n","aclImdb/train/unsup/47869_0.txt\n","aclImdb/train/unsup/47868_0.txt\n","aclImdb/train/unsup/47867_0.txt\n","aclImdb/train/unsup/47866_0.txt\n","aclImdb/train/unsup/47865_0.txt\n","aclImdb/train/unsup/47864_0.txt\n","aclImdb/train/unsup/47863_0.txt\n","aclImdb/train/unsup/47862_0.txt\n","aclImdb/train/unsup/47861_0.txt\n","aclImdb/train/unsup/47860_0.txt\n","aclImdb/train/unsup/47859_0.txt\n","aclImdb/train/unsup/47858_0.txt\n","aclImdb/train/unsup/47857_0.txt\n","aclImdb/train/unsup/47856_0.txt\n","aclImdb/train/unsup/47855_0.txt\n","aclImdb/train/unsup/47854_0.txt\n","aclImdb/train/unsup/47853_0.txt\n","aclImdb/train/unsup/47852_0.txt\n","aclImdb/train/unsup/47851_0.txt\n","aclImdb/train/unsup/47850_0.txt\n","aclImdb/train/unsup/47849_0.txt\n","aclImdb/train/unsup/47848_0.txt\n","aclImdb/train/unsup/47847_0.txt\n","aclImdb/train/unsup/47846_0.txt\n","aclImdb/train/unsup/47845_0.txt\n","aclImdb/train/unsup/47844_0.txt\n","aclImdb/train/unsup/47843_0.txt\n","aclImdb/train/unsup/47842_0.txt\n","aclImdb/train/unsup/47841_0.txt\n","aclImdb/train/unsup/47840_0.txt\n","aclImdb/train/unsup/47839_0.txt\n","aclImdb/train/unsup/47838_0.txt\n","aclImdb/train/unsup/47837_0.txt\n","aclImdb/train/unsup/47836_0.txt\n","aclImdb/train/unsup/47835_0.txt\n","aclImdb/train/unsup/47834_0.txt\n","aclImdb/train/unsup/47833_0.txt\n","aclImdb/train/unsup/47832_0.txt\n","aclImdb/train/unsup/47831_0.txt\n","aclImdb/train/unsup/47830_0.txt\n","aclImdb/train/unsup/47829_0.txt\n","aclImdb/train/unsup/47828_0.txt\n","aclImdb/train/unsup/47827_0.txt\n","aclImdb/train/unsup/47826_0.txt\n","aclImdb/train/unsup/47825_0.txt\n","aclImdb/train/unsup/47824_0.txt\n","aclImdb/train/unsup/47823_0.txt\n","aclImdb/train/unsup/47822_0.txt\n","aclImdb/train/unsup/47821_0.txt\n","aclImdb/train/unsup/47820_0.txt\n","aclImdb/train/unsup/47819_0.txt\n","aclImdb/train/unsup/47818_0.txt\n","aclImdb/train/unsup/47817_0.txt\n","aclImdb/train/unsup/47816_0.txt\n","aclImdb/train/unsup/47815_0.txt\n","aclImdb/train/unsup/47814_0.txt\n","aclImdb/train/unsup/47813_0.txt\n","aclImdb/train/unsup/47812_0.txt\n","aclImdb/train/unsup/47811_0.txt\n","aclImdb/train/unsup/47810_0.txt\n","aclImdb/train/unsup/47809_0.txt\n","aclImdb/train/unsup/47808_0.txt\n","aclImdb/train/unsup/47807_0.txt\n","aclImdb/train/unsup/47806_0.txt\n","aclImdb/train/unsup/47805_0.txt\n","aclImdb/train/unsup/47804_0.txt\n","aclImdb/train/unsup/47803_0.txt\n","aclImdb/train/unsup/47802_0.txt\n","aclImdb/train/unsup/47801_0.txt\n","aclImdb/train/unsup/47800_0.txt\n","aclImdb/train/unsup/47799_0.txt\n","aclImdb/train/unsup/47798_0.txt\n","aclImdb/train/unsup/47797_0.txt\n","aclImdb/train/unsup/47796_0.txt\n","aclImdb/train/unsup/47795_0.txt\n","aclImdb/train/unsup/47794_0.txt\n","aclImdb/train/unsup/47793_0.txt\n","aclImdb/train/unsup/47792_0.txt\n","aclImdb/train/unsup/47791_0.txt\n","aclImdb/train/unsup/47790_0.txt\n","aclImdb/train/unsup/47789_0.txt\n","aclImdb/train/unsup/47788_0.txt\n","aclImdb/train/unsup/47787_0.txt\n","aclImdb/train/unsup/47786_0.txt\n","aclImdb/train/unsup/47785_0.txt\n","aclImdb/train/unsup/47784_0.txt\n","aclImdb/train/unsup/47783_0.txt\n","aclImdb/train/unsup/47782_0.txt\n","aclImdb/train/unsup/47781_0.txt\n","aclImdb/train/unsup/47780_0.txt\n","aclImdb/train/unsup/47779_0.txt\n","aclImdb/train/unsup/47778_0.txt\n","aclImdb/train/unsup/47777_0.txt\n","aclImdb/train/unsup/47776_0.txt\n","aclImdb/train/unsup/47775_0.txt\n","aclImdb/train/unsup/47774_0.txt\n","aclImdb/train/unsup/47773_0.txt\n","aclImdb/train/unsup/47772_0.txt\n","aclImdb/train/unsup/47771_0.txt\n","aclImdb/train/unsup/47770_0.txt\n","aclImdb/train/unsup/47769_0.txt\n","aclImdb/train/unsup/47768_0.txt\n","aclImdb/train/unsup/47767_0.txt\n","aclImdb/train/unsup/47766_0.txt\n","aclImdb/train/unsup/47765_0.txt\n","aclImdb/train/unsup/47764_0.txt\n","aclImdb/train/unsup/47763_0.txt\n","aclImdb/train/unsup/47762_0.txt\n","aclImdb/train/unsup/47761_0.txt\n","aclImdb/train/unsup/47760_0.txt\n","aclImdb/train/unsup/47759_0.txt\n","aclImdb/train/unsup/47758_0.txt\n","aclImdb/train/unsup/47757_0.txt\n","aclImdb/train/unsup/47756_0.txt\n","aclImdb/train/unsup/47755_0.txt\n","aclImdb/train/unsup/47754_0.txt\n","aclImdb/train/unsup/47753_0.txt\n","aclImdb/train/unsup/47752_0.txt\n","aclImdb/train/unsup/47751_0.txt\n","aclImdb/train/unsup/47750_0.txt\n","aclImdb/train/unsup/47749_0.txt\n","aclImdb/train/unsup/47748_0.txt\n","aclImdb/train/unsup/47747_0.txt\n","aclImdb/train/unsup/47746_0.txt\n","aclImdb/train/unsup/47745_0.txt\n","aclImdb/train/unsup/47744_0.txt\n","aclImdb/train/unsup/47999_0.txt\n","aclImdb/train/unsup/47998_0.txt\n","aclImdb/train/unsup/47997_0.txt\n","aclImdb/train/unsup/47996_0.txt\n","aclImdb/train/unsup/47995_0.txt\n","aclImdb/train/unsup/47994_0.txt\n","aclImdb/train/unsup/47993_0.txt\n","aclImdb/train/unsup/47992_0.txt\n","aclImdb/train/unsup/47991_0.txt\n","aclImdb/train/unsup/47990_0.txt\n","aclImdb/train/unsup/47989_0.txt\n","aclImdb/train/unsup/47988_0.txt\n","aclImdb/train/unsup/47987_0.txt\n","aclImdb/train/unsup/47986_0.txt\n","aclImdb/train/unsup/47985_0.txt\n","aclImdb/train/unsup/47984_0.txt\n","aclImdb/train/unsup/47983_0.txt\n","aclImdb/train/unsup/47982_0.txt\n","aclImdb/train/unsup/47981_0.txt\n","aclImdb/train/unsup/47980_0.txt\n","aclImdb/train/unsup/47979_0.txt\n","aclImdb/train/unsup/47978_0.txt\n","aclImdb/train/unsup/47977_0.txt\n","aclImdb/train/unsup/47976_0.txt\n","aclImdb/train/unsup/47975_0.txt\n","aclImdb/train/unsup/47974_0.txt\n","aclImdb/train/unsup/47973_0.txt\n","aclImdb/train/unsup/47972_0.txt\n","aclImdb/train/unsup/47971_0.txt\n","aclImdb/train/unsup/47970_0.txt\n","aclImdb/train/unsup/47969_0.txt\n","aclImdb/train/unsup/47968_0.txt\n","aclImdb/train/unsup/47967_0.txt\n","aclImdb/train/unsup/47966_0.txt\n","aclImdb/train/unsup/47965_0.txt\n","aclImdb/train/unsup/47964_0.txt\n","aclImdb/train/unsup/47963_0.txt\n","aclImdb/train/unsup/47962_0.txt\n","aclImdb/train/unsup/47961_0.txt\n","aclImdb/train/unsup/47960_0.txt\n","aclImdb/train/unsup/47959_0.txt\n","aclImdb/train/unsup/47958_0.txt\n","aclImdb/train/unsup/47957_0.txt\n","aclImdb/train/unsup/47956_0.txt\n","aclImdb/train/unsup/47955_0.txt\n","aclImdb/train/unsup/47954_0.txt\n","aclImdb/train/unsup/47953_0.txt\n","aclImdb/train/unsup/47952_0.txt\n","aclImdb/train/unsup/47951_0.txt\n","aclImdb/train/unsup/47950_0.txt\n","aclImdb/train/unsup/47949_0.txt\n","aclImdb/train/unsup/47948_0.txt\n","aclImdb/train/unsup/47947_0.txt\n","aclImdb/train/unsup/47946_0.txt\n","aclImdb/train/unsup/47945_0.txt\n","aclImdb/train/unsup/47944_0.txt\n","aclImdb/train/unsup/47943_0.txt\n","aclImdb/train/unsup/47942_0.txt\n","aclImdb/train/unsup/47941_0.txt\n","aclImdb/train/unsup/47940_0.txt\n","aclImdb/train/unsup/47939_0.txt\n","aclImdb/train/unsup/47938_0.txt\n","aclImdb/train/unsup/47937_0.txt\n","aclImdb/train/unsup/47936_0.txt\n","aclImdb/train/unsup/47935_0.txt\n","aclImdb/train/unsup/47934_0.txt\n","aclImdb/train/unsup/47933_0.txt\n","aclImdb/train/unsup/47932_0.txt\n","aclImdb/train/unsup/47931_0.txt\n","aclImdb/train/unsup/47930_0.txt\n","aclImdb/train/unsup/47929_0.txt\n","aclImdb/train/unsup/47928_0.txt\n","aclImdb/train/unsup/47927_0.txt\n","aclImdb/train/unsup/47926_0.txt\n","aclImdb/train/unsup/47925_0.txt\n","aclImdb/train/unsup/47924_0.txt\n","aclImdb/train/unsup/47923_0.txt\n","aclImdb/train/unsup/47922_0.txt\n","aclImdb/train/unsup/47921_0.txt\n","aclImdb/train/unsup/47920_0.txt\n","aclImdb/train/unsup/47919_0.txt\n","aclImdb/train/unsup/47918_0.txt\n","aclImdb/train/unsup/47917_0.txt\n","aclImdb/train/unsup/47916_0.txt\n","aclImdb/train/unsup/47915_0.txt\n","aclImdb/train/unsup/47914_0.txt\n","aclImdb/train/unsup/47913_0.txt\n","aclImdb/train/unsup/47912_0.txt\n","aclImdb/train/unsup/47911_0.txt\n","aclImdb/train/unsup/47910_0.txt\n","aclImdb/train/unsup/47909_0.txt\n","aclImdb/train/unsup/47908_0.txt\n","aclImdb/train/unsup/47907_0.txt\n","aclImdb/train/unsup/47906_0.txt\n","aclImdb/train/unsup/47905_0.txt\n","aclImdb/train/unsup/47904_0.txt\n","aclImdb/train/unsup/47903_0.txt\n","aclImdb/train/unsup/47902_0.txt\n","aclImdb/train/unsup/47901_0.txt\n","aclImdb/train/unsup/47900_0.txt\n","aclImdb/train/unsup/47899_0.txt\n","aclImdb/train/unsup/47898_0.txt\n","aclImdb/train/unsup/47897_0.txt\n","aclImdb/train/unsup/47896_0.txt\n","aclImdb/train/unsup/47895_0.txt\n","aclImdb/train/unsup/47894_0.txt\n","aclImdb/train/unsup/47893_0.txt\n","aclImdb/train/unsup/47892_0.txt\n","aclImdb/train/unsup/47891_0.txt\n","aclImdb/train/unsup/47890_0.txt\n","aclImdb/train/unsup/47889_0.txt\n","aclImdb/train/unsup/47888_0.txt\n","aclImdb/train/unsup/47887_0.txt\n","aclImdb/train/unsup/47886_0.txt\n","aclImdb/train/unsup/47885_0.txt\n","aclImdb/train/unsup/47884_0.txt\n","aclImdb/train/unsup/47883_0.txt\n","aclImdb/train/unsup/47882_0.txt\n","aclImdb/train/unsup/47881_0.txt\n","aclImdb/train/unsup/47880_0.txt\n","aclImdb/train/unsup/47879_0.txt\n","aclImdb/train/unsup/47878_0.txt\n","aclImdb/train/unsup/47877_0.txt\n","aclImdb/train/unsup/47876_0.txt\n","aclImdb/train/unsup/47875_0.txt\n","aclImdb/train/unsup/47874_0.txt\n","aclImdb/train/unsup/47873_0.txt\n","aclImdb/train/unsup/47872_0.txt\n","aclImdb/train/unsup/48127_0.txt\n","aclImdb/train/unsup/48126_0.txt\n","aclImdb/train/unsup/48125_0.txt\n","aclImdb/train/unsup/48124_0.txt\n","aclImdb/train/unsup/48123_0.txt\n","aclImdb/train/unsup/48122_0.txt\n","aclImdb/train/unsup/48121_0.txt\n","aclImdb/train/unsup/48120_0.txt\n","aclImdb/train/unsup/48119_0.txt\n","aclImdb/train/unsup/48118_0.txt\n","aclImdb/train/unsup/48117_0.txt\n","aclImdb/train/unsup/48116_0.txt\n","aclImdb/train/unsup/48115_0.txt\n","aclImdb/train/unsup/48114_0.txt\n","aclImdb/train/unsup/48113_0.txt\n","aclImdb/train/unsup/48112_0.txt\n","aclImdb/train/unsup/48111_0.txt\n","aclImdb/train/unsup/48110_0.txt\n","aclImdb/train/unsup/48109_0.txt\n","aclImdb/train/unsup/48108_0.txt\n","aclImdb/train/unsup/48107_0.txt\n","aclImdb/train/unsup/48106_0.txt\n","aclImdb/train/unsup/48105_0.txt\n","aclImdb/train/unsup/48104_0.txt\n","aclImdb/train/unsup/48103_0.txt\n","aclImdb/train/unsup/48102_0.txt\n","aclImdb/train/unsup/48101_0.txt\n","aclImdb/train/unsup/48100_0.txt\n","aclImdb/train/unsup/48099_0.txt\n","aclImdb/train/unsup/48098_0.txt\n","aclImdb/train/unsup/48097_0.txt\n","aclImdb/train/unsup/48096_0.txt\n","aclImdb/train/unsup/48095_0.txt\n","aclImdb/train/unsup/48094_0.txt\n","aclImdb/train/unsup/48093_0.txt\n","aclImdb/train/unsup/48092_0.txt\n","aclImdb/train/unsup/48091_0.txt\n","aclImdb/train/unsup/48090_0.txt\n","aclImdb/train/unsup/48089_0.txt\n","aclImdb/train/unsup/48088_0.txt\n","aclImdb/train/unsup/48087_0.txt\n","aclImdb/train/unsup/48086_0.txt\n","aclImdb/train/unsup/48085_0.txt\n","aclImdb/train/unsup/48084_0.txt\n","aclImdb/train/unsup/48083_0.txt\n","aclImdb/train/unsup/48082_0.txt\n","aclImdb/train/unsup/48081_0.txt\n","aclImdb/train/unsup/48080_0.txt\n","aclImdb/train/unsup/48079_0.txt\n","aclImdb/train/unsup/48078_0.txt\n","aclImdb/train/unsup/48077_0.txt\n","aclImdb/train/unsup/48076_0.txt\n","aclImdb/train/unsup/48075_0.txt\n","aclImdb/train/unsup/48074_0.txt\n","aclImdb/train/unsup/48073_0.txt\n","aclImdb/train/unsup/48072_0.txt\n","aclImdb/train/unsup/48071_0.txt\n","aclImdb/train/unsup/48070_0.txt\n","aclImdb/train/unsup/48069_0.txt\n","aclImdb/train/unsup/48068_0.txt\n","aclImdb/train/unsup/48067_0.txt\n","aclImdb/train/unsup/48066_0.txt\n","aclImdb/train/unsup/48065_0.txt\n","aclImdb/train/unsup/48064_0.txt\n","aclImdb/train/unsup/48063_0.txt\n","aclImdb/train/unsup/48062_0.txt\n","aclImdb/train/unsup/48061_0.txt\n","aclImdb/train/unsup/48060_0.txt\n","aclImdb/train/unsup/48059_0.txt\n","aclImdb/train/unsup/48058_0.txt\n","aclImdb/train/unsup/48057_0.txt\n","aclImdb/train/unsup/48056_0.txt\n","aclImdb/train/unsup/48055_0.txt\n","aclImdb/train/unsup/48054_0.txt\n","aclImdb/train/unsup/48053_0.txt\n","aclImdb/train/unsup/48052_0.txt\n","aclImdb/train/unsup/48051_0.txt\n","aclImdb/train/unsup/48050_0.txt\n","aclImdb/train/unsup/48049_0.txt\n","aclImdb/train/unsup/48048_0.txt\n","aclImdb/train/unsup/48047_0.txt\n","aclImdb/train/unsup/48046_0.txt\n","aclImdb/train/unsup/48045_0.txt\n","aclImdb/train/unsup/48044_0.txt\n","aclImdb/train/unsup/48043_0.txt\n","aclImdb/train/unsup/48042_0.txt\n","aclImdb/train/unsup/48041_0.txt\n","aclImdb/train/unsup/48040_0.txt\n","aclImdb/train/unsup/48039_0.txt\n","aclImdb/train/unsup/48038_0.txt\n","aclImdb/train/unsup/48037_0.txt\n","aclImdb/train/unsup/48036_0.txt\n","aclImdb/train/unsup/48035_0.txt\n","aclImdb/train/unsup/48034_0.txt\n","aclImdb/train/unsup/48033_0.txt\n","aclImdb/train/unsup/48032_0.txt\n","aclImdb/train/unsup/48031_0.txt\n","aclImdb/train/unsup/48030_0.txt\n","aclImdb/train/unsup/48029_0.txt\n","aclImdb/train/unsup/48028_0.txt\n","aclImdb/train/unsup/48027_0.txt\n","aclImdb/train/unsup/48026_0.txt\n","aclImdb/train/unsup/48025_0.txt\n","aclImdb/train/unsup/48024_0.txt\n","aclImdb/train/unsup/48023_0.txt\n","aclImdb/train/unsup/48022_0.txt\n","aclImdb/train/unsup/48021_0.txt\n","aclImdb/train/unsup/48020_0.txt\n","aclImdb/train/unsup/48019_0.txt\n","aclImdb/train/unsup/48018_0.txt\n","aclImdb/train/unsup/48017_0.txt\n","aclImdb/train/unsup/48016_0.txt\n","aclImdb/train/unsup/48015_0.txt\n","aclImdb/train/unsup/48014_0.txt\n","aclImdb/train/unsup/48013_0.txt\n","aclImdb/train/unsup/48012_0.txt\n","aclImdb/train/unsup/48011_0.txt\n","aclImdb/train/unsup/48010_0.txt\n","aclImdb/train/unsup/48009_0.txt\n","aclImdb/train/unsup/48008_0.txt\n","aclImdb/train/unsup/48007_0.txt\n","aclImdb/train/unsup/48006_0.txt\n","aclImdb/train/unsup/48005_0.txt\n","aclImdb/train/unsup/48004_0.txt\n","aclImdb/train/unsup/48003_0.txt\n","aclImdb/train/unsup/48002_0.txt\n","aclImdb/train/unsup/48001_0.txt\n","aclImdb/train/unsup/48000_0.txt\n","aclImdb/train/unsup/48255_0.txt\n","aclImdb/train/unsup/48254_0.txt\n","aclImdb/train/unsup/48253_0.txt\n","aclImdb/train/unsup/48252_0.txt\n","aclImdb/train/unsup/48251_0.txt\n","aclImdb/train/unsup/48250_0.txt\n","aclImdb/train/unsup/48249_0.txt\n","aclImdb/train/unsup/48248_0.txt\n","aclImdb/train/unsup/48247_0.txt\n","aclImdb/train/unsup/48246_0.txt\n","aclImdb/train/unsup/48245_0.txt\n","aclImdb/train/unsup/48244_0.txt\n","aclImdb/train/unsup/48243_0.txt\n","aclImdb/train/unsup/48242_0.txt\n","aclImdb/train/unsup/48241_0.txt\n","aclImdb/train/unsup/48240_0.txt\n","aclImdb/train/unsup/48239_0.txt\n","aclImdb/train/unsup/48238_0.txt\n","aclImdb/train/unsup/48237_0.txt\n","aclImdb/train/unsup/48236_0.txt\n","aclImdb/train/unsup/48235_0.txt\n","aclImdb/train/unsup/48234_0.txt\n","aclImdb/train/unsup/48233_0.txt\n","aclImdb/train/unsup/48232_0.txt\n","aclImdb/train/unsup/48231_0.txt\n","aclImdb/train/unsup/48230_0.txt\n","aclImdb/train/unsup/48229_0.txt\n","aclImdb/train/unsup/48228_0.txt\n","aclImdb/train/unsup/48227_0.txt\n","aclImdb/train/unsup/48226_0.txt\n","aclImdb/train/unsup/48225_0.txt\n","aclImdb/train/unsup/48224_0.txt\n","aclImdb/train/unsup/48223_0.txt\n","aclImdb/train/unsup/48222_0.txt\n","aclImdb/train/unsup/48221_0.txt\n","aclImdb/train/unsup/48220_0.txt\n","aclImdb/train/unsup/48219_0.txt\n","aclImdb/train/unsup/48218_0.txt\n","aclImdb/train/unsup/48217_0.txt\n","aclImdb/train/unsup/48216_0.txt\n","aclImdb/train/unsup/48215_0.txt\n","aclImdb/train/unsup/48214_0.txt\n","aclImdb/train/unsup/48213_0.txt\n","aclImdb/train/unsup/48212_0.txt\n","aclImdb/train/unsup/48211_0.txt\n","aclImdb/train/unsup/48210_0.txt\n","aclImdb/train/unsup/48209_0.txt\n","aclImdb/train/unsup/48208_0.txt\n","aclImdb/train/unsup/48207_0.txt\n","aclImdb/train/unsup/48206_0.txt\n","aclImdb/train/unsup/48205_0.txt\n","aclImdb/train/unsup/48204_0.txt\n","aclImdb/train/unsup/48203_0.txt\n","aclImdb/train/unsup/48202_0.txt\n","aclImdb/train/unsup/48201_0.txt\n","aclImdb/train/unsup/48200_0.txt\n","aclImdb/train/unsup/48199_0.txt\n","aclImdb/train/unsup/48198_0.txt\n","aclImdb/train/unsup/48197_0.txt\n","aclImdb/train/unsup/48196_0.txt\n","aclImdb/train/unsup/48195_0.txt\n","aclImdb/train/unsup/48194_0.txt\n","aclImdb/train/unsup/48193_0.txt\n","aclImdb/train/unsup/48192_0.txt\n","aclImdb/train/unsup/48191_0.txt\n","aclImdb/train/unsup/48190_0.txt\n","aclImdb/train/unsup/48189_0.txt\n","aclImdb/train/unsup/48188_0.txt\n","aclImdb/train/unsup/48187_0.txt\n","aclImdb/train/unsup/48186_0.txt\n","aclImdb/train/unsup/48185_0.txt\n","aclImdb/train/unsup/48184_0.txt\n","aclImdb/train/unsup/48183_0.txt\n","aclImdb/train/unsup/48182_0.txt\n","aclImdb/train/unsup/48181_0.txt\n","aclImdb/train/unsup/48180_0.txt\n","aclImdb/train/unsup/48179_0.txt\n","aclImdb/train/unsup/48178_0.txt\n","aclImdb/train/unsup/48177_0.txt\n","aclImdb/train/unsup/48176_0.txt\n","aclImdb/train/unsup/48175_0.txt\n","aclImdb/train/unsup/48174_0.txt\n","aclImdb/train/unsup/48173_0.txt\n","aclImdb/train/unsup/48172_0.txt\n","aclImdb/train/unsup/48171_0.txt\n","aclImdb/train/unsup/48170_0.txt\n","aclImdb/train/unsup/48169_0.txt\n","aclImdb/train/unsup/48168_0.txt\n","aclImdb/train/unsup/48167_0.txt\n","aclImdb/train/unsup/48166_0.txt\n","aclImdb/train/unsup/48165_0.txt\n","aclImdb/train/unsup/48164_0.txt\n","aclImdb/train/unsup/48163_0.txt\n","aclImdb/train/unsup/48162_0.txt\n","aclImdb/train/unsup/48161_0.txt\n","aclImdb/train/unsup/48160_0.txt\n","aclImdb/train/unsup/48159_0.txt\n","aclImdb/train/unsup/48158_0.txt\n","aclImdb/train/unsup/48157_0.txt\n","aclImdb/train/unsup/48156_0.txt\n","aclImdb/train/unsup/48155_0.txt\n","aclImdb/train/unsup/48154_0.txt\n","aclImdb/train/unsup/48153_0.txt\n","aclImdb/train/unsup/48152_0.txt\n","aclImdb/train/unsup/48151_0.txt\n","aclImdb/train/unsup/48150_0.txt\n","aclImdb/train/unsup/48149_0.txt\n","aclImdb/train/unsup/48148_0.txt\n","aclImdb/train/unsup/48147_0.txt\n","aclImdb/train/unsup/48146_0.txt\n","aclImdb/train/unsup/48145_0.txt\n","aclImdb/train/unsup/48144_0.txt\n","aclImdb/train/unsup/48143_0.txt\n","aclImdb/train/unsup/48142_0.txt\n","aclImdb/train/unsup/48141_0.txt\n","aclImdb/train/unsup/48140_0.txt\n","aclImdb/train/unsup/48139_0.txt\n","aclImdb/train/unsup/48138_0.txt\n","aclImdb/train/unsup/48137_0.txt\n","aclImdb/train/unsup/48136_0.txt\n","aclImdb/train/unsup/48135_0.txt\n","aclImdb/train/unsup/48134_0.txt\n","aclImdb/train/unsup/48133_0.txt\n","aclImdb/train/unsup/48132_0.txt\n","aclImdb/train/unsup/48131_0.txt\n","aclImdb/train/unsup/48130_0.txt\n","aclImdb/train/unsup/48129_0.txt\n","aclImdb/train/unsup/48128_0.txt\n","aclImdb/train/unsup/48383_0.txt\n","aclImdb/train/unsup/48382_0.txt\n","aclImdb/train/unsup/48381_0.txt\n","aclImdb/train/unsup/48380_0.txt\n","aclImdb/train/unsup/48379_0.txt\n","aclImdb/train/unsup/48378_0.txt\n","aclImdb/train/unsup/48377_0.txt\n","aclImdb/train/unsup/48376_0.txt\n","aclImdb/train/unsup/48375_0.txt\n","aclImdb/train/unsup/48374_0.txt\n","aclImdb/train/unsup/48373_0.txt\n","aclImdb/train/unsup/48372_0.txt\n","aclImdb/train/unsup/48371_0.txt\n","aclImdb/train/unsup/48370_0.txt\n","aclImdb/train/unsup/48369_0.txt\n","aclImdb/train/unsup/48368_0.txt\n","aclImdb/train/unsup/48367_0.txt\n","aclImdb/train/unsup/48366_0.txt\n","aclImdb/train/unsup/48365_0.txt\n","aclImdb/train/unsup/48364_0.txt\n","aclImdb/train/unsup/48363_0.txt\n","aclImdb/train/unsup/48362_0.txt\n","aclImdb/train/unsup/48361_0.txt\n","aclImdb/train/unsup/48360_0.txt\n","aclImdb/train/unsup/48359_0.txt\n","aclImdb/train/unsup/48358_0.txt\n","aclImdb/train/unsup/48357_0.txt\n","aclImdb/train/unsup/48356_0.txt\n","aclImdb/train/unsup/48355_0.txt\n","aclImdb/train/unsup/48354_0.txt\n","aclImdb/train/unsup/48353_0.txt\n","aclImdb/train/unsup/48352_0.txt\n","aclImdb/train/unsup/48351_0.txt\n","aclImdb/train/unsup/48350_0.txt\n","aclImdb/train/unsup/48349_0.txt\n","aclImdb/train/unsup/48348_0.txt\n","aclImdb/train/unsup/48347_0.txt\n","aclImdb/train/unsup/48346_0.txt\n","aclImdb/train/unsup/48345_0.txt\n","aclImdb/train/unsup/48344_0.txt\n","aclImdb/train/unsup/48343_0.txt\n","aclImdb/train/unsup/48342_0.txt\n","aclImdb/train/unsup/48341_0.txt\n","aclImdb/train/unsup/48340_0.txt\n","aclImdb/train/unsup/48339_0.txt\n","aclImdb/train/unsup/48338_0.txt\n","aclImdb/train/unsup/48337_0.txt\n","aclImdb/train/unsup/48336_0.txt\n","aclImdb/train/unsup/48335_0.txt\n","aclImdb/train/unsup/48334_0.txt\n","aclImdb/train/unsup/48333_0.txt\n","aclImdb/train/unsup/48332_0.txt\n","aclImdb/train/unsup/48331_0.txt\n","aclImdb/train/unsup/48330_0.txt\n","aclImdb/train/unsup/48329_0.txt\n","aclImdb/train/unsup/48328_0.txt\n","aclImdb/train/unsup/48327_0.txt\n","aclImdb/train/unsup/48326_0.txt\n","aclImdb/train/unsup/48325_0.txt\n","aclImdb/train/unsup/48324_0.txt\n","aclImdb/train/unsup/48323_0.txt\n","aclImdb/train/unsup/48322_0.txt\n","aclImdb/train/unsup/48321_0.txt\n","aclImdb/train/unsup/48320_0.txt\n","aclImdb/train/unsup/48319_0.txt\n","aclImdb/train/unsup/48318_0.txt\n","aclImdb/train/unsup/48317_0.txt\n","aclImdb/train/unsup/48316_0.txt\n","aclImdb/train/unsup/48315_0.txt\n","aclImdb/train/unsup/48314_0.txt\n","aclImdb/train/unsup/48313_0.txt\n","aclImdb/train/unsup/48312_0.txt\n","aclImdb/train/unsup/48311_0.txt\n","aclImdb/train/unsup/48310_0.txt\n","aclImdb/train/unsup/48309_0.txt\n","aclImdb/train/unsup/48308_0.txt\n","aclImdb/train/unsup/48307_0.txt\n","aclImdb/train/unsup/48306_0.txt\n","aclImdb/train/unsup/48305_0.txt\n","aclImdb/train/unsup/48304_0.txt\n","aclImdb/train/unsup/48303_0.txt\n","aclImdb/train/unsup/48302_0.txt\n","aclImdb/train/unsup/48301_0.txt\n","aclImdb/train/unsup/48300_0.txt\n","aclImdb/train/unsup/48299_0.txt\n","aclImdb/train/unsup/48298_0.txt\n","aclImdb/train/unsup/48297_0.txt\n","aclImdb/train/unsup/48296_0.txt\n","aclImdb/train/unsup/48295_0.txt\n","aclImdb/train/unsup/48294_0.txt\n","aclImdb/train/unsup/48293_0.txt\n","aclImdb/train/unsup/48292_0.txt\n","aclImdb/train/unsup/48291_0.txt\n","aclImdb/train/unsup/48290_0.txt\n","aclImdb/train/unsup/48289_0.txt\n","aclImdb/train/unsup/48288_0.txt\n","aclImdb/train/unsup/48287_0.txt\n","aclImdb/train/unsup/48286_0.txt\n","aclImdb/train/unsup/48285_0.txt\n","aclImdb/train/unsup/48284_0.txt\n","aclImdb/train/unsup/48283_0.txt\n","aclImdb/train/unsup/48282_0.txt\n","aclImdb/train/unsup/48281_0.txt\n","aclImdb/train/unsup/48280_0.txt\n","aclImdb/train/unsup/48279_0.txt\n","aclImdb/train/unsup/48278_0.txt\n","aclImdb/train/unsup/48277_0.txt\n","aclImdb/train/unsup/48276_0.txt\n","aclImdb/train/unsup/48275_0.txt\n","aclImdb/train/unsup/48274_0.txt\n","aclImdb/train/unsup/48273_0.txt\n","aclImdb/train/unsup/48272_0.txt\n","aclImdb/train/unsup/48271_0.txt\n","aclImdb/train/unsup/48270_0.txt\n","aclImdb/train/unsup/48269_0.txt\n","aclImdb/train/unsup/48268_0.txt\n","aclImdb/train/unsup/48267_0.txt\n","aclImdb/train/unsup/48266_0.txt\n","aclImdb/train/unsup/48265_0.txt\n","aclImdb/train/unsup/48264_0.txt\n","aclImdb/train/unsup/48263_0.txt\n","aclImdb/train/unsup/48262_0.txt\n","aclImdb/train/unsup/48261_0.txt\n","aclImdb/train/unsup/48260_0.txt\n","aclImdb/train/unsup/48259_0.txt\n","aclImdb/train/unsup/48258_0.txt\n","aclImdb/train/unsup/48257_0.txt\n","aclImdb/train/unsup/48256_0.txt\n","aclImdb/train/unsup/48511_0.txt\n","aclImdb/train/unsup/48510_0.txt\n","aclImdb/train/unsup/48509_0.txt\n","aclImdb/train/unsup/48508_0.txt\n","aclImdb/train/unsup/48507_0.txt\n","aclImdb/train/unsup/48506_0.txt\n","aclImdb/train/unsup/48505_0.txt\n","aclImdb/train/unsup/48504_0.txt\n","aclImdb/train/unsup/48503_0.txt\n","aclImdb/train/unsup/48502_0.txt\n","aclImdb/train/unsup/48501_0.txt\n","aclImdb/train/unsup/48500_0.txt\n","aclImdb/train/unsup/48499_0.txt\n","aclImdb/train/unsup/48498_0.txt\n","aclImdb/train/unsup/48497_0.txt\n","aclImdb/train/unsup/48496_0.txt\n","aclImdb/train/unsup/48495_0.txt\n","aclImdb/train/unsup/48494_0.txt\n","aclImdb/train/unsup/48493_0.txt\n","aclImdb/train/unsup/48492_0.txt\n","aclImdb/train/unsup/48491_0.txt\n","aclImdb/train/unsup/48490_0.txt\n","aclImdb/train/unsup/48489_0.txt\n","aclImdb/train/unsup/48488_0.txt\n","aclImdb/train/unsup/48487_0.txt\n","aclImdb/train/unsup/48486_0.txt\n","aclImdb/train/unsup/48485_0.txt\n","aclImdb/train/unsup/48484_0.txt\n","aclImdb/train/unsup/48483_0.txt\n","aclImdb/train/unsup/48482_0.txt\n","aclImdb/train/unsup/48481_0.txt\n","aclImdb/train/unsup/48480_0.txt\n","aclImdb/train/unsup/48479_0.txt\n","aclImdb/train/unsup/48478_0.txt\n","aclImdb/train/unsup/48477_0.txt\n","aclImdb/train/unsup/48476_0.txt\n","aclImdb/train/unsup/48475_0.txt\n","aclImdb/train/unsup/48474_0.txt\n","aclImdb/train/unsup/48473_0.txt\n","aclImdb/train/unsup/48472_0.txt\n","aclImdb/train/unsup/48471_0.txt\n","aclImdb/train/unsup/48470_0.txt\n","aclImdb/train/unsup/48469_0.txt\n","aclImdb/train/unsup/48468_0.txt\n","aclImdb/train/unsup/48467_0.txt\n","aclImdb/train/unsup/48466_0.txt\n","aclImdb/train/unsup/48465_0.txt\n","aclImdb/train/unsup/48464_0.txt\n","aclImdb/train/unsup/48463_0.txt\n","aclImdb/train/unsup/48462_0.txt\n","aclImdb/train/unsup/48461_0.txt\n","aclImdb/train/unsup/48460_0.txt\n","aclImdb/train/unsup/48459_0.txt\n","aclImdb/train/unsup/48458_0.txt\n","aclImdb/train/unsup/48457_0.txt\n","aclImdb/train/unsup/48456_0.txt\n","aclImdb/train/unsup/48455_0.txt\n","aclImdb/train/unsup/48454_0.txt\n","aclImdb/train/unsup/48453_0.txt\n","aclImdb/train/unsup/48452_0.txt\n","aclImdb/train/unsup/48451_0.txt\n","aclImdb/train/unsup/48450_0.txt\n","aclImdb/train/unsup/48449_0.txt\n","aclImdb/train/unsup/48448_0.txt\n","aclImdb/train/unsup/48447_0.txt\n","aclImdb/train/unsup/48446_0.txt\n","aclImdb/train/unsup/48445_0.txt\n","aclImdb/train/unsup/48444_0.txt\n","aclImdb/train/unsup/48443_0.txt\n","aclImdb/train/unsup/48442_0.txt\n","aclImdb/train/unsup/48441_0.txt\n","aclImdb/train/unsup/48440_0.txt\n","aclImdb/train/unsup/48439_0.txt\n","aclImdb/train/unsup/48438_0.txt\n","aclImdb/train/unsup/48437_0.txt\n","aclImdb/train/unsup/48436_0.txt\n","aclImdb/train/unsup/48435_0.txt\n","aclImdb/train/unsup/48434_0.txt\n","aclImdb/train/unsup/48433_0.txt\n","aclImdb/train/unsup/48432_0.txt\n","aclImdb/train/unsup/48431_0.txt\n","aclImdb/train/unsup/48430_0.txt\n","aclImdb/train/unsup/48429_0.txt\n","aclImdb/train/unsup/48428_0.txt\n","aclImdb/train/unsup/48427_0.txt\n","aclImdb/train/unsup/48426_0.txt\n","aclImdb/train/unsup/48425_0.txt\n","aclImdb/train/unsup/48424_0.txt\n","aclImdb/train/unsup/48423_0.txt\n","aclImdb/train/unsup/48422_0.txt\n","aclImdb/train/unsup/48421_0.txt\n","aclImdb/train/unsup/48420_0.txt\n","aclImdb/train/unsup/48419_0.txt\n","aclImdb/train/unsup/48418_0.txt\n","aclImdb/train/unsup/48417_0.txt\n","aclImdb/train/unsup/48416_0.txt\n","aclImdb/train/unsup/48415_0.txt\n","aclImdb/train/unsup/48414_0.txt\n","aclImdb/train/unsup/48413_0.txt\n","aclImdb/train/unsup/48412_0.txt\n","aclImdb/train/unsup/48411_0.txt\n","aclImdb/train/unsup/48410_0.txt\n","aclImdb/train/unsup/48409_0.txt\n","aclImdb/train/unsup/48408_0.txt\n","aclImdb/train/unsup/48407_0.txt\n","aclImdb/train/unsup/48406_0.txt\n","aclImdb/train/unsup/48405_0.txt\n","aclImdb/train/unsup/48404_0.txt\n","aclImdb/train/unsup/48403_0.txt\n","aclImdb/train/unsup/48402_0.txt\n","aclImdb/train/unsup/48401_0.txt\n","aclImdb/train/unsup/48400_0.txt\n","aclImdb/train/unsup/48399_0.txt\n","aclImdb/train/unsup/48398_0.txt\n","aclImdb/train/unsup/48397_0.txt\n","aclImdb/train/unsup/48396_0.txt\n","aclImdb/train/unsup/48395_0.txt\n","aclImdb/train/unsup/48394_0.txt\n","aclImdb/train/unsup/48393_0.txt\n","aclImdb/train/unsup/48392_0.txt\n","aclImdb/train/unsup/48391_0.txt\n","aclImdb/train/unsup/48390_0.txt\n","aclImdb/train/unsup/48389_0.txt\n","aclImdb/train/unsup/48388_0.txt\n","aclImdb/train/unsup/48387_0.txt\n","aclImdb/train/unsup/48386_0.txt\n","aclImdb/train/unsup/48385_0.txt\n","aclImdb/train/unsup/48384_0.txt\n","aclImdb/train/unsup/48639_0.txt\n","aclImdb/train/unsup/48638_0.txt\n","aclImdb/train/unsup/48637_0.txt\n","aclImdb/train/unsup/48636_0.txt\n","aclImdb/train/unsup/48635_0.txt\n","aclImdb/train/unsup/48634_0.txt\n","aclImdb/train/unsup/48633_0.txt\n","aclImdb/train/unsup/48632_0.txt\n","aclImdb/train/unsup/48631_0.txt\n","aclImdb/train/unsup/48630_0.txt\n","aclImdb/train/unsup/48629_0.txt\n","aclImdb/train/unsup/48628_0.txt\n","aclImdb/train/unsup/48627_0.txt\n","aclImdb/train/unsup/48626_0.txt\n","aclImdb/train/unsup/48625_0.txt\n","aclImdb/train/unsup/48624_0.txt\n","aclImdb/train/unsup/48623_0.txt\n","aclImdb/train/unsup/48622_0.txt\n","aclImdb/train/unsup/48621_0.txt\n","aclImdb/train/unsup/48620_0.txt\n","aclImdb/train/unsup/48619_0.txt\n","aclImdb/train/unsup/48618_0.txt\n","aclImdb/train/unsup/48617_0.txt\n","aclImdb/train/unsup/48616_0.txt\n","aclImdb/train/unsup/48615_0.txt\n","aclImdb/train/unsup/48614_0.txt\n","aclImdb/train/unsup/48613_0.txt\n","aclImdb/train/unsup/48612_0.txt\n","aclImdb/train/unsup/48611_0.txt\n","aclImdb/train/unsup/48610_0.txt\n","aclImdb/train/unsup/48609_0.txt\n","aclImdb/train/unsup/48608_0.txt\n","aclImdb/train/unsup/48607_0.txt\n","aclImdb/train/unsup/48606_0.txt\n","aclImdb/train/unsup/48605_0.txt\n","aclImdb/train/unsup/48604_0.txt\n","aclImdb/train/unsup/48603_0.txt\n","aclImdb/train/unsup/48602_0.txt\n","aclImdb/train/unsup/48601_0.txt\n","aclImdb/train/unsup/48600_0.txt\n","aclImdb/train/unsup/48599_0.txt\n","aclImdb/train/unsup/48598_0.txt\n","aclImdb/train/unsup/48597_0.txt\n","aclImdb/train/unsup/48596_0.txt\n","aclImdb/train/unsup/48595_0.txt\n","aclImdb/train/unsup/48594_0.txt\n","aclImdb/train/unsup/48593_0.txt\n","aclImdb/train/unsup/48592_0.txt\n","aclImdb/train/unsup/48591_0.txt\n","aclImdb/train/unsup/48590_0.txt\n","aclImdb/train/unsup/48589_0.txt\n","aclImdb/train/unsup/48588_0.txt\n","aclImdb/train/unsup/48587_0.txt\n","aclImdb/train/unsup/48586_0.txt\n","aclImdb/train/unsup/48585_0.txt\n","aclImdb/train/unsup/48584_0.txt\n","aclImdb/train/unsup/48583_0.txt\n","aclImdb/train/unsup/48582_0.txt\n","aclImdb/train/unsup/48581_0.txt\n","aclImdb/train/unsup/48580_0.txt\n","aclImdb/train/unsup/48579_0.txt\n","aclImdb/train/unsup/48578_0.txt\n","aclImdb/train/unsup/48577_0.txt\n","aclImdb/train/unsup/48576_0.txt\n","aclImdb/train/unsup/48575_0.txt\n","aclImdb/train/unsup/48574_0.txt\n","aclImdb/train/unsup/48573_0.txt\n","aclImdb/train/unsup/48572_0.txt\n","aclImdb/train/unsup/48571_0.txt\n","aclImdb/train/unsup/48570_0.txt\n","aclImdb/train/unsup/48569_0.txt\n","aclImdb/train/unsup/48568_0.txt\n","aclImdb/train/unsup/48567_0.txt\n","aclImdb/train/unsup/48566_0.txt\n","aclImdb/train/unsup/48565_0.txt\n","aclImdb/train/unsup/48564_0.txt\n","aclImdb/train/unsup/48563_0.txt\n","aclImdb/train/unsup/48562_0.txt\n","aclImdb/train/unsup/48561_0.txt\n","aclImdb/train/unsup/48560_0.txt\n","aclImdb/train/unsup/48559_0.txt\n","aclImdb/train/unsup/48558_0.txt\n","aclImdb/train/unsup/48557_0.txt\n","aclImdb/train/unsup/48556_0.txt\n","aclImdb/train/unsup/48555_0.txt\n","aclImdb/train/unsup/48554_0.txt\n","aclImdb/train/unsup/48553_0.txt\n","aclImdb/train/unsup/48552_0.txt\n","aclImdb/train/unsup/48551_0.txt\n","aclImdb/train/unsup/48550_0.txt\n","aclImdb/train/unsup/48549_0.txt\n","aclImdb/train/unsup/48548_0.txt\n","aclImdb/train/unsup/48547_0.txt\n","aclImdb/train/unsup/48546_0.txt\n","aclImdb/train/unsup/48545_0.txt\n","aclImdb/train/unsup/48544_0.txt\n","aclImdb/train/unsup/48543_0.txt\n","aclImdb/train/unsup/48542_0.txt\n","aclImdb/train/unsup/48541_0.txt\n","aclImdb/train/unsup/48540_0.txt\n","aclImdb/train/unsup/48539_0.txt\n","aclImdb/train/unsup/48538_0.txt\n","aclImdb/train/unsup/48537_0.txt\n","aclImdb/train/unsup/48536_0.txt\n","aclImdb/train/unsup/48535_0.txt\n","aclImdb/train/unsup/48534_0.txt\n","aclImdb/train/unsup/48533_0.txt\n","aclImdb/train/unsup/48532_0.txt\n","aclImdb/train/unsup/48531_0.txt\n","aclImdb/train/unsup/48530_0.txt\n","aclImdb/train/unsup/48529_0.txt\n","aclImdb/train/unsup/48528_0.txt\n","aclImdb/train/unsup/48527_0.txt\n","aclImdb/train/unsup/48526_0.txt\n","aclImdb/train/unsup/48525_0.txt\n","aclImdb/train/unsup/48524_0.txt\n","aclImdb/train/unsup/48523_0.txt\n","aclImdb/train/unsup/48522_0.txt\n","aclImdb/train/unsup/48521_0.txt\n","aclImdb/train/unsup/48520_0.txt\n","aclImdb/train/unsup/48519_0.txt\n","aclImdb/train/unsup/48518_0.txt\n","aclImdb/train/unsup/48517_0.txt\n","aclImdb/train/unsup/48516_0.txt\n","aclImdb/train/unsup/48515_0.txt\n","aclImdb/train/unsup/48514_0.txt\n","aclImdb/train/unsup/48513_0.txt\n","aclImdb/train/unsup/48512_0.txt\n","aclImdb/train/unsup/48767_0.txt\n","aclImdb/train/unsup/48766_0.txt\n","aclImdb/train/unsup/48765_0.txt\n","aclImdb/train/unsup/48764_0.txt\n","aclImdb/train/unsup/48763_0.txt\n","aclImdb/train/unsup/48762_0.txt\n","aclImdb/train/unsup/48761_0.txt\n","aclImdb/train/unsup/48760_0.txt\n","aclImdb/train/unsup/48759_0.txt\n","aclImdb/train/unsup/48758_0.txt\n","aclImdb/train/unsup/48757_0.txt\n","aclImdb/train/unsup/48756_0.txt\n","aclImdb/train/unsup/48755_0.txt\n","aclImdb/train/unsup/48754_0.txt\n","aclImdb/train/unsup/48753_0.txt\n","aclImdb/train/unsup/48752_0.txt\n","aclImdb/train/unsup/48751_0.txt\n","aclImdb/train/unsup/48750_0.txt\n","aclImdb/train/unsup/48749_0.txt\n","aclImdb/train/unsup/48748_0.txt\n","aclImdb/train/unsup/48747_0.txt\n","aclImdb/train/unsup/48746_0.txt\n","aclImdb/train/unsup/48745_0.txt\n","aclImdb/train/unsup/48744_0.txt\n","aclImdb/train/unsup/48743_0.txt\n","aclImdb/train/unsup/48742_0.txt\n","aclImdb/train/unsup/48741_0.txt\n","aclImdb/train/unsup/48740_0.txt\n","aclImdb/train/unsup/48739_0.txt\n","aclImdb/train/unsup/48738_0.txt\n","aclImdb/train/unsup/48737_0.txt\n","aclImdb/train/unsup/48736_0.txt\n","aclImdb/train/unsup/48735_0.txt\n","aclImdb/train/unsup/48734_0.txt\n","aclImdb/train/unsup/48733_0.txt\n","aclImdb/train/unsup/48732_0.txt\n","aclImdb/train/unsup/48731_0.txt\n","aclImdb/train/unsup/48730_0.txt\n","aclImdb/train/unsup/48729_0.txt\n","aclImdb/train/unsup/48728_0.txt\n","aclImdb/train/unsup/48727_0.txt\n","aclImdb/train/unsup/48726_0.txt\n","aclImdb/train/unsup/48725_0.txt\n","aclImdb/train/unsup/48724_0.txt\n","aclImdb/train/unsup/48723_0.txt\n","aclImdb/train/unsup/48722_0.txt\n","aclImdb/train/unsup/48721_0.txt\n","aclImdb/train/unsup/48720_0.txt\n","aclImdb/train/unsup/48719_0.txt\n","aclImdb/train/unsup/48718_0.txt\n","aclImdb/train/unsup/48717_0.txt\n","aclImdb/train/unsup/48716_0.txt\n","aclImdb/train/unsup/48715_0.txt\n","aclImdb/train/unsup/48714_0.txt\n","aclImdb/train/unsup/48713_0.txt\n","aclImdb/train/unsup/48712_0.txt\n","aclImdb/train/unsup/48711_0.txt\n","aclImdb/train/unsup/48710_0.txt\n","aclImdb/train/unsup/48709_0.txt\n","aclImdb/train/unsup/48708_0.txt\n","aclImdb/train/unsup/48707_0.txt\n","aclImdb/train/unsup/48706_0.txt\n","aclImdb/train/unsup/48705_0.txt\n","aclImdb/train/unsup/48704_0.txt\n","aclImdb/train/unsup/48703_0.txt\n","aclImdb/train/unsup/48702_0.txt\n","aclImdb/train/unsup/48701_0.txt\n","aclImdb/train/unsup/48700_0.txt\n","aclImdb/train/unsup/48699_0.txt\n","aclImdb/train/unsup/48698_0.txt\n","aclImdb/train/unsup/48697_0.txt\n","aclImdb/train/unsup/48696_0.txt\n","aclImdb/train/unsup/48695_0.txt\n","aclImdb/train/unsup/48694_0.txt\n","aclImdb/train/unsup/48693_0.txt\n","aclImdb/train/unsup/48692_0.txt\n","aclImdb/train/unsup/48691_0.txt\n","aclImdb/train/unsup/48690_0.txt\n","aclImdb/train/unsup/48689_0.txt\n","aclImdb/train/unsup/48688_0.txt\n","aclImdb/train/unsup/48687_0.txt\n","aclImdb/train/unsup/48686_0.txt\n","aclImdb/train/unsup/48685_0.txt\n","aclImdb/train/unsup/48684_0.txt\n","aclImdb/train/unsup/48683_0.txt\n","aclImdb/train/unsup/48682_0.txt\n","aclImdb/train/unsup/48681_0.txt\n","aclImdb/train/unsup/48680_0.txt\n","aclImdb/train/unsup/48679_0.txt\n","aclImdb/train/unsup/48678_0.txt\n","aclImdb/train/unsup/48677_0.txt\n","aclImdb/train/unsup/48676_0.txt\n","aclImdb/train/unsup/48675_0.txt\n","aclImdb/train/unsup/48674_0.txt\n","aclImdb/train/unsup/48673_0.txt\n","aclImdb/train/unsup/48672_0.txt\n","aclImdb/train/unsup/48671_0.txt\n","aclImdb/train/unsup/48670_0.txt\n","aclImdb/train/unsup/48669_0.txt\n","aclImdb/train/unsup/48668_0.txt\n","aclImdb/train/unsup/48667_0.txt\n","aclImdb/train/unsup/48666_0.txt\n","aclImdb/train/unsup/48665_0.txt\n","aclImdb/train/unsup/48664_0.txt\n","aclImdb/train/unsup/48663_0.txt\n","aclImdb/train/unsup/48662_0.txt\n","aclImdb/train/unsup/48661_0.txt\n","aclImdb/train/unsup/48660_0.txt\n","aclImdb/train/unsup/48659_0.txt\n","aclImdb/train/unsup/48658_0.txt\n","aclImdb/train/unsup/48657_0.txt\n","aclImdb/train/unsup/48656_0.txt\n","aclImdb/train/unsup/48655_0.txt\n","aclImdb/train/unsup/48654_0.txt\n","aclImdb/train/unsup/48653_0.txt\n","aclImdb/train/unsup/48652_0.txt\n","aclImdb/train/unsup/48651_0.txt\n","aclImdb/train/unsup/48650_0.txt\n","aclImdb/train/unsup/48649_0.txt\n","aclImdb/train/unsup/48648_0.txt\n","aclImdb/train/unsup/48647_0.txt\n","aclImdb/train/unsup/48646_0.txt\n","aclImdb/train/unsup/48645_0.txt\n","aclImdb/train/unsup/48644_0.txt\n","aclImdb/train/unsup/48643_0.txt\n","aclImdb/train/unsup/48642_0.txt\n","aclImdb/train/unsup/48641_0.txt\n","aclImdb/train/unsup/48640_0.txt\n","aclImdb/train/unsup/48895_0.txt\n","aclImdb/train/unsup/48894_0.txt\n","aclImdb/train/unsup/48893_0.txt\n","aclImdb/train/unsup/48892_0.txt\n","aclImdb/train/unsup/48891_0.txt\n","aclImdb/train/unsup/48890_0.txt\n","aclImdb/train/unsup/48889_0.txt\n","aclImdb/train/unsup/48888_0.txt\n","aclImdb/train/unsup/48887_0.txt\n","aclImdb/train/unsup/48886_0.txt\n","aclImdb/train/unsup/48885_0.txt\n","aclImdb/train/unsup/48884_0.txt\n","aclImdb/train/unsup/48883_0.txt\n","aclImdb/train/unsup/48882_0.txt\n","aclImdb/train/unsup/48881_0.txt\n","aclImdb/train/unsup/48880_0.txt\n","aclImdb/train/unsup/48879_0.txt\n","aclImdb/train/unsup/48878_0.txt\n","aclImdb/train/unsup/48877_0.txt\n","aclImdb/train/unsup/48876_0.txt\n","aclImdb/train/unsup/48875_0.txt\n","aclImdb/train/unsup/48874_0.txt\n","aclImdb/train/unsup/48873_0.txt\n","aclImdb/train/unsup/48872_0.txt\n","aclImdb/train/unsup/48871_0.txt\n","aclImdb/train/unsup/48870_0.txt\n","aclImdb/train/unsup/48869_0.txt\n","aclImdb/train/unsup/48868_0.txt\n","aclImdb/train/unsup/48867_0.txt\n","aclImdb/train/unsup/48866_0.txt\n","aclImdb/train/unsup/48865_0.txt\n","aclImdb/train/unsup/48864_0.txt\n","aclImdb/train/unsup/48863_0.txt\n","aclImdb/train/unsup/48862_0.txt\n","aclImdb/train/unsup/48861_0.txt\n","aclImdb/train/unsup/48860_0.txt\n","aclImdb/train/unsup/48859_0.txt\n","aclImdb/train/unsup/48858_0.txt\n","aclImdb/train/unsup/48857_0.txt\n","aclImdb/train/unsup/48856_0.txt\n","aclImdb/train/unsup/48855_0.txt\n","aclImdb/train/unsup/48854_0.txt\n","aclImdb/train/unsup/48853_0.txt\n","aclImdb/train/unsup/48852_0.txt\n","aclImdb/train/unsup/48851_0.txt\n","aclImdb/train/unsup/48850_0.txt\n","aclImdb/train/unsup/48849_0.txt\n","aclImdb/train/unsup/48848_0.txt\n","aclImdb/train/unsup/48847_0.txt\n","aclImdb/train/unsup/48846_0.txt\n","aclImdb/train/unsup/48845_0.txt\n","aclImdb/train/unsup/48844_0.txt\n","aclImdb/train/unsup/48843_0.txt\n","aclImdb/train/unsup/48842_0.txt\n","aclImdb/train/unsup/48841_0.txt\n","aclImdb/train/unsup/48840_0.txt\n","aclImdb/train/unsup/48839_0.txt\n","aclImdb/train/unsup/48838_0.txt\n","aclImdb/train/unsup/48837_0.txt\n","aclImdb/train/unsup/48836_0.txt\n","aclImdb/train/unsup/48835_0.txt\n","aclImdb/train/unsup/48834_0.txt\n","aclImdb/train/unsup/48833_0.txt\n","aclImdb/train/unsup/48832_0.txt\n","aclImdb/train/unsup/48831_0.txt\n","aclImdb/train/unsup/48830_0.txt\n","aclImdb/train/unsup/48829_0.txt\n","aclImdb/train/unsup/48828_0.txt\n","aclImdb/train/unsup/48827_0.txt\n","aclImdb/train/unsup/48826_0.txt\n","aclImdb/train/unsup/48825_0.txt\n","aclImdb/train/unsup/48824_0.txt\n","aclImdb/train/unsup/48823_0.txt\n","aclImdb/train/unsup/48822_0.txt\n","aclImdb/train/unsup/48821_0.txt\n","aclImdb/train/unsup/48820_0.txt\n","aclImdb/train/unsup/48819_0.txt\n","aclImdb/train/unsup/48818_0.txt\n","aclImdb/train/unsup/48817_0.txt\n","aclImdb/train/unsup/48816_0.txt\n","aclImdb/train/unsup/48815_0.txt\n","aclImdb/train/unsup/48814_0.txt\n","aclImdb/train/unsup/48813_0.txt\n","aclImdb/train/unsup/48812_0.txt\n","aclImdb/train/unsup/48811_0.txt\n","aclImdb/train/unsup/48810_0.txt\n","aclImdb/train/unsup/48809_0.txt\n","aclImdb/train/unsup/48808_0.txt\n","aclImdb/train/unsup/48807_0.txt\n","aclImdb/train/unsup/48806_0.txt\n","aclImdb/train/unsup/48805_0.txt\n","aclImdb/train/unsup/48804_0.txt\n","aclImdb/train/unsup/48803_0.txt\n","aclImdb/train/unsup/48802_0.txt\n","aclImdb/train/unsup/48801_0.txt\n","aclImdb/train/unsup/48800_0.txt\n","aclImdb/train/unsup/48799_0.txt\n","aclImdb/train/unsup/48798_0.txt\n","aclImdb/train/unsup/48797_0.txt\n","aclImdb/train/unsup/48796_0.txt\n","aclImdb/train/unsup/48795_0.txt\n","aclImdb/train/unsup/48794_0.txt\n","aclImdb/train/unsup/48793_0.txt\n","aclImdb/train/unsup/48792_0.txt\n","aclImdb/train/unsup/48791_0.txt\n","aclImdb/train/unsup/48790_0.txt\n","aclImdb/train/unsup/48789_0.txt\n","aclImdb/train/unsup/48788_0.txt\n","aclImdb/train/unsup/48787_0.txt\n","aclImdb/train/unsup/48786_0.txt\n","aclImdb/train/unsup/48785_0.txt\n","aclImdb/train/unsup/48784_0.txt\n","aclImdb/train/unsup/48783_0.txt\n","aclImdb/train/unsup/48782_0.txt\n","aclImdb/train/unsup/48781_0.txt\n","aclImdb/train/unsup/48780_0.txt\n","aclImdb/train/unsup/48779_0.txt\n","aclImdb/train/unsup/48778_0.txt\n","aclImdb/train/unsup/48777_0.txt\n","aclImdb/train/unsup/48776_0.txt\n","aclImdb/train/unsup/48775_0.txt\n","aclImdb/train/unsup/48774_0.txt\n","aclImdb/train/unsup/48773_0.txt\n","aclImdb/train/unsup/48772_0.txt\n","aclImdb/train/unsup/48771_0.txt\n","aclImdb/train/unsup/48770_0.txt\n","aclImdb/train/unsup/48769_0.txt\n","aclImdb/train/unsup/48768_0.txt\n","aclImdb/train/unsup/49023_0.txt\n","aclImdb/train/unsup/49022_0.txt\n","aclImdb/train/unsup/49021_0.txt\n","aclImdb/train/unsup/49020_0.txt\n","aclImdb/train/unsup/49019_0.txt\n","aclImdb/train/unsup/49018_0.txt\n","aclImdb/train/unsup/49017_0.txt\n","aclImdb/train/unsup/49016_0.txt\n","aclImdb/train/unsup/49015_0.txt\n","aclImdb/train/unsup/49014_0.txt\n","aclImdb/train/unsup/49013_0.txt\n","aclImdb/train/unsup/49012_0.txt\n","aclImdb/train/unsup/49011_0.txt\n","aclImdb/train/unsup/49010_0.txt\n","aclImdb/train/unsup/49009_0.txt\n","aclImdb/train/unsup/49008_0.txt\n","aclImdb/train/unsup/49007_0.txt\n","aclImdb/train/unsup/49006_0.txt\n","aclImdb/train/unsup/49005_0.txt\n","aclImdb/train/unsup/49004_0.txt\n","aclImdb/train/unsup/49003_0.txt\n","aclImdb/train/unsup/49002_0.txt\n","aclImdb/train/unsup/49001_0.txt\n","aclImdb/train/unsup/49000_0.txt\n","aclImdb/train/unsup/48999_0.txt\n","aclImdb/train/unsup/48998_0.txt\n","aclImdb/train/unsup/48997_0.txt\n","aclImdb/train/unsup/48996_0.txt\n","aclImdb/train/unsup/48995_0.txt\n","aclImdb/train/unsup/48994_0.txt\n","aclImdb/train/unsup/48993_0.txt\n","aclImdb/train/unsup/48992_0.txt\n","aclImdb/train/unsup/48991_0.txt\n","aclImdb/train/unsup/48990_0.txt\n","aclImdb/train/unsup/48989_0.txt\n","aclImdb/train/unsup/48988_0.txt\n","aclImdb/train/unsup/48987_0.txt\n","aclImdb/train/unsup/48986_0.txt\n","aclImdb/train/unsup/48985_0.txt\n","aclImdb/train/unsup/48984_0.txt\n","aclImdb/train/unsup/48983_0.txt\n","aclImdb/train/unsup/48982_0.txt\n","aclImdb/train/unsup/48981_0.txt\n","aclImdb/train/unsup/48980_0.txt\n","aclImdb/train/unsup/48979_0.txt\n","aclImdb/train/unsup/48978_0.txt\n","aclImdb/train/unsup/48977_0.txt\n","aclImdb/train/unsup/48976_0.txt\n","aclImdb/train/unsup/48975_0.txt\n","aclImdb/train/unsup/48974_0.txt\n","aclImdb/train/unsup/48973_0.txt\n","aclImdb/train/unsup/48972_0.txt\n","aclImdb/train/unsup/48971_0.txt\n","aclImdb/train/unsup/48970_0.txt\n","aclImdb/train/unsup/48969_0.txt\n","aclImdb/train/unsup/48968_0.txt\n","aclImdb/train/unsup/48967_0.txt\n","aclImdb/train/unsup/48966_0.txt\n","aclImdb/train/unsup/48965_0.txt\n","aclImdb/train/unsup/48964_0.txt\n","aclImdb/train/unsup/48963_0.txt\n","aclImdb/train/unsup/48962_0.txt\n","aclImdb/train/unsup/48961_0.txt\n","aclImdb/train/unsup/48960_0.txt\n","aclImdb/train/unsup/48959_0.txt\n","aclImdb/train/unsup/48958_0.txt\n","aclImdb/train/unsup/48957_0.txt\n","aclImdb/train/unsup/48956_0.txt\n","aclImdb/train/unsup/48955_0.txt\n","aclImdb/train/unsup/48954_0.txt\n","aclImdb/train/unsup/48953_0.txt\n","aclImdb/train/unsup/48952_0.txt\n","aclImdb/train/unsup/48951_0.txt\n","aclImdb/train/unsup/48950_0.txt\n","aclImdb/train/unsup/48949_0.txt\n","aclImdb/train/unsup/48948_0.txt\n","aclImdb/train/unsup/48947_0.txt\n","aclImdb/train/unsup/48946_0.txt\n","aclImdb/train/unsup/48945_0.txt\n","aclImdb/train/unsup/48944_0.txt\n","aclImdb/train/unsup/48943_0.txt\n","aclImdb/train/unsup/48942_0.txt\n","aclImdb/train/unsup/48941_0.txt\n","aclImdb/train/unsup/48940_0.txt\n","aclImdb/train/unsup/48939_0.txt\n","aclImdb/train/unsup/48938_0.txt\n","aclImdb/train/unsup/48937_0.txt\n","aclImdb/train/unsup/48936_0.txt\n","aclImdb/train/unsup/48935_0.txt\n","aclImdb/train/unsup/48934_0.txt\n","aclImdb/train/unsup/48933_0.txt\n","aclImdb/train/unsup/48932_0.txt\n","aclImdb/train/unsup/48931_0.txt\n","aclImdb/train/unsup/48930_0.txt\n","aclImdb/train/unsup/48929_0.txt\n","aclImdb/train/unsup/48928_0.txt\n","aclImdb/train/unsup/48927_0.txt\n","aclImdb/train/unsup/48926_0.txt\n","aclImdb/train/unsup/48925_0.txt\n","aclImdb/train/unsup/48924_0.txt\n","aclImdb/train/unsup/48923_0.txt\n","aclImdb/train/unsup/48922_0.txt\n","aclImdb/train/unsup/48921_0.txt\n","aclImdb/train/unsup/48920_0.txt\n","aclImdb/train/unsup/48919_0.txt\n","aclImdb/train/unsup/48918_0.txt\n","aclImdb/train/unsup/48917_0.txt\n","aclImdb/train/unsup/48916_0.txt\n","aclImdb/train/unsup/48915_0.txt\n","aclImdb/train/unsup/48914_0.txt\n","aclImdb/train/unsup/48913_0.txt\n","aclImdb/train/unsup/48912_0.txt\n","aclImdb/train/unsup/48911_0.txt\n","aclImdb/train/unsup/48910_0.txt\n","aclImdb/train/unsup/48909_0.txt\n","aclImdb/train/unsup/48908_0.txt\n","aclImdb/train/unsup/48907_0.txt\n","aclImdb/train/unsup/48906_0.txt\n","aclImdb/train/unsup/48905_0.txt\n","aclImdb/train/unsup/48904_0.txt\n","aclImdb/train/unsup/48903_0.txt\n","aclImdb/train/unsup/48902_0.txt\n","aclImdb/train/unsup/48901_0.txt\n","aclImdb/train/unsup/48900_0.txt\n","aclImdb/train/unsup/48899_0.txt\n","aclImdb/train/unsup/48898_0.txt\n","aclImdb/train/unsup/48897_0.txt\n","aclImdb/train/unsup/48896_0.txt\n","aclImdb/train/unsup/49151_0.txt\n","aclImdb/train/unsup/49150_0.txt\n","aclImdb/train/unsup/49149_0.txt\n","aclImdb/train/unsup/49148_0.txt\n","aclImdb/train/unsup/49147_0.txt\n","aclImdb/train/unsup/49146_0.txt\n","aclImdb/train/unsup/49145_0.txt\n","aclImdb/train/unsup/49144_0.txt\n","aclImdb/train/unsup/49143_0.txt\n","aclImdb/train/unsup/49142_0.txt\n","aclImdb/train/unsup/49141_0.txt\n","aclImdb/train/unsup/49140_0.txt\n","aclImdb/train/unsup/49139_0.txt\n","aclImdb/train/unsup/49138_0.txt\n","aclImdb/train/unsup/49137_0.txt\n","aclImdb/train/unsup/49136_0.txt\n","aclImdb/train/unsup/49135_0.txt\n","aclImdb/train/unsup/49134_0.txt\n","aclImdb/train/unsup/49133_0.txt\n","aclImdb/train/unsup/49132_0.txt\n","aclImdb/train/unsup/49131_0.txt\n","aclImdb/train/unsup/49130_0.txt\n","aclImdb/train/unsup/49129_0.txt\n","aclImdb/train/unsup/49128_0.txt\n","aclImdb/train/unsup/49127_0.txt\n","aclImdb/train/unsup/49126_0.txt\n","aclImdb/train/unsup/49125_0.txt\n","aclImdb/train/unsup/49124_0.txt\n","aclImdb/train/unsup/49123_0.txt\n","aclImdb/train/unsup/49122_0.txt\n","aclImdb/train/unsup/49121_0.txt\n","aclImdb/train/unsup/49120_0.txt\n","aclImdb/train/unsup/49119_0.txt\n","aclImdb/train/unsup/49118_0.txt\n","aclImdb/train/unsup/49117_0.txt\n","aclImdb/train/unsup/49116_0.txt\n","aclImdb/train/unsup/49115_0.txt\n","aclImdb/train/unsup/49114_0.txt\n","aclImdb/train/unsup/49113_0.txt\n","aclImdb/train/unsup/49112_0.txt\n","aclImdb/train/unsup/49111_0.txt\n","aclImdb/train/unsup/49110_0.txt\n","aclImdb/train/unsup/49109_0.txt\n","aclImdb/train/unsup/49108_0.txt\n","aclImdb/train/unsup/49107_0.txt\n","aclImdb/train/unsup/49106_0.txt\n","aclImdb/train/unsup/49105_0.txt\n","aclImdb/train/unsup/49104_0.txt\n","aclImdb/train/unsup/49103_0.txt\n","aclImdb/train/unsup/49102_0.txt\n","aclImdb/train/unsup/49101_0.txt\n","aclImdb/train/unsup/49100_0.txt\n","aclImdb/train/unsup/49099_0.txt\n","aclImdb/train/unsup/49098_0.txt\n","aclImdb/train/unsup/49097_0.txt\n","aclImdb/train/unsup/49096_0.txt\n","aclImdb/train/unsup/49095_0.txt\n","aclImdb/train/unsup/49094_0.txt\n","aclImdb/train/unsup/49093_0.txt\n","aclImdb/train/unsup/49092_0.txt\n","aclImdb/train/unsup/49091_0.txt\n","aclImdb/train/unsup/49090_0.txt\n","aclImdb/train/unsup/49089_0.txt\n","aclImdb/train/unsup/49088_0.txt\n","aclImdb/train/unsup/49087_0.txt\n","aclImdb/train/unsup/49086_0.txt\n","aclImdb/train/unsup/49085_0.txt\n","aclImdb/train/unsup/49084_0.txt\n","aclImdb/train/unsup/49083_0.txt\n","aclImdb/train/unsup/49082_0.txt\n","aclImdb/train/unsup/49081_0.txt\n","aclImdb/train/unsup/49080_0.txt\n","aclImdb/train/unsup/49079_0.txt\n","aclImdb/train/unsup/49078_0.txt\n","aclImdb/train/unsup/49077_0.txt\n","aclImdb/train/unsup/49076_0.txt\n","aclImdb/train/unsup/49075_0.txt\n","aclImdb/train/unsup/49074_0.txt\n","aclImdb/train/unsup/49073_0.txt\n","aclImdb/train/unsup/49072_0.txt\n","aclImdb/train/unsup/49071_0.txt\n","aclImdb/train/unsup/49070_0.txt\n","aclImdb/train/unsup/49069_0.txt\n","aclImdb/train/unsup/49068_0.txt\n","aclImdb/train/unsup/49067_0.txt\n","aclImdb/train/unsup/49066_0.txt\n","aclImdb/train/unsup/49065_0.txt\n","aclImdb/train/unsup/49064_0.txt\n","aclImdb/train/unsup/49063_0.txt\n","aclImdb/train/unsup/49062_0.txt\n","aclImdb/train/unsup/49061_0.txt\n","aclImdb/train/unsup/49060_0.txt\n","aclImdb/train/unsup/49059_0.txt\n","aclImdb/train/unsup/49058_0.txt\n","aclImdb/train/unsup/49057_0.txt\n","aclImdb/train/unsup/49056_0.txt\n","aclImdb/train/unsup/49055_0.txt\n","aclImdb/train/unsup/49054_0.txt\n","aclImdb/train/unsup/49053_0.txt\n","aclImdb/train/unsup/49052_0.txt\n","aclImdb/train/unsup/49051_0.txt\n","aclImdb/train/unsup/49050_0.txt\n","aclImdb/train/unsup/49049_0.txt\n","aclImdb/train/unsup/49048_0.txt\n","aclImdb/train/unsup/49047_0.txt\n","aclImdb/train/unsup/49046_0.txt\n","aclImdb/train/unsup/49045_0.txt\n","aclImdb/train/unsup/49044_0.txt\n","aclImdb/train/unsup/49043_0.txt\n","aclImdb/train/unsup/49042_0.txt\n","aclImdb/train/unsup/49041_0.txt\n","aclImdb/train/unsup/49040_0.txt\n","aclImdb/train/unsup/49039_0.txt\n","aclImdb/train/unsup/49038_0.txt\n","aclImdb/train/unsup/49037_0.txt\n","aclImdb/train/unsup/49036_0.txt\n","aclImdb/train/unsup/49035_0.txt\n","aclImdb/train/unsup/49034_0.txt\n","aclImdb/train/unsup/49033_0.txt\n","aclImdb/train/unsup/49032_0.txt\n","aclImdb/train/unsup/49031_0.txt\n","aclImdb/train/unsup/49030_0.txt\n","aclImdb/train/unsup/49029_0.txt\n","aclImdb/train/unsup/49028_0.txt\n","aclImdb/train/unsup/49027_0.txt\n","aclImdb/train/unsup/49026_0.txt\n","aclImdb/train/unsup/49025_0.txt\n","aclImdb/train/unsup/49024_0.txt\n","aclImdb/train/unsup/49279_0.txt\n","aclImdb/train/unsup/49278_0.txt\n","aclImdb/train/unsup/49277_0.txt\n","aclImdb/train/unsup/49276_0.txt\n","aclImdb/train/unsup/49275_0.txt\n","aclImdb/train/unsup/49274_0.txt\n","aclImdb/train/unsup/49273_0.txt\n","aclImdb/train/unsup/49272_0.txt\n","aclImdb/train/unsup/49271_0.txt\n","aclImdb/train/unsup/49270_0.txt\n","aclImdb/train/unsup/49269_0.txt\n","aclImdb/train/unsup/49268_0.txt\n","aclImdb/train/unsup/49267_0.txt\n","aclImdb/train/unsup/49266_0.txt\n","aclImdb/train/unsup/49265_0.txt\n","aclImdb/train/unsup/49264_0.txt\n","aclImdb/train/unsup/49263_0.txt\n","aclImdb/train/unsup/49262_0.txt\n","aclImdb/train/unsup/49261_0.txt\n","aclImdb/train/unsup/49260_0.txt\n","aclImdb/train/unsup/49259_0.txt\n","aclImdb/train/unsup/49258_0.txt\n","aclImdb/train/unsup/49257_0.txt\n","aclImdb/train/unsup/49256_0.txt\n","aclImdb/train/unsup/49255_0.txt\n","aclImdb/train/unsup/49254_0.txt\n","aclImdb/train/unsup/49253_0.txt\n","aclImdb/train/unsup/49252_0.txt\n","aclImdb/train/unsup/49251_0.txt\n","aclImdb/train/unsup/49250_0.txt\n","aclImdb/train/unsup/49249_0.txt\n","aclImdb/train/unsup/49248_0.txt\n","aclImdb/train/unsup/49247_0.txt\n","aclImdb/train/unsup/49246_0.txt\n","aclImdb/train/unsup/49245_0.txt\n","aclImdb/train/unsup/49244_0.txt\n","aclImdb/train/unsup/49243_0.txt\n","aclImdb/train/unsup/49242_0.txt\n","aclImdb/train/unsup/49241_0.txt\n","aclImdb/train/unsup/49240_0.txt\n","aclImdb/train/unsup/49239_0.txt\n","aclImdb/train/unsup/49238_0.txt\n","aclImdb/train/unsup/49237_0.txt\n","aclImdb/train/unsup/49236_0.txt\n","aclImdb/train/unsup/49235_0.txt\n","aclImdb/train/unsup/49234_0.txt\n","aclImdb/train/unsup/49233_0.txt\n","aclImdb/train/unsup/49232_0.txt\n","aclImdb/train/unsup/49231_0.txt\n","aclImdb/train/unsup/49230_0.txt\n","aclImdb/train/unsup/49229_0.txt\n","aclImdb/train/unsup/49228_0.txt\n","aclImdb/train/unsup/49227_0.txt\n","aclImdb/train/unsup/49226_0.txt\n","aclImdb/train/unsup/49225_0.txt\n","aclImdb/train/unsup/49224_0.txt\n","aclImdb/train/unsup/49223_0.txt\n","aclImdb/train/unsup/49222_0.txt\n","aclImdb/train/unsup/49221_0.txt\n","aclImdb/train/unsup/49220_0.txt\n","aclImdb/train/unsup/49219_0.txt\n","aclImdb/train/unsup/49218_0.txt\n","aclImdb/train/unsup/49217_0.txt\n","aclImdb/train/unsup/49216_0.txt\n","aclImdb/train/unsup/49215_0.txt\n","aclImdb/train/unsup/49214_0.txt\n","aclImdb/train/unsup/49213_0.txt\n","aclImdb/train/unsup/49212_0.txt\n","aclImdb/train/unsup/49211_0.txt\n","aclImdb/train/unsup/49210_0.txt\n","aclImdb/train/unsup/49209_0.txt\n","aclImdb/train/unsup/49208_0.txt\n","aclImdb/train/unsup/49207_0.txt\n","aclImdb/train/unsup/49206_0.txt\n","aclImdb/train/unsup/49205_0.txt\n","aclImdb/train/unsup/49204_0.txt\n","aclImdb/train/unsup/49203_0.txt\n","aclImdb/train/unsup/49202_0.txt\n","aclImdb/train/unsup/49201_0.txt\n","aclImdb/train/unsup/49200_0.txt\n","aclImdb/train/unsup/49199_0.txt\n","aclImdb/train/unsup/49198_0.txt\n","aclImdb/train/unsup/49197_0.txt\n","aclImdb/train/unsup/49196_0.txt\n","aclImdb/train/unsup/49195_0.txt\n","aclImdb/train/unsup/49194_0.txt\n","aclImdb/train/unsup/49193_0.txt\n","aclImdb/train/unsup/49192_0.txt\n","aclImdb/train/unsup/49191_0.txt\n","aclImdb/train/unsup/49190_0.txt\n","aclImdb/train/unsup/49189_0.txt\n","aclImdb/train/unsup/49188_0.txt\n","aclImdb/train/unsup/49187_0.txt\n","aclImdb/train/unsup/49186_0.txt\n","aclImdb/train/unsup/49185_0.txt\n","aclImdb/train/unsup/49184_0.txt\n","aclImdb/train/unsup/49183_0.txt\n","aclImdb/train/unsup/49182_0.txt\n","aclImdb/train/unsup/49181_0.txt\n","aclImdb/train/unsup/49180_0.txt\n","aclImdb/train/unsup/49179_0.txt\n","aclImdb/train/unsup/49178_0.txt\n","aclImdb/train/unsup/49177_0.txt\n","aclImdb/train/unsup/49176_0.txt\n","aclImdb/train/unsup/49175_0.txt\n","aclImdb/train/unsup/49174_0.txt\n","aclImdb/train/unsup/49173_0.txt\n","aclImdb/train/unsup/49172_0.txt\n","aclImdb/train/unsup/49171_0.txt\n","aclImdb/train/unsup/49170_0.txt\n","aclImdb/train/unsup/49169_0.txt\n","aclImdb/train/unsup/49168_0.txt\n","aclImdb/train/unsup/49167_0.txt\n","aclImdb/train/unsup/49166_0.txt\n","aclImdb/train/unsup/49165_0.txt\n","aclImdb/train/unsup/49164_0.txt\n","aclImdb/train/unsup/49163_0.txt\n","aclImdb/train/unsup/49162_0.txt\n","aclImdb/train/unsup/49161_0.txt\n","aclImdb/train/unsup/49160_0.txt\n","aclImdb/train/unsup/49159_0.txt\n","aclImdb/train/unsup/49158_0.txt\n","aclImdb/train/unsup/49157_0.txt\n","aclImdb/train/unsup/49156_0.txt\n","aclImdb/train/unsup/49155_0.txt\n","aclImdb/train/unsup/49154_0.txt\n","aclImdb/train/unsup/49153_0.txt\n","aclImdb/train/unsup/49152_0.txt\n","aclImdb/train/unsup/49407_0.txt\n","aclImdb/train/unsup/49406_0.txt\n","aclImdb/train/unsup/49405_0.txt\n","aclImdb/train/unsup/49404_0.txt\n","aclImdb/train/unsup/49403_0.txt\n","aclImdb/train/unsup/49402_0.txt\n","aclImdb/train/unsup/49401_0.txt\n","aclImdb/train/unsup/49400_0.txt\n","aclImdb/train/unsup/49399_0.txt\n","aclImdb/train/unsup/49398_0.txt\n","aclImdb/train/unsup/49397_0.txt\n","aclImdb/train/unsup/49396_0.txt\n","aclImdb/train/unsup/49395_0.txt\n","aclImdb/train/unsup/49394_0.txt\n","aclImdb/train/unsup/49393_0.txt\n","aclImdb/train/unsup/49392_0.txt\n","aclImdb/train/unsup/49391_0.txt\n","aclImdb/train/unsup/49390_0.txt\n","aclImdb/train/unsup/49389_0.txt\n","aclImdb/train/unsup/49388_0.txt\n","aclImdb/train/unsup/49387_0.txt\n","aclImdb/train/unsup/49386_0.txt\n","aclImdb/train/unsup/49385_0.txt\n","aclImdb/train/unsup/49384_0.txt\n","aclImdb/train/unsup/49383_0.txt\n","aclImdb/train/unsup/49382_0.txt\n","aclImdb/train/unsup/49381_0.txt\n","aclImdb/train/unsup/49380_0.txt\n","aclImdb/train/unsup/49379_0.txt\n","aclImdb/train/unsup/49378_0.txt\n","aclImdb/train/unsup/49377_0.txt\n","aclImdb/train/unsup/49376_0.txt\n","aclImdb/train/unsup/49375_0.txt\n","aclImdb/train/unsup/49374_0.txt\n","aclImdb/train/unsup/49373_0.txt\n","aclImdb/train/unsup/49372_0.txt\n","aclImdb/train/unsup/49371_0.txt\n","aclImdb/train/unsup/49370_0.txt\n","aclImdb/train/unsup/49369_0.txt\n","aclImdb/train/unsup/49368_0.txt\n","aclImdb/train/unsup/49367_0.txt\n","aclImdb/train/unsup/49366_0.txt\n","aclImdb/train/unsup/49365_0.txt\n","aclImdb/train/unsup/49364_0.txt\n","aclImdb/train/unsup/49363_0.txt\n","aclImdb/train/unsup/49362_0.txt\n","aclImdb/train/unsup/49361_0.txt\n","aclImdb/train/unsup/49360_0.txt\n","aclImdb/train/unsup/49359_0.txt\n","aclImdb/train/unsup/49358_0.txt\n","aclImdb/train/unsup/49357_0.txt\n","aclImdb/train/unsup/49356_0.txt\n","aclImdb/train/unsup/49355_0.txt\n","aclImdb/train/unsup/49354_0.txt\n","aclImdb/train/unsup/49353_0.txt\n","aclImdb/train/unsup/49352_0.txt\n","aclImdb/train/unsup/49351_0.txt\n","aclImdb/train/unsup/49350_0.txt\n","aclImdb/train/unsup/49349_0.txt\n","aclImdb/train/unsup/49348_0.txt\n","aclImdb/train/unsup/49347_0.txt\n","aclImdb/train/unsup/49346_0.txt\n","aclImdb/train/unsup/49345_0.txt\n","aclImdb/train/unsup/49344_0.txt\n","aclImdb/train/unsup/49343_0.txt\n","aclImdb/train/unsup/49342_0.txt\n","aclImdb/train/unsup/49341_0.txt\n","aclImdb/train/unsup/49340_0.txt\n","aclImdb/train/unsup/49339_0.txt\n","aclImdb/train/unsup/49338_0.txt\n","aclImdb/train/unsup/49337_0.txt\n","aclImdb/train/unsup/49336_0.txt\n","aclImdb/train/unsup/49335_0.txt\n","aclImdb/train/unsup/49334_0.txt\n","aclImdb/train/unsup/49333_0.txt\n","aclImdb/train/unsup/49332_0.txt\n","aclImdb/train/unsup/49331_0.txt\n","aclImdb/train/unsup/49330_0.txt\n","aclImdb/train/unsup/49329_0.txt\n","aclImdb/train/unsup/49328_0.txt\n","aclImdb/train/unsup/49327_0.txt\n","aclImdb/train/unsup/49326_0.txt\n","aclImdb/train/unsup/49325_0.txt\n","aclImdb/train/unsup/49324_0.txt\n","aclImdb/train/unsup/49323_0.txt\n","aclImdb/train/unsup/49322_0.txt\n","aclImdb/train/unsup/49321_0.txt\n","aclImdb/train/unsup/49320_0.txt\n","aclImdb/train/unsup/49319_0.txt\n","aclImdb/train/unsup/49318_0.txt\n","aclImdb/train/unsup/49317_0.txt\n","aclImdb/train/unsup/49316_0.txt\n","aclImdb/train/unsup/49315_0.txt\n","aclImdb/train/unsup/49314_0.txt\n","aclImdb/train/unsup/49313_0.txt\n","aclImdb/train/unsup/49312_0.txt\n","aclImdb/train/unsup/49311_0.txt\n","aclImdb/train/unsup/49310_0.txt\n","aclImdb/train/unsup/49309_0.txt\n","aclImdb/train/unsup/49308_0.txt\n","aclImdb/train/unsup/49307_0.txt\n","aclImdb/train/unsup/49306_0.txt\n","aclImdb/train/unsup/49305_0.txt\n","aclImdb/train/unsup/49304_0.txt\n","aclImdb/train/unsup/49303_0.txt\n","aclImdb/train/unsup/49302_0.txt\n","aclImdb/train/unsup/49301_0.txt\n","aclImdb/train/unsup/49300_0.txt\n","aclImdb/train/unsup/49299_0.txt\n","aclImdb/train/unsup/49298_0.txt\n","aclImdb/train/unsup/49297_0.txt\n","aclImdb/train/unsup/49296_0.txt\n","aclImdb/train/unsup/49295_0.txt\n","aclImdb/train/unsup/49294_0.txt\n","aclImdb/train/unsup/49293_0.txt\n","aclImdb/train/unsup/49292_0.txt\n","aclImdb/train/unsup/49291_0.txt\n","aclImdb/train/unsup/49290_0.txt\n","aclImdb/train/unsup/49289_0.txt\n","aclImdb/train/unsup/49288_0.txt\n","aclImdb/train/unsup/49287_0.txt\n","aclImdb/train/unsup/49286_0.txt\n","aclImdb/train/unsup/49285_0.txt\n","aclImdb/train/unsup/49284_0.txt\n","aclImdb/train/unsup/49283_0.txt\n","aclImdb/train/unsup/49282_0.txt\n","aclImdb/train/unsup/49281_0.txt\n","aclImdb/train/unsup/49280_0.txt\n","aclImdb/train/unsup/49535_0.txt\n","aclImdb/train/unsup/49534_0.txt\n","aclImdb/train/unsup/49533_0.txt\n","aclImdb/train/unsup/49532_0.txt\n","aclImdb/train/unsup/49531_0.txt\n","aclImdb/train/unsup/49530_0.txt\n","aclImdb/train/unsup/49529_0.txt\n","aclImdb/train/unsup/49528_0.txt\n","aclImdb/train/unsup/49527_0.txt\n","aclImdb/train/unsup/49526_0.txt\n","aclImdb/train/unsup/49525_0.txt\n","aclImdb/train/unsup/49524_0.txt\n","aclImdb/train/unsup/49523_0.txt\n","aclImdb/train/unsup/49522_0.txt\n","aclImdb/train/unsup/49521_0.txt\n","aclImdb/train/unsup/49520_0.txt\n","aclImdb/train/unsup/49519_0.txt\n","aclImdb/train/unsup/49518_0.txt\n","aclImdb/train/unsup/49517_0.txt\n","aclImdb/train/unsup/49516_0.txt\n","aclImdb/train/unsup/49515_0.txt\n","aclImdb/train/unsup/49514_0.txt\n","aclImdb/train/unsup/49513_0.txt\n","aclImdb/train/unsup/49512_0.txt\n","aclImdb/train/unsup/49511_0.txt\n","aclImdb/train/unsup/49510_0.txt\n","aclImdb/train/unsup/49509_0.txt\n","aclImdb/train/unsup/49508_0.txt\n","aclImdb/train/unsup/49507_0.txt\n","aclImdb/train/unsup/49506_0.txt\n","aclImdb/train/unsup/49505_0.txt\n","aclImdb/train/unsup/49504_0.txt\n","aclImdb/train/unsup/49503_0.txt\n","aclImdb/train/unsup/49502_0.txt\n","aclImdb/train/unsup/49501_0.txt\n","aclImdb/train/unsup/49500_0.txt\n","aclImdb/train/unsup/49499_0.txt\n","aclImdb/train/unsup/49498_0.txt\n","aclImdb/train/unsup/49497_0.txt\n","aclImdb/train/unsup/49496_0.txt\n","aclImdb/train/unsup/49495_0.txt\n","aclImdb/train/unsup/49494_0.txt\n","aclImdb/train/unsup/49493_0.txt\n","aclImdb/train/unsup/49492_0.txt\n","aclImdb/train/unsup/49491_0.txt\n","aclImdb/train/unsup/49490_0.txt\n","aclImdb/train/unsup/49489_0.txt\n","aclImdb/train/unsup/49488_0.txt\n","aclImdb/train/unsup/49487_0.txt\n","aclImdb/train/unsup/49486_0.txt\n","aclImdb/train/unsup/49485_0.txt\n","aclImdb/train/unsup/49484_0.txt\n","aclImdb/train/unsup/49483_0.txt\n","aclImdb/train/unsup/49482_0.txt\n","aclImdb/train/unsup/49481_0.txt\n","aclImdb/train/unsup/49480_0.txt\n","aclImdb/train/unsup/49479_0.txt\n","aclImdb/train/unsup/49478_0.txt\n","aclImdb/train/unsup/49477_0.txt\n","aclImdb/train/unsup/49476_0.txt\n","aclImdb/train/unsup/49475_0.txt\n","aclImdb/train/unsup/49474_0.txt\n","aclImdb/train/unsup/49473_0.txt\n","aclImdb/train/unsup/49472_0.txt\n","aclImdb/train/unsup/49471_0.txt\n","aclImdb/train/unsup/49470_0.txt\n","aclImdb/train/unsup/49469_0.txt\n","aclImdb/train/unsup/49468_0.txt\n","aclImdb/train/unsup/49467_0.txt\n","aclImdb/train/unsup/49466_0.txt\n","aclImdb/train/unsup/49465_0.txt\n","aclImdb/train/unsup/49464_0.txt\n","aclImdb/train/unsup/49463_0.txt\n","aclImdb/train/unsup/49462_0.txt\n","aclImdb/train/unsup/49461_0.txt\n","aclImdb/train/unsup/49460_0.txt\n","aclImdb/train/unsup/49459_0.txt\n","aclImdb/train/unsup/49458_0.txt\n","aclImdb/train/unsup/49457_0.txt\n","aclImdb/train/unsup/49456_0.txt\n","aclImdb/train/unsup/49455_0.txt\n","aclImdb/train/unsup/49454_0.txt\n","aclImdb/train/unsup/49453_0.txt\n","aclImdb/train/unsup/49452_0.txt\n","aclImdb/train/unsup/49451_0.txt\n","aclImdb/train/unsup/49450_0.txt\n","aclImdb/train/unsup/49449_0.txt\n","aclImdb/train/unsup/49448_0.txt\n","aclImdb/train/unsup/49447_0.txt\n","aclImdb/train/unsup/49446_0.txt\n","aclImdb/train/unsup/49445_0.txt\n","aclImdb/train/unsup/49444_0.txt\n","aclImdb/train/unsup/49443_0.txt\n","aclImdb/train/unsup/49442_0.txt\n","aclImdb/train/unsup/49441_0.txt\n","aclImdb/train/unsup/49440_0.txt\n","aclImdb/train/unsup/49439_0.txt\n","aclImdb/train/unsup/49438_0.txt\n","aclImdb/train/unsup/49437_0.txt\n","aclImdb/train/unsup/49436_0.txt\n","aclImdb/train/unsup/49435_0.txt\n","aclImdb/train/unsup/49434_0.txt\n","aclImdb/train/unsup/49433_0.txt\n","aclImdb/train/unsup/49432_0.txt\n","aclImdb/train/unsup/49431_0.txt\n","aclImdb/train/unsup/49430_0.txt\n","aclImdb/train/unsup/49429_0.txt\n","aclImdb/train/unsup/49428_0.txt\n","aclImdb/train/unsup/49427_0.txt\n","aclImdb/train/unsup/49426_0.txt\n","aclImdb/train/unsup/49425_0.txt\n","aclImdb/train/unsup/49424_0.txt\n","aclImdb/train/unsup/49423_0.txt\n","aclImdb/train/unsup/49422_0.txt\n","aclImdb/train/unsup/49421_0.txt\n","aclImdb/train/unsup/49420_0.txt\n","aclImdb/train/unsup/49419_0.txt\n","aclImdb/train/unsup/49418_0.txt\n","aclImdb/train/unsup/49417_0.txt\n","aclImdb/train/unsup/49416_0.txt\n","aclImdb/train/unsup/49415_0.txt\n","aclImdb/train/unsup/49414_0.txt\n","aclImdb/train/unsup/49413_0.txt\n","aclImdb/train/unsup/49412_0.txt\n","aclImdb/train/unsup/49411_0.txt\n","aclImdb/train/unsup/49410_0.txt\n","aclImdb/train/unsup/49409_0.txt\n","aclImdb/train/unsup/49408_0.txt\n","aclImdb/train/unsup/49663_0.txt\n","aclImdb/train/unsup/49662_0.txt\n","aclImdb/train/unsup/49661_0.txt\n","aclImdb/train/unsup/49660_0.txt\n","aclImdb/train/unsup/49659_0.txt\n","aclImdb/train/unsup/49658_0.txt\n","aclImdb/train/unsup/49657_0.txt\n","aclImdb/train/unsup/49656_0.txt\n","aclImdb/train/unsup/49655_0.txt\n","aclImdb/train/unsup/49654_0.txt\n","aclImdb/train/unsup/49653_0.txt\n","aclImdb/train/unsup/49652_0.txt\n","aclImdb/train/unsup/49651_0.txt\n","aclImdb/train/unsup/49650_0.txt\n","aclImdb/train/unsup/49649_0.txt\n","aclImdb/train/unsup/49648_0.txt\n","aclImdb/train/unsup/49647_0.txt\n","aclImdb/train/unsup/49646_0.txt\n","aclImdb/train/unsup/49645_0.txt\n","aclImdb/train/unsup/49644_0.txt\n","aclImdb/train/unsup/49643_0.txt\n","aclImdb/train/unsup/49642_0.txt\n","aclImdb/train/unsup/49641_0.txt\n","aclImdb/train/unsup/49640_0.txt\n","aclImdb/train/unsup/49639_0.txt\n","aclImdb/train/unsup/49638_0.txt\n","aclImdb/train/unsup/49637_0.txt\n","aclImdb/train/unsup/49636_0.txt\n","aclImdb/train/unsup/49635_0.txt\n","aclImdb/train/unsup/49634_0.txt\n","aclImdb/train/unsup/49633_0.txt\n","aclImdb/train/unsup/49632_0.txt\n","aclImdb/train/unsup/49631_0.txt\n","aclImdb/train/unsup/49630_0.txt\n","aclImdb/train/unsup/49629_0.txt\n","aclImdb/train/unsup/49628_0.txt\n","aclImdb/train/unsup/49627_0.txt\n","aclImdb/train/unsup/49626_0.txt\n","aclImdb/train/unsup/49625_0.txt\n","aclImdb/train/unsup/49624_0.txt\n","aclImdb/train/unsup/49623_0.txt\n","aclImdb/train/unsup/49622_0.txt\n","aclImdb/train/unsup/49621_0.txt\n","aclImdb/train/unsup/49620_0.txt\n","aclImdb/train/unsup/49619_0.txt\n","aclImdb/train/unsup/49618_0.txt\n","aclImdb/train/unsup/49617_0.txt\n","aclImdb/train/unsup/49616_0.txt\n","aclImdb/train/unsup/49615_0.txt\n","aclImdb/train/unsup/49614_0.txt\n","aclImdb/train/unsup/49613_0.txt\n","aclImdb/train/unsup/49612_0.txt\n","aclImdb/train/unsup/49611_0.txt\n","aclImdb/train/unsup/49610_0.txt\n","aclImdb/train/unsup/49609_0.txt\n","aclImdb/train/unsup/49608_0.txt\n","aclImdb/train/unsup/49607_0.txt\n","aclImdb/train/unsup/49606_0.txt\n","aclImdb/train/unsup/49605_0.txt\n","aclImdb/train/unsup/49604_0.txt\n","aclImdb/train/unsup/49603_0.txt\n","aclImdb/train/unsup/49602_0.txt\n","aclImdb/train/unsup/49601_0.txt\n","aclImdb/train/unsup/49600_0.txt\n","aclImdb/train/unsup/49599_0.txt\n","aclImdb/train/unsup/49598_0.txt\n","aclImdb/train/unsup/49597_0.txt\n","aclImdb/train/unsup/49596_0.txt\n","aclImdb/train/unsup/49595_0.txt\n","aclImdb/train/unsup/49594_0.txt\n","aclImdb/train/unsup/49593_0.txt\n","aclImdb/train/unsup/49592_0.txt\n","aclImdb/train/unsup/49591_0.txt\n","aclImdb/train/unsup/49590_0.txt\n","aclImdb/train/unsup/49589_0.txt\n","aclImdb/train/unsup/49588_0.txt\n","aclImdb/train/unsup/49587_0.txt\n","aclImdb/train/unsup/49586_0.txt\n","aclImdb/train/unsup/49585_0.txt\n","aclImdb/train/unsup/49584_0.txt\n","aclImdb/train/unsup/49583_0.txt\n","aclImdb/train/unsup/49582_0.txt\n","aclImdb/train/unsup/49581_0.txt\n","aclImdb/train/unsup/49580_0.txt\n","aclImdb/train/unsup/49579_0.txt\n","aclImdb/train/unsup/49578_0.txt\n","aclImdb/train/unsup/49577_0.txt\n","aclImdb/train/unsup/49576_0.txt\n","aclImdb/train/unsup/49575_0.txt\n","aclImdb/train/unsup/49574_0.txt\n","aclImdb/train/unsup/49573_0.txt\n","aclImdb/train/unsup/49572_0.txt\n","aclImdb/train/unsup/49571_0.txt\n","aclImdb/train/unsup/49570_0.txt\n","aclImdb/train/unsup/49569_0.txt\n","aclImdb/train/unsup/49568_0.txt\n","aclImdb/train/unsup/49567_0.txt\n","aclImdb/train/unsup/49566_0.txt\n","aclImdb/train/unsup/49565_0.txt\n","aclImdb/train/unsup/49564_0.txt\n","aclImdb/train/unsup/49563_0.txt\n","aclImdb/train/unsup/49562_0.txt\n","aclImdb/train/unsup/49561_0.txt\n","aclImdb/train/unsup/49560_0.txt\n","aclImdb/train/unsup/49559_0.txt\n","aclImdb/train/unsup/49558_0.txt\n","aclImdb/train/unsup/49557_0.txt\n","aclImdb/train/unsup/49556_0.txt\n","aclImdb/train/unsup/49555_0.txt\n","aclImdb/train/unsup/49554_0.txt\n","aclImdb/train/unsup/49553_0.txt\n","aclImdb/train/unsup/49552_0.txt\n","aclImdb/train/unsup/49551_0.txt\n","aclImdb/train/unsup/49550_0.txt\n","aclImdb/train/unsup/49549_0.txt\n","aclImdb/train/unsup/49548_0.txt\n","aclImdb/train/unsup/49547_0.txt\n","aclImdb/train/unsup/49546_0.txt\n","aclImdb/train/unsup/49545_0.txt\n","aclImdb/train/unsup/49544_0.txt\n","aclImdb/train/unsup/49543_0.txt\n","aclImdb/train/unsup/49542_0.txt\n","aclImdb/train/unsup/49541_0.txt\n","aclImdb/train/unsup/49540_0.txt\n","aclImdb/train/unsup/49539_0.txt\n","aclImdb/train/unsup/49538_0.txt\n","aclImdb/train/unsup/49537_0.txt\n","aclImdb/train/unsup/49536_0.txt\n","aclImdb/train/unsup/49791_0.txt\n","aclImdb/train/unsup/49790_0.txt\n","aclImdb/train/unsup/49789_0.txt\n","aclImdb/train/unsup/49788_0.txt\n","aclImdb/train/unsup/49787_0.txt\n","aclImdb/train/unsup/49786_0.txt\n","aclImdb/train/unsup/49785_0.txt\n","aclImdb/train/unsup/49784_0.txt\n","aclImdb/train/unsup/49783_0.txt\n","aclImdb/train/unsup/49782_0.txt\n","aclImdb/train/unsup/49781_0.txt\n","aclImdb/train/unsup/49780_0.txt\n","aclImdb/train/unsup/49779_0.txt\n","aclImdb/train/unsup/49778_0.txt\n","aclImdb/train/unsup/49777_0.txt\n","aclImdb/train/unsup/49776_0.txt\n","aclImdb/train/unsup/49775_0.txt\n","aclImdb/train/unsup/49774_0.txt\n","aclImdb/train/unsup/49773_0.txt\n","aclImdb/train/unsup/49772_0.txt\n","aclImdb/train/unsup/49771_0.txt\n","aclImdb/train/unsup/49770_0.txt\n","aclImdb/train/unsup/49769_0.txt\n","aclImdb/train/unsup/49768_0.txt\n","aclImdb/train/unsup/49767_0.txt\n","aclImdb/train/unsup/49766_0.txt\n","aclImdb/train/unsup/49765_0.txt\n","aclImdb/train/unsup/49764_0.txt\n","aclImdb/train/unsup/49763_0.txt\n","aclImdb/train/unsup/49762_0.txt\n","aclImdb/train/unsup/49761_0.txt\n","aclImdb/train/unsup/49760_0.txt\n","aclImdb/train/unsup/49759_0.txt\n","aclImdb/train/unsup/49758_0.txt\n","aclImdb/train/unsup/49757_0.txt\n","aclImdb/train/unsup/49756_0.txt\n","aclImdb/train/unsup/49755_0.txt\n","aclImdb/train/unsup/49754_0.txt\n","aclImdb/train/unsup/49753_0.txt\n","aclImdb/train/unsup/49752_0.txt\n","aclImdb/train/unsup/49751_0.txt\n","aclImdb/train/unsup/49750_0.txt\n","aclImdb/train/unsup/49749_0.txt\n","aclImdb/train/unsup/49748_0.txt\n","aclImdb/train/unsup/49747_0.txt\n","aclImdb/train/unsup/49746_0.txt\n","aclImdb/train/unsup/49745_0.txt\n","aclImdb/train/unsup/49744_0.txt\n","aclImdb/train/unsup/49743_0.txt\n","aclImdb/train/unsup/49742_0.txt\n","aclImdb/train/unsup/49741_0.txt\n","aclImdb/train/unsup/49740_0.txt\n","aclImdb/train/unsup/49739_0.txt\n","aclImdb/train/unsup/49738_0.txt\n","aclImdb/train/unsup/49737_0.txt\n","aclImdb/train/unsup/49736_0.txt\n","aclImdb/train/unsup/49735_0.txt\n","aclImdb/train/unsup/49734_0.txt\n","aclImdb/train/unsup/49733_0.txt\n","aclImdb/train/unsup/49732_0.txt\n","aclImdb/train/unsup/49731_0.txt\n","aclImdb/train/unsup/49730_0.txt\n","aclImdb/train/unsup/49729_0.txt\n","aclImdb/train/unsup/49728_0.txt\n","aclImdb/train/unsup/49727_0.txt\n","aclImdb/train/unsup/49726_0.txt\n","aclImdb/train/unsup/49725_0.txt\n","aclImdb/train/unsup/49724_0.txt\n","aclImdb/train/unsup/49723_0.txt\n","aclImdb/train/unsup/49722_0.txt\n","aclImdb/train/unsup/49721_0.txt\n","aclImdb/train/unsup/49720_0.txt\n","aclImdb/train/unsup/49719_0.txt\n","aclImdb/train/unsup/49718_0.txt\n","aclImdb/train/unsup/49717_0.txt\n","aclImdb/train/unsup/49716_0.txt\n","aclImdb/train/unsup/49715_0.txt\n","aclImdb/train/unsup/49714_0.txt\n","aclImdb/train/unsup/49713_0.txt\n","aclImdb/train/unsup/49712_0.txt\n","aclImdb/train/unsup/49711_0.txt\n","aclImdb/train/unsup/49710_0.txt\n","aclImdb/train/unsup/49709_0.txt\n","aclImdb/train/unsup/49708_0.txt\n","aclImdb/train/unsup/49707_0.txt\n","aclImdb/train/unsup/49706_0.txt\n","aclImdb/train/unsup/49705_0.txt\n","aclImdb/train/unsup/49704_0.txt\n","aclImdb/train/unsup/49703_0.txt\n","aclImdb/train/unsup/49702_0.txt\n","aclImdb/train/unsup/49701_0.txt\n","aclImdb/train/unsup/49700_0.txt\n","aclImdb/train/unsup/49699_0.txt\n","aclImdb/train/unsup/49698_0.txt\n","aclImdb/train/unsup/49697_0.txt\n","aclImdb/train/unsup/49696_0.txt\n","aclImdb/train/unsup/49695_0.txt\n","aclImdb/train/unsup/49694_0.txt\n","aclImdb/train/unsup/49693_0.txt\n","aclImdb/train/unsup/49692_0.txt\n","aclImdb/train/unsup/49691_0.txt\n","aclImdb/train/unsup/49690_0.txt\n","aclImdb/train/unsup/49689_0.txt\n","aclImdb/train/unsup/49688_0.txt\n","aclImdb/train/unsup/49687_0.txt\n","aclImdb/train/unsup/49686_0.txt\n","aclImdb/train/unsup/49685_0.txt\n","aclImdb/train/unsup/49684_0.txt\n","aclImdb/train/unsup/49683_0.txt\n","aclImdb/train/unsup/49682_0.txt\n","aclImdb/train/unsup/49681_0.txt\n","aclImdb/train/unsup/49680_0.txt\n","aclImdb/train/unsup/49679_0.txt\n","aclImdb/train/unsup/49678_0.txt\n","aclImdb/train/unsup/49677_0.txt\n","aclImdb/train/unsup/49676_0.txt\n","aclImdb/train/unsup/49675_0.txt\n","aclImdb/train/unsup/49674_0.txt\n","aclImdb/train/unsup/49673_0.txt\n","aclImdb/train/unsup/49672_0.txt\n","aclImdb/train/unsup/49671_0.txt\n","aclImdb/train/unsup/49670_0.txt\n","aclImdb/train/unsup/49669_0.txt\n","aclImdb/train/unsup/49668_0.txt\n","aclImdb/train/unsup/49667_0.txt\n","aclImdb/train/unsup/49666_0.txt\n","aclImdb/train/unsup/49665_0.txt\n","aclImdb/train/unsup/49664_0.txt\n","aclImdb/train/unsup/49919_0.txt\n","aclImdb/train/unsup/49918_0.txt\n","aclImdb/train/unsup/49917_0.txt\n","aclImdb/train/unsup/49916_0.txt\n","aclImdb/train/unsup/49915_0.txt\n","aclImdb/train/unsup/49914_0.txt\n","aclImdb/train/unsup/49913_0.txt\n","aclImdb/train/unsup/49912_0.txt\n","aclImdb/train/unsup/49911_0.txt\n","aclImdb/train/unsup/49910_0.txt\n","aclImdb/train/unsup/49909_0.txt\n","aclImdb/train/unsup/49908_0.txt\n","aclImdb/train/unsup/49907_0.txt\n","aclImdb/train/unsup/49906_0.txt\n","aclImdb/train/unsup/49905_0.txt\n","aclImdb/train/unsup/49904_0.txt\n","aclImdb/train/unsup/49903_0.txt\n","aclImdb/train/unsup/49902_0.txt\n","aclImdb/train/unsup/49901_0.txt\n","aclImdb/train/unsup/49900_0.txt\n","aclImdb/train/unsup/49899_0.txt\n","aclImdb/train/unsup/49898_0.txt\n","aclImdb/train/unsup/49897_0.txt\n","aclImdb/train/unsup/49896_0.txt\n","aclImdb/train/unsup/49895_0.txt\n","aclImdb/train/unsup/49894_0.txt\n","aclImdb/train/unsup/49893_0.txt\n","aclImdb/train/unsup/49892_0.txt\n","aclImdb/train/unsup/49891_0.txt\n","aclImdb/train/unsup/49890_0.txt\n","aclImdb/train/unsup/49889_0.txt\n","aclImdb/train/unsup/49888_0.txt\n","aclImdb/train/unsup/49887_0.txt\n","aclImdb/train/unsup/49886_0.txt\n","aclImdb/train/unsup/49885_0.txt\n","aclImdb/train/unsup/49884_0.txt\n","aclImdb/train/unsup/49883_0.txt\n","aclImdb/train/unsup/49882_0.txt\n","aclImdb/train/unsup/49881_0.txt\n","aclImdb/train/unsup/49880_0.txt\n","aclImdb/train/unsup/49879_0.txt\n","aclImdb/train/unsup/49878_0.txt\n","aclImdb/train/unsup/49877_0.txt\n","aclImdb/train/unsup/49876_0.txt\n","aclImdb/train/unsup/49875_0.txt\n","aclImdb/train/unsup/49874_0.txt\n","aclImdb/train/unsup/49873_0.txt\n","aclImdb/train/unsup/49872_0.txt\n","aclImdb/train/unsup/49871_0.txt\n","aclImdb/train/unsup/49870_0.txt\n","aclImdb/train/unsup/49869_0.txt\n","aclImdb/train/unsup/49868_0.txt\n","aclImdb/train/unsup/49867_0.txt\n","aclImdb/train/unsup/49866_0.txt\n","aclImdb/train/unsup/49865_0.txt\n","aclImdb/train/unsup/49864_0.txt\n","aclImdb/train/unsup/49863_0.txt\n","aclImdb/train/unsup/49862_0.txt\n","aclImdb/train/unsup/49861_0.txt\n","aclImdb/train/unsup/49860_0.txt\n","aclImdb/train/unsup/49859_0.txt\n","aclImdb/train/unsup/49858_0.txt\n","aclImdb/train/unsup/49857_0.txt\n","aclImdb/train/unsup/49856_0.txt\n","aclImdb/train/unsup/49855_0.txt\n","aclImdb/train/unsup/49854_0.txt\n","aclImdb/train/unsup/49853_0.txt\n","aclImdb/train/unsup/49852_0.txt\n","aclImdb/train/unsup/49851_0.txt\n","aclImdb/train/unsup/49850_0.txt\n","aclImdb/train/unsup/49849_0.txt\n","aclImdb/train/unsup/49848_0.txt\n","aclImdb/train/unsup/49847_0.txt\n","aclImdb/train/unsup/49846_0.txt\n","aclImdb/train/unsup/49845_0.txt\n","aclImdb/train/unsup/49844_0.txt\n","aclImdb/train/unsup/49843_0.txt\n","aclImdb/train/unsup/49842_0.txt\n","aclImdb/train/unsup/49841_0.txt\n","aclImdb/train/unsup/49840_0.txt\n","aclImdb/train/unsup/49839_0.txt\n","aclImdb/train/unsup/49838_0.txt\n","aclImdb/train/unsup/49837_0.txt\n","aclImdb/train/unsup/49836_0.txt\n","aclImdb/train/unsup/49835_0.txt\n","aclImdb/train/unsup/49834_0.txt\n","aclImdb/train/unsup/49833_0.txt\n","aclImdb/train/unsup/49832_0.txt\n","aclImdb/train/unsup/49831_0.txt\n","aclImdb/train/unsup/49830_0.txt\n","aclImdb/train/unsup/49829_0.txt\n","aclImdb/train/unsup/49828_0.txt\n","aclImdb/train/unsup/49827_0.txt\n","aclImdb/train/unsup/49826_0.txt\n","aclImdb/train/unsup/49825_0.txt\n","aclImdb/train/unsup/49824_0.txt\n","aclImdb/train/unsup/49823_0.txt\n","aclImdb/train/unsup/49822_0.txt\n","aclImdb/train/unsup/49821_0.txt\n","aclImdb/train/unsup/49820_0.txt\n","aclImdb/train/unsup/49819_0.txt\n","aclImdb/train/unsup/49818_0.txt\n","aclImdb/train/unsup/49817_0.txt\n","aclImdb/train/unsup/49816_0.txt\n","aclImdb/train/unsup/49815_0.txt\n","aclImdb/train/unsup/49814_0.txt\n","aclImdb/train/unsup/49813_0.txt\n","aclImdb/train/unsup/49812_0.txt\n","aclImdb/train/unsup/49811_0.txt\n","aclImdb/train/unsup/49810_0.txt\n","aclImdb/train/unsup/49809_0.txt\n","aclImdb/train/unsup/49808_0.txt\n","aclImdb/train/unsup/49807_0.txt\n","aclImdb/train/unsup/49806_0.txt\n","aclImdb/train/unsup/49805_0.txt\n","aclImdb/train/unsup/49804_0.txt\n","aclImdb/train/unsup/49803_0.txt\n","aclImdb/train/unsup/49802_0.txt\n","aclImdb/train/unsup/49801_0.txt\n","aclImdb/train/unsup/49800_0.txt\n","aclImdb/train/unsup/49799_0.txt\n","aclImdb/train/unsup/49798_0.txt\n","aclImdb/train/unsup/49797_0.txt\n","aclImdb/train/unsup/49796_0.txt\n","aclImdb/train/unsup/49795_0.txt\n","aclImdb/train/unsup/49794_0.txt\n","aclImdb/train/unsup/49793_0.txt\n","aclImdb/train/unsup/49792_0.txt\n","aclImdb/train/unsup/49999_0.txt\n","aclImdb/train/unsup/49998_0.txt\n","aclImdb/train/unsup/49997_0.txt\n","aclImdb/train/unsup/49996_0.txt\n","aclImdb/train/unsup/49995_0.txt\n","aclImdb/train/unsup/49994_0.txt\n","aclImdb/train/unsup/49993_0.txt\n","aclImdb/train/unsup/49992_0.txt\n","aclImdb/train/unsup/49991_0.txt\n","aclImdb/train/unsup/49990_0.txt\n","aclImdb/train/unsup/49989_0.txt\n","aclImdb/train/unsup/49988_0.txt\n","aclImdb/train/unsup/49987_0.txt\n","aclImdb/train/unsup/49986_0.txt\n","aclImdb/train/unsup/49985_0.txt\n","aclImdb/train/unsup/49984_0.txt\n","aclImdb/train/unsup/49983_0.txt\n","aclImdb/train/unsup/49982_0.txt\n","aclImdb/train/unsup/49981_0.txt\n","aclImdb/train/unsup/49980_0.txt\n","aclImdb/train/unsup/49979_0.txt\n","aclImdb/train/unsup/49978_0.txt\n","aclImdb/train/unsup/49977_0.txt\n","aclImdb/train/unsup/49976_0.txt\n","aclImdb/train/unsup/49975_0.txt\n","aclImdb/train/unsup/49974_0.txt\n","aclImdb/train/unsup/49973_0.txt\n","aclImdb/train/unsup/49972_0.txt\n","aclImdb/train/unsup/49971_0.txt\n","aclImdb/train/unsup/49970_0.txt\n","aclImdb/train/unsup/49969_0.txt\n","aclImdb/train/unsup/49968_0.txt\n","aclImdb/train/unsup/49967_0.txt\n","aclImdb/train/unsup/49966_0.txt\n","aclImdb/train/unsup/49965_0.txt\n","aclImdb/train/unsup/49964_0.txt\n","aclImdb/train/unsup/49963_0.txt\n","aclImdb/train/unsup/49962_0.txt\n","aclImdb/train/unsup/49961_0.txt\n","aclImdb/train/unsup/49960_0.txt\n","aclImdb/train/unsup/49959_0.txt\n","aclImdb/train/unsup/49958_0.txt\n","aclImdb/train/unsup/49957_0.txt\n","aclImdb/train/unsup/49956_0.txt\n","aclImdb/train/unsup/49955_0.txt\n","aclImdb/train/unsup/49954_0.txt\n","aclImdb/train/unsup/49953_0.txt\n","aclImdb/train/unsup/49952_0.txt\n","aclImdb/train/unsup/49951_0.txt\n","aclImdb/train/unsup/49950_0.txt\n","aclImdb/train/unsup/49949_0.txt\n","aclImdb/train/unsup/49948_0.txt\n","aclImdb/train/unsup/49947_0.txt\n","aclImdb/train/unsup/49946_0.txt\n","aclImdb/train/unsup/49945_0.txt\n","aclImdb/train/unsup/49944_0.txt\n","aclImdb/train/unsup/49943_0.txt\n","aclImdb/train/unsup/49942_0.txt\n","aclImdb/train/unsup/49941_0.txt\n","aclImdb/train/unsup/49940_0.txt\n","aclImdb/train/unsup/49939_0.txt\n","aclImdb/train/unsup/49938_0.txt\n","aclImdb/train/unsup/49937_0.txt\n","aclImdb/train/unsup/49936_0.txt\n","aclImdb/train/unsup/49935_0.txt\n","aclImdb/train/unsup/49934_0.txt\n","aclImdb/train/unsup/49933_0.txt\n","aclImdb/train/unsup/49932_0.txt\n","aclImdb/train/unsup/49931_0.txt\n","aclImdb/train/unsup/49930_0.txt\n","aclImdb/train/unsup/49929_0.txt\n","aclImdb/train/unsup/49928_0.txt\n","aclImdb/train/unsup/49927_0.txt\n","aclImdb/train/unsup/49926_0.txt\n","aclImdb/train/unsup/49925_0.txt\n","aclImdb/train/unsup/49924_0.txt\n","aclImdb/train/unsup/49923_0.txt\n","aclImdb/train/unsup/49922_0.txt\n","aclImdb/train/unsup/49921_0.txt\n","aclImdb/train/unsup/49920_0.txt\n"]}],"source":["if not os.path.exists('aclImdb'):\n","    # YOUR CODE HERE\n","    !mkdir -p aclImdb\n","    !tar -xvf aclImdb_v1.tar.gz aclImdb"]},{"cell_type":"markdown","metadata":{"id":"WwY-5DlBOBOk"},"source":["Посмотрите в файле `./aclImdb/README` как организованы данные:"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":47,"status":"ok","timestamp":1744808649417,"user":{"displayName":"ГУЩИН СТАНИСЛАВ АЛЕКСЕЕВИЧ","userId":"03202281510855514510"},"user_tz":-180},"id":"-O6oWSt2OBOk","outputId":"2d459b7f-25bb-4bbe-e993-30637a8a40a9"},"outputs":[{"name":"stdout","output_type":"stream","text":["This is not the typical Mel Brooks film. It was much less slapstick than most of his movies and actually had a plot that was followable. Leslie Ann Warren made the movie, she is such a fantastic, under-rated actress. There were some moments that could have been fleshed out a bit more, and some scenes that could probably have been cut to make the room to do so, but all in all, this is worth the price to rent and see it. The acting was good overall, Brooks himself did a good job without his characteristic speaking to directly to the audience. Again, Warren was the best actor in the movie, but \"Fume\" and \"Sailor\" both played their parts well."]}],"source":["! cat ./aclImdb/train/pos/10003_8.txt"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IdMUasqEOBOk"},"outputs":[],"source":["test_data_path = './aclImdb/test/'\n","train_data_path = './aclImdb/train/'"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11358,"status":"ok","timestamp":1744808660796,"user":{"displayName":"ГУЩИН СТАНИСЛАВ АЛЕКСЕЕВИЧ","userId":"03202281510855514510"},"user_tz":-180},"id":"obftsEfdOBOk","outputId":"f8ea00aa-5e27-4814-f8e8-ba2e84cfec0d"},"outputs":[{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n"]}],"source":["import random\n","from tqdm import tqdm\n","from functools import partial\n","from collections import defaultdict\n","from typing import Optional, Tuple, Union, List\n","\n","from IPython.display import Markdown, display\n","\n","\n","import nltk\n","nltk.download('stopwords')\n","\n","import regex\n","import numpy as np\n","\n","import torch\n","from torch.utils.data import Dataset, DataLoader\n","\n","import tokenizers\n","from tokenizers import Tokenizer, trainers, pre_tokenizers\n","\n","torch.backends.cudnn.benchmark = True\n","torch.use_deterministic_algorithms(False)\n","\n","torch.autograd.profiler.profile(False)\n","torch.autograd.profiler.emit_nvtx(False)\n","torch.autograd.set_detect_anomaly(False)\n","\n","torch.set_float32_matmul_precision('high')\n","torch.backends.cuda.matmul.allow_tf32 = True\n","\n","os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Uoj2UdgfOBOm"},"outputs":[],"source":["def set_global_seed(seed: int) -> None:\n","    \"\"\"Set global seed for reproducibility.\n","    :param int seed: Seed to be set\n","    \"\"\"\n","    random.seed(seed)\n","    np.random.seed(seed)\n","\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.cuda.manual_seed_all(seed)\n","\n","def check_numel(module: torch.nn.Module, params_numel: int, buffers_numel: Optional[int] = None) -> None:\n","    \"\"\"Check whether module has correct number of parameters and buffers\n","    :param torch.nn.Module module: Target model\n","    :param int params_numel: Target number of parameters\n","    :param Optional[int] buffers_numel: Target number of buffers\n","    :rtype:\n","    \"\"\"\n","    numel = sum(param.numel() for param in module.parameters())\n","    assert numel == params_numel, f'For params numel != correct numel: {numel} vs {params_numel}'\n","\n","    if buffers_numel is not None:\n","        numel = sum(param.numel() for param in module.buffers())\n","        assert numel == buffers_numel, f'For buffers numel != correct numel: {numel} vs {buffers_numel}'\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"12JQxaV7OBOm"},"outputs":[],"source":["set_global_seed(42)"]},{"cell_type":"markdown","metadata":{"id":"uPmTj72EOBOm"},"source":["Стандартной предобработкой данных является токенизация текстов. Полученные токены можно будет закодировать и затем подавать на вход нейронной сети. Ключевым моментом, который влияет на скорость работы нейросети и её размер в памяти — размер словаря, используемого при токенизации. Для задачи классификации мы можем убрать часть слов (стоп слова, редкие слова), ускорив обучение без потери в качестве."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1CfWIrNpOBOm"},"outputs":[],"source":["STOPWORDS = nltk.corpus.stopwords.words('english')"]},{"cell_type":"markdown","metadata":{"id":"dXya32_0OBOm"},"source":["Реализуйте функцию для токенизации текста. Выполнять токенизацию можно по-разному, но в данном задании предлагается это делать следующим образом:\n","1. Привести текст к нижнему регистру\n","2. Убрать html разметку из текстов (`<br />`, ...)\n","3. Убрать все символы кроме латинских букв\n","4. Разбить строку по пробелам\n","5. Убрать стоп слова"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GV4A8xU7OBOm"},"outputs":[],"source":["import re\n","def tokenize(text):\n","    \"\"\"\n","    :param str text: Input text\n","    :return List[str]: List of words\n","    \"\"\"\n","    # YOUR CODE HERE\n","    lower_text = text.lower()\n","    clean_text = re.sub(r'<.*?>', '', lower_text)\n","    lat_text = re.sub(r'[^a-zA-Z ]', '', clean_text)\n","    space_text = lat_text.split()\n","    filtered_text = [word for word in space_text if word not in STOPWORDS]\n","    return filtered_text\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":27,"status":"ok","timestamp":1744808660845,"user":{"displayName":"ГУЩИН СТАНИСЛАВ АЛЕКСЕЕВИЧ","userId":"03202281510855514510"},"user_tz":-180},"id":"joDu3yQLOBOm","outputId":"a940e46d-0790-4746-9334-0629a84dcfdc"},"outputs":[{"data":{"text/plain":["['hello', 'words', 'program']"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["tokenize('1. Hello <br />  words!!   I am program!  <br />')"]},{"cell_type":"markdown","metadata":{"id":"epCreX49OBOn"},"source":["Теперь мы можем создать словарь, с помощью которого мы будем кодировать токены из текста в числа и наоборот. Для этого мы воспользуемся библиотекой [tokenizers](https://huggingface.co/docs/tokenizers/index)\n","\n","Токенезация происходит через класс `tokenizer`. Для того чтобы получить `tokenizer` его надо сначала **обучить**, для этого нам необходимо использовать `tokenizers.trainers`. Так как мы будем работать на уровне слов, то выберем `tokenizers.trainers.WordLevelTrainer`.\n","\n","Для работы с текстами нам необходимо зарезервировать два специальных токена:\n","1. `<pad>` для токена означающего паддинг\n","2. `<unk>` для токенов, которые отсутствуют в словаре\n","3. `<sos>` для токенов, которые обозначают начало последовательности (потребуется во второй части задания)\n","4. `<eos>` для токенов, которые обозначают конец последовательности (потребуется во второй части задания)"]},{"cell_type":"markdown","metadata":{"id":"uol8rIEqOBOn"},"source":["Для начала мы будем разбивать предложение по словам, для этого воспользуемся `trainers.WordLevelTrainer`. Будем рассматривать словарь размером `top_n_words` слов. Подробнее про различных `trainers` можно почитать в [документации](https://huggingface.co/docs/tokenizers/api/trainers), например, из коробки можно использовать BPE."]},{"cell_type":"markdown","metadata":{"id":"Zrse3p0eOBOn"},"source":["```python\n","trainers.WordLevelTrainer(self, /, *args, **kwargs)\n","Docstring:     \n","Trainer capable of training a WorldLevel model\n","\n","Args:\n","    vocab_size (:obj:`int`, `optional`):\n","        The size of the final vocabulary, including all tokens and alphabet.\n","\n","    min_frequency (:obj:`int`, `optional`):\n","        The minimum frequency a pair should have in order to be merged.\n","\n","    show_progress (:obj:`bool`, `optional`):\n","        Whether to show progress bars while training.\n","\n","    special_tokens (:obj:`List[Union[str, AddedToken]]`):\n","        A list of special tokens the model should know of.\n","```"]},{"cell_type":"markdown","metadata":{"id":"dfyG9ltDOBOn"},"source":["Не забудьте добавить специальные токены. В первой части это токены, отвечающие за паддинг и слова, которых нет в словаре."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XX2d_DqpOBOn"},"outputs":[],"source":["# YOUR CODE HERE\n","\n","trainer = trainers.WordLevelTrainer( # занимается обучением словаря\n","    vocab_size = top_n_words,\n","    special_tokens=[\"<pad>\", \"<unk>\"],\n","    show_progress = True,\n",")\n","\n","tokenizer = tokenizers.Tokenizer( # при помощи trainer преобразует из токена в слово и наоборот\n","    model = tokenizers.models.WordLevel(unk_token=\"<unk>\")\n",")"]},{"cell_type":"markdown","metadata":{"id":"9bhOawWROBOn"},"source":["Обучить `tokenizers.Tokenizer` можно **двумя способами**:\n","\n","- [указать список файлов и обучиться на них](https://huggingface.co/docs/tokenizers/pipeline), бывает полезно, когда датасет нельзя поместить в оперативную память;\n","\n","- [обучиться из памяти](https://huggingface.co/docs/tokenizers/training_from_memory), то есть хранить датасет в оперативной памяти, бывает полезно при маленьких датасетах как наш.\n","\n","\n","Чтобы обучиться из файлов нам необходимо задать `tokenizers.normalizers.Normalizer` для нормализации строк (удаление лишних слов и символов), после чего необходимо задать `tokenizers.pre_tokenizers.PreTokenizer` для разделение строки на слова. Подробнее можно посмотреть [в этом примере](https://github.com/huggingface/tokenizers/blob/4383a25787cf366f5e8eaf12643b64f0ba548dc2/bindings/python/examples/custom_components.py). Такая сложность обусловленна тем, что `tokenizers` крайне много использует особенности ООП (объектно-ориентированного программирования).\n","\n","Мы будем обучаться из памяти, поэтому нам необходимо сделать итератор, который пройдет по всем файлам и токенизирует текст в них их. Подробнее можно почитать [в официальной документации](https://huggingface.co/docs/tokenizers/training_from_memory).\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"A6PflyJJOBOn"},"outputs":[],"source":["def get_data_iterator():\n","    for path in ['./aclImdb/test/neg', './aclImdb/test/pos', './aclImdb/train/neg', './aclImdb/train/pos']:\n","        paths = sorted(list(os.listdir(path)))\n","        # YOUR CODE HERE\n","        for file_path in paths:\n","            text = open(os.path.join(path, file_path), 'r', encoding='utf-8', errors='ignore').read().strip()\n","            yield tokenize(text)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":28433,"status":"ok","timestamp":1744808689311,"user":{"displayName":"ГУЩИН СТАНИСЛАВ АЛЕКСЕЕВИЧ","userId":"03202281510855514510"},"user_tz":-180},"id":"YUt5npY3OBOn","outputId":"60be1e37-6525-493c-94c6-0c2b3510dee7"},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 50000/50000 [00:28<00:00, 1763.02it/s]\n"]}],"source":["tokenizer.train_from_iterator(tqdm(get_data_iterator(), total=50_000), trainer=trainer)"]},{"cell_type":"markdown","metadata":{"id":"h9gOfdfxOBOo"},"source":["Посмотрим на токены с наименьшим *id*. Обратим внимание, что специальные токены имеют наименьшие *id* по-умолчанию."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1744808689318,"user":{"displayName":"ГУЩИН СТАНИСЛАВ АЛЕКСЕЕВИЧ","userId":"03202281510855514510"},"user_tz":-180},"id":"6T6DUyYkOBOo","outputId":"ecfada2e-65c6-4c0d-9407-2be508fea888"},"outputs":[{"name":"stdout","output_type":"stream","text":["ID = 0, token = <pad>\n","ID = 1, token = <unk>\n","ID = 2, token = movie\n","ID = 3, token = film\n","ID = 4, token = one\n","ID = 5, token = like\n","ID = 6, token = good\n","ID = 7, token = even\n","ID = 8, token = would\n","ID = 9, token = time\n"]}],"source":["for i in range(10):\n","    token = tokenizer.id_to_token(i)\n","    print(f\"ID = {i}, token = {token}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cd6Wn2Z_OBOo"},"outputs":[],"source":["assert tokenizer.get_vocab_size() == top_n_words\n","\n","# assert tokenizer.id_to_token(464) == 'complete', f\"token = {tokenizer.id_to_token(464)}\"\n","# assert tokenizer.id_to_token(646) == 'typical',  f\"token = {tokenizer.id_to_token(646)}\"\n","# assert tokenizer.id_to_token(573) == 'fast',     f\"token = {tokenizer.id_to_token(573)}\""]},{"cell_type":"markdown","metadata":{"id":"Fw36340GOBOo"},"source":["**Важно:** При создании итератора мы сортировали файлы, поэтому результат при корретной реализации должен быть детерминированный."]},{"cell_type":"markdown","metadata":{"id":"eJmsMe7ZOBOo"},"source":["Для кодирования предложений используется метод `encode`, так как мы самостоятельно описали функцию `tokenize`, то установим `is_pretokenized=True`."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18,"status":"ok","timestamp":1744808689368,"user":{"displayName":"ГУЩИН СТАНИСЛАВ АЛЕКСЕЕВИЧ","userId":"03202281510855514510"},"user_tz":-180},"id":"1OStm3qLOBOo","outputId":"a496d5c6-0d8b-41f1-a08a-2d33d75d9c45"},"outputs":[{"name":"stdout","output_type":"stream","text":["Encoding(num_tokens=2, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])\n","Tokens ids:  [1, 543]\n"]}],"source":["result = tokenizer.encode(\n","    sequence        = tokenize('1. Hello <br /> words!! <br />'),\n","    is_pretokenized = True\n",")\n","\n","print(result)\n","print(\"Tokens ids: \", result.ids)"]},{"cell_type":"markdown","metadata":{"id":"2nmCAwNmOBOr"},"source":["Для декодирования, следует использовать метод `decode`, по умолчанию все специальные токены будут пропущены, то есть все токены `<unk>` будут пропущены."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":77,"status":"ok","timestamp":1744808689446,"user":{"displayName":"ГУЩИН СТАНИСЛАВ АЛЕКСЕЕВИЧ","userId":"03202281510855514510"},"user_tz":-180},"id":"ZxyW4jpaOBOr","outputId":"8db4488a-3ff3-44bd-d5de-172f169c528e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Decode result: words\n"]}],"source":["decode_res = tokenizer.decode(\n","    ids                 = result.ids,\n","    skip_special_tokens = True\n",")\n","print(f\"Decode result: {decode_res}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uNsAyEt2Ek9d"},"outputs":[],"source":["a = \"Once again Mr. Costner has dragged out a movie for far longer than necessary. Aside from the terrific sea rescue sequences, of which there are very few I just did not care about any of the characters. Most of us have ghosts in the closet, and Costner's character are realized early on, and then forgotten until much later, by which time I did not care. The character we should really care about is a very cocky, overconfident Ashton Kutcher. The problem is he comes off as kid who thinks he's better than anyone else around him and shows no signs of a cluttered closet. His only obstacle appears to be winning over Costner. Finally when we are well past the half way point of this stinker, Costner tells us all about Kutcher's ghosts. We are told why Kutcher is driven to be the best with no prior inkling or foreshadowing. No magic here, it was all I could do to keep from turning it off an hour in.\""]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":34,"status":"ok","timestamp":1744808689483,"user":{"displayName":"ГУЩИН СТАНИСЛАВ АЛЕКСЕЕВИЧ","userId":"03202281510855514510"},"user_tz":-180},"id":"FHVKo7rcEazF","outputId":"de56f108-3f42-46ff-c5b3-c8e7dd9bc921"},"outputs":[{"data":{"text/plain":["[337,\n"," 1,\n"," 3161,\n"," 2,\n"," 127,\n"," 993,\n"," 1552,\n"," 1077,\n"," 1151,\n"," 1517,\n"," 1962,\n"," 714,\n"," 339,\n"," 28,\n"," 77,\n"," 2744,\n"," 4163,\n"," 1,\n"," 34,\n"," 1497,\n"," 290,\n"," 1402,\n"," 13,\n"," 200,\n"," 9,\n"," 339,\n"," 34,\n"," 10,\n"," 339,\n"," 1,\n"," 1,\n"," 1,\n"," 1,\n"," 325,\n"," 158,\n"," 423,\n"," 1062,\n"," 130,\n"," 45,\n"," 147,\n"," 220,\n"," 88,\n"," 155,\n"," 3526,\n"," 1,\n"," 4163,\n"," 1,\n"," 588,\n"," 1818,\n"," 1,\n"," 322,\n"," 14,\n"," 387,\n"," 239,\n"," 27,\n"," 123,\n"," 3884,\n"," 1,\n"," 574,\n"," 77,\n"," 1,\n"," 2744,\n"," 435,\n"," 1,\n"," 2439,\n"," 40,\n"," 2333,\n"," 1,\n"," 1,\n"," 1169,\n"," 26,\n"," 269,\n"," 1423,\n"," 429]"]},"execution_count":21,"metadata":{},"output_type":"execute_result"}],"source":["tokenizer.encode(sequence=tokenize(a),  is_pretokenized = True).ids"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1744808689488,"user":{"displayName":"ГУЩИН СТАНИСЛАВ АЛЕКСЕЕВИЧ","userId":"03202281510855514510"},"user_tz":-180},"id":"FxaenhVCKaIL","outputId":"d1875ec8-d259-476d-94f8-2d2230873864"},"outputs":[{"name":"stdout","output_type":"stream","text":["Decode result: mr dragged movie far longer necessary aside terrific sea rescue sequences care characters us ghosts closet character realized early forgotten much later time care character really care problem comes kid thinks hes better anyone else around shows signs closet appears winning finally well past half way point stinker tells us ghosts told driven best prior magic could keep turning hour\n"]}],"source":["de_res = tokenizer.decode(\n","    ids                 = tokenizer.encode(sequence=tokenize(a),  is_pretokenized = True).ids,\n","    skip_special_tokens = True\n",")\n","print(f\"Decode result: {de_res}\")"]},{"cell_type":"markdown","metadata":{"id":"2x6od9HJOBOr"},"source":["Теперь мы готовы создать обёртку-датасет для наших данных.\n","\n","Необходимо добавить несколько опций, которые понадобятся во второй части задания:\n","1. Ограничение на максимальную длину текста в токенах. Если текст оказывается длиннее, то последние токены отбрасываются. Иметь ограничение на максимальную длину бывает полезно, так вы имеете гарантии, что во время обучения не засэмплируется очень большой батч, после которого упадет обучение с ошибкой **CUDA error: out of memory**. Кроме того, вы гарантированно знаете на контекстах какой длины обучалась модель, то есть если на валидации вам подасться текст большей длины, то он гарантировано будет отличаться от обучащей выборки.\n","2. Возможность добавить в специальные токены `<sos>`, `<eos>` в начало и конец токенизированного текста\n","    \n","**tips:**\n","1. В исходных данных рейтинг закодирован в названии файла в виде числа от $1$ до $10$. Для удобства, вычтите $1$, чтобы рейтинг был от $0$ до $9$"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uUL6XRLxOBOs"},"outputs":[],"source":["class LargeMovieReviewDataset(Dataset):\n","    def __init__(self, data_path, tokenizer, max_len, pad_sos=False, pad_eos=False):\n","        \"\"\"\n","        :param str data_path: Path to folder with one of the data splits (train or test)\n","        :param tokenizers.tokenizer: tokenizer with lookup_indices method\n","        :param int max_len: Maximum length of tokenized text\n","        :param bool pad_sos: If True pad sequence at the beginning with <sos>\n","        :param bool pad_eos: If True pad sequence at the end with <eos>\n","        \"\"\"\n","        super().__init__()\n","\n","        self.pad_sos = pad_sos\n","        if self.pad_sos:\n","            self.sos_id = tokenizer.token_to_id('<sos>')\n","        self.pad_eos = pad_eos\n","        if self.pad_eos:\n","            self.eos_id = tokenizer.token_to_id('<eos>')\n","\n","        self.tokenizer = tokenizer\n","        self.max_len   = max_len\n","        self.data_path = data_path\n","        self.negative_path = os.path.join(data_path, 'neg')\n","        self.positive_path = os.path.join(data_path, 'pos')\n","\n","        self.negative_paths = []\n","        self.positive_paths = []\n","\n","        for file_path in os.listdir(self.negative_path):\n","            self.negative_paths.append(os.path.join(self.negative_path, file_path))\n","\n","        for file_path in os.listdir(self.positive_path):\n","            self.positive_paths.append(os.path.join(self.positive_path, file_path))\n","\n","        self.negative_paths = sorted(self.negative_paths)\n","        self.positive_paths = sorted(self.positive_paths)\n","\n","        self.texts = []\n","        self.tokens = []\n","        self.ratings = []\n","        self.labels = [0] * len(self.negative_paths) + [1] * len(self.positive_paths)\n","        # Read each file in data_path, tokenize it, get tokens ids, its rating and store\n","        for path in self.negative_paths + self.positive_paths:\n","            # YOUR CODE HERE\n","            text = open(path, mode='r', encoding='utf-8', errors='ignore').read().strip()\n","            ind1 = path.find('_')\n","            ind2 = path.find('.txt')\n","            rating = int(path[ind1 + 1: ind2]) - 1\n","            tok_text = tokenize(text)[:max_len]\n","            self.labels.append(int(path[len(\"./aclImdb/test/\"):len(\"./aclImdb/test/\")+3] == \"pos\"))\n","            if self.pad_sos:\n","                tok_text.insert(0, \"<sos>\")\n","            if self.pad_eos:\n","                tok_text.append(\"<eos>\")\n","            self.ratings.append(rating)\n","            self.texts.append(text)\n","            self.tokens.append(tok_text)\n","\n","    def __getitem__(self, idx):\n","        \"\"\"\n","        :param int idx: index of object in dataset\n","        :return dict: Dictionary with all useful object data\n","            {\n","                'text' str: unprocessed text,\n","                'label' torch.Tensor(dtype=torch.long): sentiment of the text (0 for negative, 1 for positive)\n","                'rating' torch.Tensor(dtype=torch.long): rating of the text\n","                'tokens' torch.Tensor(dtype=torch.long): tensor of tokens ids for the text\n","                'tokens_len' torch.Tensor(dtype=torch.long): number of tokens\n","            }\n","        \"\"\"\n","        # YOUR CODE HERE\n","        # Do not forget to add <sos> and <eos> if needed!\n","        token_ids = self.tokenizer.encode(self.tokens[idx],  is_pretokenized = True).ids\n","        tokens_len = len(self.tokens[idx])\n","        return {\n","            'text': self.texts[idx],\n","            'label': torch.tensor(self.labels[idx], dtype=torch.long),\n","            'tokens': torch.tensor(token_ids, dtype=torch.long),\n","            'tokens_len': torch.tensor(len(self.tokens[idx]), dtype=torch.long),\n","            'rating': torch.tensor(self.ratings[idx], dtype=torch.long),\n","        }\n","\n","    def __len__(self):\n","        \"\"\"\n","        :return int: number of objects in dataset\n","        \"\"\"\n","        # YOUR CODE HERE\n","        return len(self.texts)"]},{"cell_type":"markdown","metadata":{"id":"7rRbEIGhOBOs"},"source":["Создайте датасеты для тестовой и обучающей выборки.\n","\n","Обратите внимание, что для задачи классификации нам не потребуется дополнять текст с помощью `<sos>`, `<eos>`. Эти токены отвечают за обозначение начала последовательности (**start of sequence**) и её конца (**end of sequence**). При моделировании языка нам будет необходимо уметь понимать где начался и закончился текст. Например, предложения часто начинаются со слова **\"однажды\"** и крайне редко со слова **\"щекотать\"**, аналогично про конец предложения.\n","\n","Не забудьте обрезать длинные тексты, передав параметр `max_length`."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7J9_q2vaOBOs"},"outputs":[],"source":["# YOUR CODE HERE\n","test_dataset = LargeMovieReviewDataset(\"./aclImdb/test\", tokenizer, max_length)\n","train_dataset = LargeMovieReviewDataset(\"./aclImdb/train\", tokenizer, max_length)"]},{"cell_type":"markdown","metadata":{"id":"njNk5hQoOBOs"},"source":["Посмотрим, как выглядит объект в датасете:"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1744808712283,"user":{"displayName":"ГУЩИН СТАНИСЛАВ АЛЕКСЕЕВИЧ","userId":"03202281510855514510"},"user_tz":-180},"id":"dSl0R7YHOBOs","outputId":"12aad37a-9f01-4bb4-a800-8e629381ae51"},"outputs":[{"data":{"text/plain":["{'text': \"This film lacked something I couldn't put my finger on at first: charisma on the part of the leading actress. This inevitably translated to lack of chemistry when she shared the screen with her leading man. Even the romantic scenes came across as being merely the actors at play. It could very well have been the director who miscalculated what he needed from the actors. I just don't know.<br /><br />But could it have been the screenplay? Just exactly who was the chef in love with? He seemed more enamored of his culinary skills and restaurant, and ultimately of himself and his youthful exploits, than of anybody or anything else. He never convinced me he was in love with the princess.<br /><br />I was disappointed in this movie. But, don't forget it was nominated for an Oscar, so judge for yourself.\",\n"," 'label': tensor(0),\n"," 'tokens': tensor([   3, 3001,   52,  286,  162, 3631,   20, 3270,   78,  837,  414, 4941,\n","            1,  438, 1041,    1,  179,  837,   50,    7,  606,   51,  260,  475,\n","         1361,   61,  186,   26,   14,   80,    1,  744,   61,   21,    1,   26,\n","          792,  478,    1,   36,  332,    1,    1, 1845, 3312, 1029,    1,    1,\n","         1587,  133,  220,   35, 2438,   36,    1,  571,    2,   21,  700, 2204,\n","          754, 1526]),\n"," 'tokens_len': tensor(62),\n"," 'rating': tensor(3)}"]},"execution_count":25,"metadata":{},"output_type":"execute_result"}],"source":["train_dataset[2]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1744808712288,"user":{"displayName":"ГУЩИН СТАНИСЛАВ АЛЕКСЕЕВИЧ","userId":"03202281510855514510"},"user_tz":-180},"id":"Q-Vxc5bIOBOs","outputId":"571d935b-7303-49e9-8df8-8b8a782d5284"},"outputs":[{"data":{"text/plain":["{'text': \"Once again Mr. Costner has dragged out a movie for far longer than necessary. Aside from the terrific sea rescue sequences, of which there are very few I just did not care about any of the characters. Most of us have ghosts in the closet, and Costner's character are realized early on, and then forgotten until much later, by which time I did not care. The character we should really care about is a very cocky, overconfident Ashton Kutcher. The problem is he comes off as kid who thinks he's better than anyone else around him and shows no signs of a cluttered closet. His only obstacle appears to be winning over Costner. Finally when we are well past the half way point of this stinker, Costner tells us all about Kutcher's ghosts. We are told why Kutcher is driven to be the best with no prior inkling or foreshadowing. No magic here, it was all I could do to keep from turning it off an hour in.\",\n"," 'label': tensor(0),\n"," 'tokens': tensor([ 337,    1, 3161,    2,  127,  993, 1552, 1077, 1151, 1517, 1962,  714,\n","          339,   28,   77, 2744, 4163,    1,   34, 1497,  290, 1402,   13,  200,\n","            9,  339,   34,   10,  339,    1,    1,    1,    1,  325,  158,  423,\n","         1062,  130,   45,  147,  220,   88,  155, 3526,    1, 4163,    1,  588,\n","         1818,    1,  322,   14,  387,  239,   27,  123, 3884,    1,  574,   77,\n","            1, 2744,  435,    1, 2439,   40, 2333,    1,    1, 1169,   26,  269,\n","         1423,  429]),\n"," 'tokens_len': tensor(74),\n"," 'rating': tensor(1)}"]},"execution_count":26,"metadata":{},"output_type":"execute_result"}],"source":["test_dataset[0]"]},{"cell_type":"markdown","metadata":{"id":"XexfPP0FOBOs"},"source":["Теперь нам нужно создать `DataLoader` для наших данных. `DataLoader` умеет из коробки объединять список объектов из датасета в один батч, даже когда датасет возвращает словарь тензоров. Однако, это работает только в случае когда все эти тензоры имеют один и тот же размер во всех батчах. В нашем случае, это не так, так как разные тексты могут иметь разную длину.\n","\n","Чтобы обойти эту проблему у `DataLoader` есть параметр `collate_fn`, который позволяет задать функцию для объединения списка объектов в один батч.\n","\n","**tips**\n","1. Обратите свое внимание на функцию `torch.stack`, она позволяет \"застакать\" элементы списка в тензор"]},{"cell_type":"markdown","metadata":{"id":"Vl9p1BWvOBOt"},"source":["Чтобы объединить несколько тензоров разной длины в один можно использовать функцию `torch.nn.utils.rnn.pad_sequence`. Такой формат позволит удобно передавать данные в rnn модель.\n","\n","Обратите внимание на её аргументы:\n","1. `batch_first` определяет по какой оси \"складывать\" тензоры. Предпочтительнее использовать `batch_first=False` так как это может упростить выполнение задания в дальнейшем\n","2. `padding_value` — число, которое будет использоваться в качестве паддинга, чтобы сделать все тензоры одинаковой длины\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1744808712292,"user":{"displayName":"ГУЩИН СТАНИСЛАВ АЛЕКСЕЕВИЧ","userId":"03202281510855514510"},"user_tz":-180},"id":"SqS9PIYvOBOt","outputId":"169e47c3-e378-4394-e292-c6c9440e9e5d"},"outputs":[{"name":"stdout","output_type":"stream","text":["batch_first=False\n","Shape = torch.Size([4, 3])\n","tensor([[ 1,  4,  6],\n","        [ 2,  5,  7],\n","        [ 3, -1,  8],\n","        [-1, -1,  9]])\n","batch_first=True\n","Shape = torch.Size([3, 4])\n","tensor([[ 1,  2,  3, -1],\n","        [ 4,  5, -1, -1],\n","        [ 6,  7,  8,  9]])\n"]}],"source":["elemets = [\n","    torch.tensor([1, 2, 3]),\n","    torch.tensor([4, 5]),\n","    torch.tensor([6, 7, 8, 9])\n","]\n","\n","out_nbf = torch.nn.utils.rnn.pad_sequence(\n","    elemets,\n","    batch_first   = False,\n","    padding_value = -1\n",")\n","\n","out_bf = torch.nn.utils.rnn.pad_sequence(\n","    elemets,\n","    batch_first   = True,\n","    padding_value = -1\n",")\n","\n","print(f\"batch_first=False\")\n","print(f\"Shape = {out_nbf.shape}\")\n","print(out_nbf)\n","\n","print(f\"batch_first=True\")\n","print(f\"Shape = {out_bf.shape}\")\n","print(out_bf)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"p6kgDVCMOBOt"},"outputs":[],"source":["from torch.nn.utils.rnn import pad_sequence\n","def my_collate_fn(batch, padding_value, batch_first=False):\n","    \"\"\"\n","    :param List[Dict] batch: List of objects from dataset\n","    :param int padding_value: Value that will be used to pad tokens\n","    :param bool batch_first: If True resulting tensor with tokens must have shape [B, T] otherwise [T, B]\n","    :return dict: Dictionary with all data collated\n","        {\n","            'ratings' torch.Tensor(dtype=torch.long): rating of the text for each object in batch\n","            'labels' torch.Tensor(dtype=torch.long): sentiment of the text for each object in batch\n","\n","            'texts' List[str]: All texts in one list\n","            'tokens' torch.Tensor(dtype=torch.long): tensor of tokens ids padded with @padding_value\n","            'tokens_lens' torch.Tensor(dtype=torch.long): number of tokens for each object in batch\n","        }\n","    \"\"\"\n","    # YOUR CODE HERE\n","    ratings = []\n","    labels = []\n","    texts = []\n","    tokens = []\n","    tokens_lens = []\n","\n","    for item in batch:\n","        ratings.append(item['rating'])\n","        labels.append(item['label'])\n","        texts.append(item['text'])\n","        tokens.append(item['tokens'])\n","        tokens_lens.append(item['tokens_len'])\n","\n","    ratings = torch.stack(ratings, dim=0)\n","    labels = torch.stack(labels, dim=0)\n","    tokens = pad_sequence(tokens, batch_first=batch_first, padding_value=padding_value)\n","    tokens_lens = torch.stack(tokens_lens, dim=0)\n","\n","\n","    collate_dict = {\n","        'ratings': ratings,\n","        'labels': labels,\n","        \"texts\": texts,\n","        'tokens': tokens,\n","        'tokens_lens': tokens_lens,\n","    }\n","    return collate_dict"]},{"cell_type":"markdown","metadata":{"id":"9BLYVY7oOBOt"},"source":["Создайте даталоадеры с использованием `collate_fn`.\n","\n","**tips**:\n","1. Передать в `collate_fn` правильное значение паддинга можно, например, с помощью `functools.partial`\n","2. Если вы работаете в Google Colab, то, возможно, вам будет необходимо установить `num_workers=0` во избежание падения ноутбука.\n","3. Для определения индекса `<pad>` надо использовать `tokenizer.token_to_id('<pad>')`, а не магическую константу 0."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"N0JCo3YSOBOt"},"outputs":[],"source":["# YOUR CODE HERE\n","collate = lambda batch: my_collate_fn(batch, tokenizer.token_to_id(\"<pad>\"), batch_first=False)\n","test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=0, collate_fn = collate)\n","train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0, collate_fn = collate)"]},{"cell_type":"markdown","metadata":{"id":"g8pd_UFHOBOt"},"source":["Посмотрим на какой-нибудь батч:"]},{"cell_type":"markdown","metadata":{"id":"SNN8y7FuOBOu"},"source":["# `Часть 1. Классификация текстов (4 балла)`"]},{"cell_type":"markdown","metadata":{"id":"daVid2YOOBOu"},"source":["В этой части вы обучите классификатор текстов на основе рекуррентной нейронной сети. Выше мы уже создали удобные класс-обёртки для работы с данными. Теперь мы соберем модель для решения задачи классификации. Вам предлагается решить задачу предсказания **рейтинга фильма** (классы 0 до 9), то есть мы решаем задачу многоклассовой классификации."]},{"cell_type":"markdown","metadata":{"id":"-muyT5jROBOu"},"source":["## `Сборка и обучение RNN в pytorch (1 балл)`"]},{"cell_type":"markdown","metadata":{"id":"acD4VW_pOBOu"},"source":["Создадим переменные для device-agnostic кода:"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1744808712329,"user":{"displayName":"ГУЩИН СТАНИСЛАВ АЛЕКСЕЕВИЧ","userId":"03202281510855514510"},"user_tz":-180},"id":"klcx8VHcOBOu","outputId":"9de1b704-d3c8-456e-91e7-d0bdd5fd5306"},"outputs":[{"name":"stdout","output_type":"stream","text":["Using device: cpu, dtype: torch.float32\n"]}],"source":["dtype, device, cuda_device_id = torch.float32, None, 0\n","os.environ[\"CUDA_VISIBLE_DEVICES\"] = '{0}'.format(str(cuda_device_id) if cuda_device_id is not None else '')\n","if cuda_device_id is not None and torch.cuda.is_available():\n","    device = 'cuda:{0:d}'.format(0)\n","else:\n","    device = torch.device('cpu')\n","print(f'Using device: {device}, dtype: {dtype}')"]},{"cell_type":"markdown","metadata":{"id":"I49GllLZOBOu"},"source":["Наша нейросеть будет обрабатывать входную последовательность по словам (word level). Мы будем использовать простую и стандартную рекуррентную архитектуру для классификации:\n","1. Слой представлений, превращающий id токена в вектор-эмбеддинг этого слова\n","2. Слой LSTM\n","3. Полносвязный слой, предсказывающий выход по последнему скрытому состоянию\n","\n","Ниже дан код для сборки и обучения нашей нейросети."]},{"cell_type":"markdown","metadata":{"id":"1zwA8smiOBOu"},"source":["Допишите класс-обёртку над LSTM для задачи классификации.\n","**Не используйте циклы.**"]},{"cell_type":"markdown","metadata":{"id":"TSI3pSPAOBOv"},"source":["**Для каждого тензора в функции `forward` подпишите в комментарии его размеры**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-LTr24yZOBOw"},"outputs":[],"source":["class RNNClassifier(torch.nn.Module):\n","    def __init__(\n","        self, embedding_dim, hidden_dim, output_size, tokenizer,\n","        rec_layer=torch.nn.LSTM, dropout=None, **kwargs\n","    ):\n","        super().__init__()\n","\n","        self.dropout = dropout\n","\n","        self.tokenizer = tokenizer\n","        self.hidden_dim = hidden_dim\n","        self.output_size = output_size\n","        self.embedding_dim = embedding_dim\n","\n","        # Create a simple lookup table that stores embeddings of a fixed dictionary and size.\n","        #    Use torch.nn.Embedding. Do not forget specify padding_idx!\n","        # YOUR CODE HERE\n","        self.word_embeddings = torch.nn.Embedding(self.tokenizer.get_vocab_size(), self.embedding_dim, padding_idx=self.tokenizer.token_to_id(\"<pad>\"))\n","        # Add **kwargs in rec_layer constructor\n","        if dropout is not None:\n","            self.rnn = rec_layer(\n","                input_size=self.embedding_dim,\n","                hidden_size=self.hidden_dim,\n","                dropout=dropout,\n","                **kwargs,\n","                )\n","        else:\n","            self.rnn = rec_layer(\n","                input_size=self.embedding_dim,\n","                hidden_size=self.hidden_dim,\n","                dropout=0.0,\n","                **kwargs,\n","                )\n","\n","        # Create linear layer for classification\n","        # YOUR CODE HERE\n","        self.Linear = torch.nn.Linear(self.hidden_dim, self.output_size, bias=True)\n","    def forward(self, tokens, tokens_lens):\n","        \"\"\"\n","        :param torch.Tensor(dtype=torch.long) tokens: Batch of texts represented with tokens.\n","        :param torch.Tensor(dtype=torch.long) tokens_lens: Number of non-padding tokens for each object in batch.\n","        :return torch.Tensor(dtype=torch.long): Vector representation for each sequence in batch\n","        \"\"\"\n","        # Evaluate embeddings\n","        # YOUR CODE HERE\n","\n","        # tokens.shape = [seg_len, batch_size]\n","        # embedings.shape = [seg_len, batch_size, embedding_dim]\n","        embedings = self.word_embeddings(tokens)\n","\n","\n","        # Make forward pass through recurrent network\n","        # YOUR CODE HERE\n","\n","\n","        # output.shape = [seg_len, batch_size, embedding_dim] ~ embedding.shape\n","        # hn.shape = [num_layers, batch_size, hidden_dim]\n","        # cn.shape = [num_layers, batch_size, hidden_dim]\n","        output, (hn, cn) = self.rnn(embedings) # h_n: [num_layers, batch_size, hidden_dim]\n","        output_linear = self.Linear(hn.squeeze(0))\n","\n","        # Pass output from rnn to linear layer\n","        # Note: each object in batch has its own length\n","        #     so we must take rnn hidden state after the last token for each text in batch\n","        # YOUR CODE HERE\n","        return output_linear\n"]},{"cell_type":"markdown","metadata":{"id":"QIPvArexOBOw"},"source":["[Исходный код LSTM](http://pytorch.org/docs/master/_modules/torch/nn/modules/rnn.html#LSTM)"]},{"cell_type":"markdown","metadata":{"id":"dhpP4TgiOBOw"},"source":["Допишите функции для обучения и оценки модели:\n","\n","**tip:**\n","1. В функции `evaluate` при подсчёте метрик учитывайте, что батчи могут иметь разный размер. (в частности последний батч)\n","\n","**Важно:** Мы предсказываем `rating`, не `label`."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PUZtI0RdOBOw"},"outputs":[],"source":["def train_epoch(dataloader, model, loss_fn, optimizer, device):\n","    model.train()\n","    for idx, data in enumerate(dataloader):\n","        # 1. Take data from batch\n","        # 2. Perform forward pass\n","        # 3. Evaluate loss\n","        # 4. Make optimizer step\n","        # YOUR CODE HERE\n","\n","\n","        ratings = data['ratings'].long().to(device)\n","        tokens_lens = data['tokens_lens'].to(device)\n","        data_tokens = data['tokens'].to(device)\n","\n","        optimizer.zero_grad()\n","        output = model(data_tokens, tokens_lens)\n","        loss = loss_fn(output, ratings)\n","        loss.backward()\n","        optimizer.step()\n","\n","def evaluate(dataloader, model, loss_fn, device):\n","    model.eval()\n","\n","    total_loss = 0.0\n","    total_accuracy = 0.0\n","    with torch.no_grad():\n","        for idx, data in enumerate(dataloader):\n","            # 1. Take data from batch\n","            # 2. Perform forward pass\n","            # 3. Evaluate loss\n","            # 4. Evaluate accuracy\n","            # YOUR CODE HERE\n","            ratings = data['ratings'].long().to(device)\n","            tokens_lens = data['tokens_lens'].to(device)\n","            data_tokens = data['tokens'].to(device)\n","\n","            output = model(data_tokens, tokens_lens)\n","            preds = torch.argmax(output, dim=1)\n","            total_accuracy += (preds == ratings).sum()\n","\n","            loss = loss_fn(output, ratings)\n","            total_loss += loss.item() * len(tokens_lens)\n","\n","    return total_loss / len(dataloader.dataset), total_accuracy / len(dataloader.dataset)\n","\n","\n","def train(\n","    train_loader, test_loader, model, loss_fn, optimizer, device, num_epochs\n","):\n","    test_losses = []\n","    train_losses = []\n","    test_accuracies = []\n","    train_accuracies = []\n","    for epoch in range(num_epochs):\n","        train_epoch(train_loader, model, loss_fn, optimizer, device)\n","\n","        train_loss, train_acc = evaluate(train_loader, model, loss_fn, device)\n","        train_accuracies.append(train_acc)\n","        train_losses.append(train_loss)\n","\n","        test_loss, test_acc = evaluate(test_loader, model, loss_fn, device)\n","        test_accuracies.append(test_acc)\n","        test_losses.append(test_loss)\n","\n","        print(\n","            'Epoch: {0:d}/{1:d}. Loss (Train/Test): {2:.3f}/{3:.3f}. Accuracy (Train/Test): {4:.3f}/{5:.3f}'.format(\n","                epoch + 1, num_epochs, train_losses[-1], test_losses[-1], train_accuracies[-1], test_accuracies[-1]\n","            )\n","        )\n","    return train_losses, train_accuracies, test_losses, test_accuracies"]},{"cell_type":"markdown","metadata":{"id":"IOe1OgRbOBOw"},"source":["Создадим модель:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"b_roSQ3uOBOw"},"outputs":[],"source":["set_global_seed(42)\n","\n","model = RNNClassifier(\n","    embedding_dim=embedding_dim, hidden_dim=hidden_dim, output_size=10, tokenizer=tokenizer,\n","    rec_layer=torch.nn.LSTM, dropout=None\n",").to(device)\n","\n","check_numel(model, 244234, 0)"]},{"cell_type":"markdown","metadata":{"id":"RyicyyMvOBOw"},"source":["Создадим класс для подсчёта функции потерь и оптимизатор:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OYaCzV9ZOBOw"},"outputs":[],"source":["loss_fn = torch.nn.CrossEntropyLoss(reduction='mean')\n","optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"]},{"cell_type":"markdown","metadata":{"id":"4ZXnaUxKOBOx"},"source":["Попробуем обучить модель:"]},{"cell_type":"markdown","metadata":{"id":"Npbwe50yOBOx"},"source":["**Сохраните все метрики и время работы модели. Это потребуется в конце первой части для построения графиков обучения и сравнения времени работы для всех моделей в этой секции**\n","\n","**Возможно стоит сохранить результаты в виде файлов и скачать их**\n","\n","**Обратите внимание, что надо сохранить и время**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":416427,"status":"ok","timestamp":1744792697241,"user":{"displayName":"Станислав Гущин","userId":"15072888739243516419"},"user_tz":-180},"id":"PhE9gptJOBOx","outputId":"99cd25a5-3738-45e2-880b-91231a70ff2d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch: 1/15. Loss (Train/Test): 2.027/2.026. Accuracy (Train/Test): 0.209/0.202\n","Epoch: 2/15. Loss (Train/Test): 2.009/2.013. Accuracy (Train/Test): 0.214/0.202\n","Epoch: 3/15. Loss (Train/Test): 1.968/1.982. Accuracy (Train/Test): 0.250/0.248\n","Epoch: 4/15. Loss (Train/Test): 1.776/1.810. Accuracy (Train/Test): 0.334/0.327\n","Epoch: 5/15. Loss (Train/Test): 1.659/1.724. Accuracy (Train/Test): 0.367/0.343\n","Epoch: 6/15. Loss (Train/Test): 1.563/1.660. Accuracy (Train/Test): 0.393/0.357\n","Epoch: 7/15. Loss (Train/Test): 1.500/1.658. Accuracy (Train/Test): 0.411/0.358\n","Epoch: 8/15. Loss (Train/Test): 1.436/1.646. Accuracy (Train/Test): 0.429/0.363\n","Epoch: 9/15. Loss (Train/Test): 1.378/1.667. Accuracy (Train/Test): 0.449/0.359\n","Epoch: 10/15. Loss (Train/Test): 1.372/1.700. Accuracy (Train/Test): 0.459/0.358\n","Epoch: 11/15. Loss (Train/Test): 1.249/1.720. Accuracy (Train/Test): 0.504/0.365\n","Epoch: 12/15. Loss (Train/Test): 1.209/1.751. Accuracy (Train/Test): 0.518/0.362\n","Epoch: 13/15. Loss (Train/Test): 1.163/1.853. Accuracy (Train/Test): 0.535/0.351\n","Epoch: 14/15. Loss (Train/Test): 1.102/1.871. Accuracy (Train/Test): 0.561/0.365\n","Epoch: 15/15. Loss (Train/Test): 1.054/1.964. Accuracy (Train/Test): 0.591/0.347\n"]}],"source":["train_losses_pure, train_accuracies_pure, test_losses_pure, test_accuracies_pure = train(\n","    train_dataloader, test_dataloader, model, loss_fn, optimizer, device, num_epochs\n",")"]},{"cell_type":"markdown","metadata":{"id":"O60eLIRaOBOx"},"source":["Нерегуляризованные LSTM часто быстро переобучаются (и мы это видим по точности на контроле). Чтобы с этим бороться, часто используют *L2-регуляризацию* и *дропаут*.\n","Однако способов накладывать дропаут на рекуррентный слой достаточно много, и далеко не все хорошо работают. По [ссылке](https://medium.com/@bingobee01/a-review-of-dropout-as-applied-to-rnns-72e79ecd5b7b) доступен хороший обзор дропаутов для RNN.\n","\n","Мы реализуем два варианта DropOut для RNN (и третий дополнительно). Заодно увидим, что для реализации различных усовершенствований рекуррентной архитектуры приходится \"вскрывать\" слой до различной \"глубины\"."]},{"cell_type":"markdown","metadata":{"id":"wxgNfxU3OBOx"},"source":["## `Реализация дропаута по статье Гала и Гарамани. Variational Dropout (1 балл)`"]},{"cell_type":"markdown","metadata":{"id":"aCKHSR3nOBOx"},"source":["Начнем с дропаута, описанного в [статье Гала и Гарамани](https://arxiv.org/abs/1512.05287).\n","Для этого нам потребуется перейти от использования слоя `torch.nn.LSTM`, полностью скрывающего от нас рекуррентную логику, к использованию слоя `torch.nn.LSTMCell`, обрабатывающего лишь один временной шаг нашей последовательности (а всю логику вокруг придется реализовать самостоятельно).\n","\n","Для начала напишем функцию, которая позволит нам получать $h_0$ и $c_0$, которые мы будем использовать в качестве инициализаций.\n","\n","**tips:**\n","\n","1. Используйте some_existing_tensor, как тензор в котором содержится информация о типе данных, девайсе целевого тензора. Обратите внимание на функцию [new_ones](https://pytorch.org/docs/stable/generated/torch.Tensor.new_ones.html)."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HKhZIE2yOBOx"},"outputs":[],"source":["def init_h0_c0(num_objects, hidden_size, some_existing_tensor):\n","    \"\"\"\n","    return h0 and c0, use some_existing_tensor.new_zeros() to gen them\n","    h0 shape: num_objects x hidden_size\n","    c0 shape: num_objects x hidden_size\n","    \"\"\"\n","    # YOUR CODE HERE\n","    h0 = some_existing_tensor.new_zeros(size=(num_objects, hidden_size))\n","    c0 = some_existing_tensor.new_zeros(size=(num_objects, hidden_size))\n","    return h0, c0"]},{"cell_type":"markdown","metadata":{"id":"l9ZdhKCMOBOx"},"source":["Допишите класс `RNNLayer`. При `dropout=0` ваш класс должен работать как обычный слой LSTM, а при `dropout > 0` накладывать бинарную маску на входной и скрытый вектор на каждом временном шаге, причем эта маска должна быть одинаковой во все моменты времени.\n","\n","Дропаут Гала и Гарамани в виде формул (m обозначает маску дропаута):\n","\n","$$\n","h_{t-1} = h_{t-1}*m_h, \\, x_t = x_t * m_x\n","$$\n","\n","Далее обычный шаг рекуррентной архитектуры, например, LSTM:\n","\n","$$\n","i = \\sigma(h_{t-1}W^i + x_t U^i+b_i) \\quad\n","o = \\sigma(h_{t-1}W^o + x_t U^o+b_o)\n","$$\n","$$\n","f = \\sigma(h_{t-1}W^f + x_t U^f+b_f) \\quad\n","g = tanh(h_{t-1} W^g + x_t U^g+b_g)\n","$$\n","$$\n","c_t = f \\odot c_{t-1} +  i \\odot  g \\quad\n","h_t =  o \\odot tanh(c_t)\n","$$\n","\n","**Важно**: Мы считаем, что объекты в батче независимы, то есть маски для них должны быть разные.\n","\n","**tips:**\n","\n","1. Для получения бернулливской случайной величины достаточно вызвать `.bernoulli()` от массива содержащего вероятности.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vla4ajS5OBOx"},"outputs":[],"source":["def gen_dropout_mask(input_size, hidden_size, is_training, p, some_existing_tensor): # generate 2 masks: [batch_size, input_size], [batch_size, input_size]\n","    \"\"\"\n","    is_training: if True, gen masks from Bernoulli\n","                 if False, gen masks consisting of (1-p)\n","\n","    return dropout masks of size input_size, hidden_size if p is not None\n","    return one masks if p is None\n","    \"\"\"\n","    # YOUR CODE HERE\n","    batch_size = some_existing_tensor.shape[1]\n","    if p == None:\n","        return some_existing_tensor.new_ones(size=(batch_size, input_size)), some_existing_tensor.new_ones(size=(batch_size, hidden_size))\n","\n","    if is_training:\n","        return torch.bernoulli(torch.full(size=(batch_size, input_size), fill_value=1-p)), torch.bernoulli(torch.full(size=(batch_size, hidden_size), fill_value=1-p))\n","\n","    return torch.full(size=(batch_size, input_size), fill_value=1-p), torch.full(size=(batch_size, hidden_size), fill_value=1-p)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":343},"executionInfo":{"elapsed":67,"status":"error","timestamp":1744807837031,"user":{"displayName":"Станислав Гущин","userId":"15072888739243516419"},"user_tz":-180},"id":"Jrol05oVOBOy","outputId":"f7f75904-d239-489e-caea-75b73932abb4"},"outputs":[{"ename":"IndexError","evalue":"tuple index out of range","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-92-469bf63254b6>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mset_global_seed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.12\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_dropout_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m120\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_training\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msome_existing_tensor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-79-98f0dc87990e>\u001b[0m in \u001b[0;36mgen_dropout_mask\u001b[0;34m(input_size, hidden_size, is_training, p, some_existing_tensor)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \"\"\"\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m# YOUR CODE HERE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msome_existing_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msome_existing_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew_ones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msome_existing_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew_ones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mIndexError\u001b[0m: tuple index out of range"]}],"source":["set_global_seed(42)\n","p = 0.12\n","m = gen_dropout_mask(100, 120, is_training=True, p=p, some_existing_tensor=torch.tensor(1.))\n","\n","\n","print(f'm.mean(): {m.mean():0.4f}')\n","assert m.shape == (100, 120)\n","assert (1 - p) - 0.005 <= m.mean() <= (1 - p) + 0.005"]},{"cell_type":"markdown","metadata":{"id":"hTrYfjdeOBOy"},"source":["Допишите класс-обёртку над `LSTMCell` для реализации Variational Dropout. **Используйте только цикл по времени**"]},{"cell_type":"markdown","metadata":{"id":"FngujyQjOBOy"},"source":["**Для каждого тензора в функции `forward` подпишите в комментарии его размеры**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nBBfwQ47OBOy"},"outputs":[],"source":["class RNNLayer(torch.nn.Module):\n","    def __init__(self, input_size, hidden_size, dropout=None):\n","        super().__init__()\n","\n","        self.dropout = dropout\n","        self.input_size = input_size\n","        self.hidden_size = hidden_size\n","\n","        self.rnn_cell = torch.nn.LSTMCell(self.input_size, self.hidden_size)\n","\n","    def forward(self, x):\n","        # Initialize h_0, c_0\n","        # YOUR CODE HERE\n","\n","        # x.shape = [seq_len, batch_size, embedding_size]\n","        h_0, c_0 = init_h0_c0(x.shape[1], self.hidden_size, x)\n","        # Gen masks for input and hidden state\n","        # YOUR CODE HERE\n","        mask_input, mask_hidden = gen_dropout_mask(self.input_size, self.hidden_size, is_training=True, p=self.dropout, some_existing_tensor=x)\n","        # Implement recurrent logic and return what nn.LSTM returns\n","        # Do not forget to apply generated dropout masks!\n","        # YOUR CODE HERE\n","        h, c = h_0, c_0\n","        x_t = x\n","        output_h = []\n","        for t in range(x.shape[0]):\n","            x_t = x[t]\n","            h, c = self.rnn_cell(x_t * mask_input, (h * mask_hidden, c))\n","            output_h.append(h.unsqueeze(0))\n","        output_h = torch.cat(output_h, dim=0)\n","        return output_h, (h, c)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xJzurwqZOBOy"},"outputs":[],"source":["layer = RNNLayer(32, 64, dropout=None)\n","dummy_input = torch.ones((10, 16, 32)) # [seq_len, batch_size, embedding_len]\n","\n","out = layer(dummy_input)\n","\n","assert out[0].shape == (10, 16, 64)\n","assert out[1][0].shape == (16, 64)\n","assert out[1][1].shape == (16, 64)"]},{"cell_type":"markdown","metadata":{"id":"lugHIgwcOBOy"},"source":["Протестируйте реализованную модель с выключенным дропаутом (слой `RNNLayer` надо передать в `RNNClassifier` в качестве `rec_layer`). Замерьте время обучения. Сильно ли оно увеличилось по сравнению с `torch.nn.LSTM` (LSTM \"из коробки\")?"]},{"cell_type":"markdown","metadata":{"id":"gtOud3FNOBOy"},"source":["**Сохраните все метрики и время работы модели. Это потребуется в конце первой части для построения графиков обучения и сравнения времени работы для всех моделей в этой секции**\n","\n","**Возможно стоит сохранить результаты в виде файлов и скачать их**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VGZ9ilLzOBOy"},"outputs":[],"source":["set_global_seed(42)\n","\n","# YOUR CODE HERE\n","\n","model_first = RNNClassifier(\n","    embedding_dim=embedding_dim, hidden_dim=hidden_dim, output_size=10, tokenizer=tokenizer,\n","    rec_layer=RNNLayer, dropout=None\n",").to(device)\n","\n","\n","loss_fn = torch.nn.CrossEntropyLoss(reduction='mean')\n","optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NYHjzag4q9Ho"},"outputs":[],"source":["def train_epoch(dataloader, model, loss_fn, optimizer, device):\n","    model.train()\n","    for idx, data in enumerate(dataloader):\n","        # 1. Take data from batch\n","        # 2. Perform forward pass\n","        # 3. Evaluate loss\n","        # 4. Make optimizer step\n","        # YOUR CODE HERE\n","\n","\n","        ratings = data['ratings'].long().to(device)\n","        tokens_lens = data['tokens_lens'].to(device)\n","        data_tokens = data['tokens'].to(device)\n","\n","        optimizer.zero_grad()\n","        output = model(data_tokens, tokens_lens)\n","        loss = loss_fn(output, ratings)\n","        loss.backward()\n","        optimizer.step()\n","\n","def evaluate(dataloader, model, loss_fn, device):\n","    model.eval()\n","\n","    total_loss = 0.0\n","    total_accuracy = 0.0\n","    with torch.no_grad():\n","        for idx, data in enumerate(dataloader):\n","            # 1. Take data from batch\n","            # 2. Perform forward pass\n","            # 3. Evaluate loss\n","            # 4. Evaluate accuracy\n","            # YOUR CODE HERE\n","            ratings = data['ratings'].long().to(device)\n","            tokens_lens = data['tokens_lens'].to(device)\n","            data_tokens = data['tokens'].to(device)\n","\n","            output = model(data_tokens, tokens_lens)\n","            preds = torch.argmax(output, dim=1)\n","            total_accuracy += (preds == ratings).sum()\n","\n","            loss = loss_fn(output, ratings)\n","            total_loss += loss.item() * len(tokens_lens)\n","\n","    return total_loss / len(dataloader.dataset), total_accuracy / len(dataloader.dataset)\n","\n","\n","def train(\n","    train_loader, test_loader, model, loss_fn, optimizer, device, num_epochs\n","):\n","    test_losses = []\n","    train_losses = []\n","    test_accuracies = []\n","    train_accuracies = []\n","    for epoch in range(num_epochs):\n","        train_epoch(train_loader, model, loss_fn, optimizer, device)\n","\n","        train_loss, train_acc = evaluate(train_loader, model, loss_fn, device)\n","        train_accuracies.append(train_acc)\n","        train_losses.append(train_loss)\n","\n","        test_loss, test_acc = evaluate(test_loader, model, loss_fn, device)\n","        test_accuracies.append(test_acc)\n","        test_losses.append(test_loss)\n","\n","        print(\n","            'Epoch: {0:d}/{1:d}. Loss (Train/Test): {2:.3f}/{3:.3f}. Accuracy (Train/Test): {4:.3f}/{5:.3f}'.format(\n","                epoch + 1, num_epochs, train_losses[-1], test_losses[-1], train_accuracies[-1], test_accuracies[-1]\n","            )\n","        )\n","    return train_losses, train_accuracies, test_losses, test_accuracies"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"1qf3l1t6rAFE","outputId":"2d9c27f1-2709-49c0-b7b8-a3b1e6b2392b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch: 1/15. Loss (Train/Test): 2.311/2.312. Accuracy (Train/Test): 0.118/0.110\n","Epoch: 2/15. Loss (Train/Test): 2.311/2.312. Accuracy (Train/Test): 0.118/0.110\n","Epoch: 3/15. Loss (Train/Test): 2.311/2.312. Accuracy (Train/Test): 0.118/0.110\n","Epoch: 4/15. Loss (Train/Test): 2.311/2.312. Accuracy (Train/Test): 0.118/0.110\n","Epoch: 5/15. Loss (Train/Test): 2.311/2.312. Accuracy (Train/Test): 0.118/0.110\n","Epoch: 6/15. Loss (Train/Test): 2.311/2.312. Accuracy (Train/Test): 0.118/0.110\n","Epoch: 7/15. Loss (Train/Test): 2.311/2.312. Accuracy (Train/Test): 0.118/0.110\n"]}],"source":["train_losses_pure, train_accuracies_pure, test_losses_pure, test_accuracies_pure = train(\n","    train_dataloader, test_dataloader, model_first, loss_fn, optimizer, device, num_epochs\n",")"]},{"cell_type":"markdown","metadata":{"id":"N0ZmmzEPOBOy"},"source":["Протестируйте полученную модель с `dropout=0.25`, вновь замерив время обучения. Получилось ли побороть переобучение? Сильно ли дольше обучается данная модель по сравнению с предыдущей? (доп. время тратится на генерацию масок дропаута)."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AfgExGh7OBOz"},"outputs":[],"source":["set_global_seed(42)\n","\n","# YOUR CODE HERE\n","..."]},{"cell_type":"markdown","metadata":{"id":"zKGz59EoOBOz"},"source":["## `Реализация дропаута по статье Гала и Гарамани. Дубль 2 (1 балл)`"]},{"cell_type":"markdown","metadata":{"id":"xd4jh3_3OBOz"},"source":["<начало взлома pytorch>"]},{"cell_type":"markdown","metadata":{"id":"W1IQv7izOBOz"},"source":["При разворачивании цикла по времени средствами python обучение рекуррентной нейросети сильно замедляется. Однако для реализации дропаута Гала и Гарамани необязательно явно задавать в коде умножение нейронов на маски. Можно схитрить и обойтись использованием слоя `torch.nn.LSTM`: перед вызовом `forward` слоя `torch.nn.LSTM` подменять его веса на веса, домноженные **по строкам** на маски. А обучаемые веса хранить отдельно. Именно так этот дропаут реализован в библиотеке `fastai`, код из которой использован в ячейке ниже.\n","\n","Благодаря такому подходу мы используем быстрый код слоя `torch.nn.LSTM`, который гарантировано написан хорошо и правильно, но подменяем веса так, чтобы получить необходимый эффект.\n","\n","Для начала посмотрим на стандартный слой `nn.LSTM` и вспомним дропаут Гала и Гарамани (m обозначает маску дропаута):\n","\n","$$\n","h_{t-1} = h_{t-1}*m_h, \\, x_t = x_t * m_x\n","$$\n","\n","Далее обычный шаг рекуррентной архитектуры, например, LSTM:\n","\n","$$\n","i = \\sigma(h_{t-1}W^i + x_t U^i+b_i) \\quad\n","o = \\sigma(h_{t-1}W^o + x_t U^o+b_o)\n","$$\n","$$\n","f = \\sigma(h_{t-1}W^f + x_t U^f+b_f) \\quad\n","g = tanh(h_{t-1} W^g + x_t U^g+b_g)\n","$$\n","$$\n","c_t = f \\odot c_{t-1} +  i \\odot  g \\quad\n","h_t =  o \\odot tanh(c_t)\n","$$"]},{"cell_type":"markdown","metadata":{"id":"0oP4dw0bOBOz"},"source":["Сначал посмотрим на параметры слоя `nn.LSTM`."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IFymrz6_OBOz"},"outputs":[],"source":["lstm = torch.nn.LSTM(embedding_dim, hidden_dim, num_layers=2)\n","\n","for tag, p in lstm.named_parameters():\n","    print(f\"{tag:<12}: {p.shape}\")"]},{"cell_type":"markdown","metadata":{"id":"eiJN-_ujOBOz"},"source":["Подробнее про каждый отдельный модуль можно почитать на [официальной странице](https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html), важно, что умножая каждую строку весов **weight\\_\\*\\*\\_\\*\\*** на маску, мы получим те же вычисления, что и при умножении $h_{t-1}$ и $x_t$ на маску. Для проверки этого факта рассмотрим игрушечный пример:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yaWM6lEpOBOz"},"outputs":[],"source":["set_global_seed(42)\n","\n","W = torch.randn((hidden_dim * 4, hidden_dim))\n","x = torch.arange(hidden_dim).float()\n","mask = (torch.arange(hidden_dim) % 2 == 0).long()\n","\n","res1 = W @ (x * mask)\n","\n","res2 = (W * mask[None, :]) @ x\n","\n","torch.isclose(res1, res2).all()"]},{"cell_type":"markdown","metadata":{"id":"18DkIiUAOBOz"},"source":["Реализуйте слой, который с помощью подмены весов реализует  дропаут Гала и Гарамани, в виде обертки над `torch.nn.LSTM`. Допишите класс:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gosFQZ8zOBO0"},"outputs":[],"source":["import warnings"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OBlmSHUiOBO0"},"outputs":[],"source":["class FastRNNLayer(torch.nn.Module):\n","    def __init__(self, input_size, hidden_size, dropout=0.0, layers_dropout=0.0, num_layers=1):\n","        super().__init__()\n","\n","        self.input_size = input_size\n","        self.hidden_size = hidden_size\n","\n","        self.num_layers = num_layers\n","\n","        self.dropout = dropout\n","        self.layers_dropout = layers_dropout\n","        self.module = torch.nn.LSTM(input_size, hidden_size, dropout=layers_dropout, num_layers=num_layers)\n","\n","        self.layer_names = []\n","        for layer_n in range(self.num_layers):\n","            self.layer_names += [f'weight_hh_l{layer_n}', f'weight_ih_l{layer_n}']\n","\n","        for layer in self.layer_names:\n","            # Get torch.nn.Parameter with weights from torch.nn.LSTM instance\n","            w = getattr(self.module, layer)\n","\n","            # Remove it from model\n","            delattr(self.module, layer)\n","\n","            # And create new torch.nn.Parameter with the same data but different name\n","            self.register_parameter(f'{layer}_raw', torch.nn.Parameter(w.data))\n","\n","            # Note. In torch.nn.LSTM.forward parameter with name `layer` will be used\n","            #     so we must initialize it using `layer_raw` before forward pass\n","\n","    def _setweights(self, x):\n","        \"\"\"\n","            Apply dropout to the raw weights.\n","        \"\"\"\n","        for layer in self.layer_names:\n","            # Get torch.nn.Parameter with weights\n","            raw_w = getattr(self, f'{layer}_raw')\n","\n","            # Generate mask (use function gen_dropout_mask)\n","            # YOUR CODE HERE\n","            ...\n","\n","            # Apply dropout mask\n","            # YOUR CODE HERE\n","            ...\n","\n","            # Set modified weights in its place\n","            setattr(self.module, layer, masked_raw_w)\n","\n","    def forward(self, x, h_c=None):\n","        \"\"\"\n","        :param x: tensor containing the features of the input sequence.\n","        :param Optional[Tuple[torch.Tensor, torch.Tensor]] h_c: initial hidden state and initial cell state\n","        \"\"\"\n","        with warnings.catch_warnings():\n","            # To avoid the warning that comes because the weights aren't flattened.\n","            warnings.simplefilter(\"ignore\")\n","\n","            # Set new weights of self.module and call its forward\n","            # Pass h_c with x if it is not None. Otherwise pass only x\n","            # YOUR CODE HERE\n","            ...\n","\n","    def reset(self):\n","        if hasattr(self.module, 'reset'):\n","            self.module.reset()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PrCLGdqkOBO0"},"outputs":[],"source":["layer = FastRNNLayer(32, 64, dropout=None)\n","dummy_input = torch.ones((10, 16, 32))\n","\n","out = layer(dummy_input)\n","\n","assert out[0].shape == (10, 16, 64)\n","assert out[1][0].shape == (1, 16, 64)\n","assert out[1][1].shape == (1, 16, 64)"]},{"cell_type":"markdown","metadata":{"id":"sZyS_kuFOBO0"},"source":["Протестируйте реализованную модель с выключенным дропаутом (слой `FastRNNLayer` надо передать в `RNNClassifier` в качестве `rec_layer`). Замерьте время обучения. Убедитесь, что модель выдаёт такое же качество, как и оригинальная реализация LSTM."]},{"cell_type":"markdown","metadata":{"id":"NPg3UddJOBO0"},"source":["**Сохраните все метрики и время работы модели. Это потребуется в конце первой части для построения графиков обучения и сравнения времени работы для всех моделей в этой секции**\n","\n","**Возможно стоит сохранить результаты в виде файлов и скачать их**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yf0nY0pWOBO0"},"outputs":[],"source":["set_global_seed(42)\n","\n","# YOUR CODE HERE\n","..."]},{"cell_type":"markdown","metadata":{"id":"-0tYHqdCOBO0"},"source":["Протестируйте полученный слой (вновь подставив его в `RNNClassifier` в качестве `rec_layer`) с `dropout=0.25`. Сравните время обучения с предыдущими моделями. Проследите, чтобы качество получилось такое же, как при первой реализации этого дропаута."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HxWcsFBYOBO0"},"outputs":[],"source":["set_global_seed(42)\n","\n","# YOUR CODE HERE\n","..."]},{"cell_type":"markdown","metadata":{"id":"24-C1okQOBO0"},"source":["</конец взлома pytorch>"]},{"cell_type":"markdown","metadata":{"id":"Sp-P9gf8OBO1"},"source":["## `Реализация дропаута по статье Семениуты и др. (1 балл)`"]},{"cell_type":"markdown","metadata":{"id":"0-sc4uwYOBO1"},"source":["Перейдем к реализации дропаута для LSTM по статье [Semeniuta et al](http://www.aclweb.org/anthology/C16-1165).\n","\n","Этот метод применения дропаута не менее популярен, чем предыдущий. Его особенность состоит в том, что он придуман специально для гейтовых архитектур. В контексте LSTM этот дропаут накладывается только на информационный поток ($m_h$ — маска дропаута):\n","$$\n","i = \\sigma(h_{t-1}W^i + x_t U^i+b_i) \\quad\n","o = \\sigma(h_{t-1}W^o + x_t U^o+b_o)\n","$$\n","$$\n","f = \\sigma(h_{t-1}W^f + x_t U^f+b_f) \\quad\n","g = tanh(h_{t-1} W^g + x_t U^g+b_g)\n","$$\n","$$\n","c_t = f \\odot c_{t-1} +  i \\odot g \\odot {\\bf m_h} \\quad\n","h_t =  o \\odot tanh(c_t)\n","$$\n","**На входы $x_t$ маска накладывается как в предыдущем дропауте.** Впрочем, на входы маску можно наложить вообще до вызова рекуррентного слоя.\n","\n","Согласно статье, маска дропаута может быть как одинаковая, так и разная для всех моментов времени. Мы сделаем одинаковую для всех моментов времени.\n","\n","Для реализации этого дропаута можно:\n","1. самостоятельно реализовать LSTM (интерфейса LSTMCell не хватит)\n","2. снова воспользоваться трюком с установкой весов (но тут мы опираемся на свойство $tanh(0)=0$, к тому же, трюк в данном случае выглядит менее тривиально, чем с дропаутом Гала).\n","\n","**Внимание:** Раньше мы реализовывали через LSTMCell и модель работала долго, теперь при рукописном варианте будет работать еще дольше!\n","\n","Предлагается реализовать дропаут по сценарию 1. Допишите класс:"]},{"cell_type":"markdown","metadata":{"id":"vyLTJkEWOBO1"},"source":["**Для каждого тензора в функции `forward` подпишите в комментарии его размеры**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0hvf4WmQOBO1"},"outputs":[],"source":["class HandmadeLSTM(torch.nn.Module):\n","    def __init__(self, input_size, hidden_size, dropout=0.0):\n","        super().__init__()\n","\n","        self.dropout = dropout\n","        self.input_size = input_size\n","        self.hidden_size = hidden_size\n","\n","        self.input_weights = torch.nn.Linear(input_size, 4 * hidden_size)\n","        self.hidden_weights = torch.nn.Linear(hidden_size, 4 * hidden_size)\n","\n","        self.reset_params()\n","\n","    def reset_params(self):\n","        \"\"\"\n","        Initialization as in Pytorch.\n","        Do not forget to call this method!\n","        https://pytorch.org/docs/stable/_modules/torch/nn/modules/rnn.html#LSTM\n","        \"\"\"\n","        stdv = 1.0 / np.sqrt(self.hidden_size)\n","        for weight in self.parameters():\n","            torch.nn.init.uniform_(weight, -stdv, stdv)\n","\n","    def forward(self, x):\n","        # Use functions init_h0_c0 and gen_dropout_masks defined above\n","        # YOUR CODE HERE\n","        ...\n","\n","        # Implement recurrent logic to mimic torch.nn.LSTM\n","        # Do not forget to apply dropout mask\n","        # YOUR CODE HERE\n","        ..."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CQ8Vvhq7OBO1"},"outputs":[],"source":["layer = HandmadeLSTM(32, 64, dropout=None)\n","dummy_input = torch.ones((10, 16, 32))\n","\n","out = layer(dummy_input)\n","\n","assert out[0].shape == (10, 16, 64)\n","assert out[1][0].shape == (16, 64)\n","assert out[1][1].shape == (16, 64)"]},{"cell_type":"markdown","metadata":{"id":"Zj3L7o2BOBO1"},"source":["Протестируйте вашу реализацию без дропаута (проконтролируйте качество и сравните время обучения с временем обучения `torch.nn.LSTM` и `RNNLayer`), а также с `dropout=0.25`. Сравните качество модели с таким дропаутом с качеством модели с дропаутом Гала и Гарамани."]},{"cell_type":"markdown","metadata":{"id":"iHX8nEpQOBO1"},"source":["**Сохраните все метрики и время работы модели. Это потребуется в конце первой части для построения графиков обучения и сравнения времени работы для всех моделей в этой секции**\n","\n","**Возможно стоит сохранить результаты в виде файлов и скачать их**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4gtYrA3JOBO1"},"outputs":[],"source":["set_global_seed(42)\n","\n","# YOUR CODE HERE\n","..."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LsETx-L5OBO1"},"outputs":[],"source":["set_global_seed(42)\n","\n","# YOUR CODE HERE\n","..."]},{"cell_type":"markdown","metadata":{"id":"vsoGzPlPOBO1"},"source":["## `Сравнение всех предложенных моделей (1 балл)`"]},{"cell_type":"markdown","metadata":{"id":"4RcL83soOBO2"},"source":["Используя замеры времени заполните табличку с временем работы четырёх реализованных моделей в следующей ячейке:"]},{"cell_type":"markdown","metadata":{"id":"pvgYyjqiOBO2"},"source":["| torch.nn.LSTM | RNNLayer | FastRNNLayer | HandmadeLSTM |\n","|---------------|----------|--------------|--------------|\n","| 2m 35s        | 14m 16s  | 2m 41s       | 31m 44s      |"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rctlqpL9OBO2"},"outputs":[],"source":["import matplotlib.pyplot as plt"]},{"cell_type":"markdown","metadata":{"id":"p_qB0VqsOBO2"},"source":["Крайне желательно рисовать графики в векторном формате.\n","\n","Если по каким-то причинам, отрисовка не будет работать, закомментируйте следующую ячейку."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sTqDDtFqOBO2"},"outputs":[],"source":["%matplotlib inline\n","\n","import matplotlib_inline\n","from IPython.display import set_matplotlib_formats\n","\n","matplotlib_inline.backend_inline.set_matplotlib_formats('pdf', 'svg')"]},{"cell_type":"markdown","metadata":{"id":"ii1psMVVOBO2"},"source":["Нарисуйте два графика — функция потерь и качество на обучающей и тестовой выборке для всех 7 моделей обученных выше."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OXy5LXaKOBO2"},"outputs":[],"source":["fig, axes = plt.subplots(2, 1, figsize=(10, 10))\n","colors = ['black', 'red', 'blue', 'green', 'orange', 'purple', 'cyan']\n","\n","# YOUR CODE HERE\n","...\n","\n","axes[0].legend()\n","axes[0].grid(True)\n","axes[0].set_xlabel('Epoch')\n","axes[0].set_title('CrossEntropy Loss')\n","\n","axes[1].legend()\n","axes[1].grid(True)\n","axes[1].set_xlabel('Epoch')\n","axes[1].set_title('Accuracy')\n","\n","fig.tight_layout()\n","plt.savefig(\"results.png\")\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"p3zrczHqOBO2"},"source":["Сделайте итоговые выводы о качестве работы моделей с разными реализациями DropOut:"]},{"cell_type":"markdown","metadata":{"id":"gcvMz1piOBO2"},"source":["**Ответ:**"]},{"cell_type":"markdown","metadata":{"collapsed":true,"id":"nvg13PGXOBO3"},"source":["## `Бонус. Zoneout (0.5 балла)`"]},{"cell_type":"markdown","metadata":{"collapsed":true,"id":"wOy4aJgiOBO3"},"source":["Это еще одна модификация идеи дропаута применительно к рекуррентным нейросетям. В Zoneout на каждом временном шаге с вероятностью $p$ компонента скрытого состояния обновляется, а с вероятностью $1-p$ берется с предыдущего шага.\n","В Виде формул ($m^t_h$ - бинарная маска):\n","\n","(сначала обычный рекуррентный переход, например LSTM)\n","$$\n","i = \\sigma(h_{t-1}W^i + x_t U^i+b_i) \\quad\n","o = \\sigma(h_{t-1}W^o + x_t U^o+b_o)\n","$$\n","$$\n","f = \\sigma(h_{t-1}W^f + x_t U^f+b_f) \\quad\n","g = tanh(h_{t-1} W^g + x_t U^g+b_g)\n","$$\n","$$\n","c_t = f \\odot c_{t-1} +  i \\odot  g \\quad\n","h_t =  o \\odot tanh(c_t)\n","$$\n","Затем Zoneout:\n","$$\n","h_t = h_t * m_h^t + h_{t-1}*(1-m_h^t)\n","$$\n","В этом методе маска уже должна быть разная во все моменты времени (иначе метод упрощается до дропаута Гала и Гарамани). На входы $x_t$ вновь можно накладывать маску до начала работы рекуррентного слоя.  \n","\n","Если у вас осталось время, вы можете реализовать этот метод. Выберите основу из трех рассмотренных случаев самостоятельно.\n","\n","**Полный балл ставится только при наличии качественного и количественного сравнения с предыдущими моделями.**"]},{"cell_type":"markdown","metadata":{"id":"81Nbw6rmOBO3"},"source":["# `Часть 2. Language Modeling с помощью LSTM (5 баллов)`"]},{"cell_type":"markdown","metadata":{"id":"vdTUkKmROBO3"},"source":["Во второй части мы попробуем обучить модель для генерации отзывов по их началу."]},{"cell_type":"markdown","metadata":{"id":"HHtdBcjjOBO3"},"source":["Концептуально модель будет выглядеть следующим образом:\n","    \n","![image info](https://www.researchgate.net/publication/350391597/figure/fig1/AS:1005416683167744@1616721425265/Structure-of-the-long-short-term-memory-language-model-LSTMLM.png)"]},{"cell_type":"markdown","metadata":{"id":"7Ed4LIk2OBO3"},"source":["В процессе обучения будем тренировать сеть предсказывать вероятность следующего символа при условии всех предыдущих. Эту вероятность можно моделировать с помощью скрытого состояния $h^{(t)}$ пропуская его через линейный слой с выходной размерностью равной размерности словаря:\n","$$\n","p(x^{t}|x^{t-1}, ..., x^{1}) = SoftMax(Linear(h^{(t)}))\n","$$"]},{"cell_type":"markdown","metadata":{"id":"TW_cgFacOBO3"},"source":["Обратите внимание, что для вычисления $p(x^{t}|x^{t-1}, ..., x^{1})$ для всех моментов времени достаточно сделать один проход по RNN, а затем применить линейное преобразование ко всем скрытым состояниям."]},{"cell_type":"markdown","metadata":{"id":"ZniSZRnKOBO3"},"source":["В качестве функции потерь необходимо использовать `CrossEntropy`."]},{"cell_type":"markdown","metadata":{"id":"OX2IPY8eOBO3"},"source":["Рассмотрим другой важный момент. Для того, чтобы решить данную задачу, модель должна уметь определять момент начала генерации предложения и оповещать о завершении генерации — конце предложения. Для этого добавим в словарь вспомогательные токены `<sos>`, `<eos>`. Добавив `<sos>` в начало каждого предложения и `<eos>` в конец.\n","\n","Модель сможет начинать генерацию как только ей будет передан токен `<sos>` и заканчивать генерацию, как только на очередном месте самым вероятным токеном оказывается `<eos>`."]},{"cell_type":"markdown","metadata":{"id":"G1bBIiCCOBO3"},"source":["Для решения этой задачи мы воспользуемся уже реализованной LSTM с дропаутом `FastRNNLayer` и классом `RNNClassifier`, то есть архитектура сети принципиально не поменяется."]},{"cell_type":"markdown","metadata":{"id":"XyZmbzYbOBO4"},"source":["## `Реализация модели и цикла обучения (2 балла)`"]},{"cell_type":"markdown","metadata":{"id":"ZeA1iaPKOBO4"},"source":["**Не используйте циклы в `RNNLM`, `LMCrossEntropyLoss`, `LMAccuracy`**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KlKEbUIDOBO4"},"outputs":[],"source":["class RNNLM(RNNClassifier):\n","    def __init__(\n","        self, embedding_dim, hidden_dim, tokenizer, dropout=0.5, layers_dropout=0.5, num_layers=1\n","    ):\n","        super().__init__(\n","            embedding_dim=embedding_dim, hidden_dim=hidden_dim,\n","            output_size=tokenizer.get_vocab_size(), tokenizer=tokenizer,\n","            rec_layer=FastRNNLayer, dropout=dropout, layers_dropout=layers_dropout, num_layers=num_layers\n","        )\n","\n","    def forward(self, tokens, tokens_lens):\n","        \"\"\"\n","        :param torch.Tensor(dtype=torch.long) tokens:\n","            Batch of texts represented with tokens. Shape: [T, B]\n","        :param torch.Tensor(dtype=torch.long) tokens_lens:\n","            Number of non-padding tokens for each object in batch. Shape: [B]\n","        :return torch.Tensor:\n","            Distribution of next token for each time step. Shape: [T, B, V], V — size of vocabulary\n","        \"\"\"\n","        # Make embeddings for all tokens\n","        # YOUR CODE HERE\n","        ...\n","\n","        # Forward pass embeddings through network\n","        # YOUR CODE HERE\n","        ...\n","\n","        # Take all hidden states from the last layer of LSTM for each step and perform linear transformation\n","        # YOUR CODE HERE\n","        ..."]},{"cell_type":"markdown","metadata":{"id":"KNITeST-OBO4"},"source":["Реализуем функцию потерь для данной задачи.\n","\n","Моменты на которые нужно обратить внимание:\n","1. Распределение вероятности следующего токена для последнего токена в последовательности не участвует в подсчёте функции потерь.\n","2. Необходимо учитывать, что в одном батче могут быть тексты разной длины."]},{"cell_type":"markdown","metadata":{"id":"lBC_VEyVOBO4"},"source":["Для решения второй проблемы можно воспользоваться функцией `torch.nn.utils.rnn.pack_padded_sequence`.\n","\n","Принимая на вход батч тензоров и длину каждого тензора без учёта паддинга эта функция позволяет получить все элементы в тензорах, которые не относятся к паддингу в виде плоского массива:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dsZ64DtQOBO4"},"outputs":[],"source":["padded_tensors = torch.tensor([\n","    [[1, 11, 111], [2, 22, 222], [3, 33, 333]],\n","    [[4, 44, 444], [5, 55, 555], [6, 66, 666]],\n","    [[7, 77, 777], [0, 0, 0], [8, 88, 888]],\n","    [[9, 99, 999], [0, 0, 0], [0, 0, 0]]\n","])\n","tensors_lens = torch.tensor([4, 2, 3])"]},{"cell_type":"markdown","metadata":{"id":"wVwL_3XvOBO4"},"source":["Обратите внимание, что `torch.nn.utils.rnn.pack_padded_sequence` автоматически переупорядочивает тензоры в батче по убыванию их длины."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fCzMqHqAOBO4"},"outputs":[],"source":["torch.nn.utils.rnn.pack_padded_sequence(padded_tensors, tensors_lens, batch_first=False, enforce_sorted=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xJttmqL2OBO5"},"outputs":[],"source":["class LMCrossEntropyLoss(torch.nn.CrossEntropyLoss):\n","    def __init__(self, *args, **kwargs):\n","        super().__init__(*args, **kwargs)\n","\n","    def forward(self, outputs, tokens, tokens_lens):\n","        \"\"\"\n","        :param torch.Tensor outputs: Output from RNNLM.forward. Shape: [T, B, V]\n","        :param torch.Tensor tokens: Batch of tokens. Shape: [T, B]\n","        :param torch.Tensor tokens_lens: Length of each sequence in batch\n","        :return torch.Tensor: CrossEntropyLoss between corresponding logits and tokens\n","        \"\"\"\n","        # Use torch.nn.utils.rnn.pack_padded_sequence().data to remove padding and flatten logits and tokens\n","        # Do not forget specify enforce_sorted=False and correct value of batch_first\n","        # YOUR CODE HERE\n","        packed_outputs = ...\n","        packed_tokens = ...\n","\n","        # Use super().forward(..., ...) to compute CrossEntropyLoss\n","        # YOUR CODE HERE\n","        ..."]},{"cell_type":"markdown","metadata":{"id":"8tkdDIjKOBO5"},"source":["Проверим как работает класс `LMCrossEntropyLoss`. Важно помнить, что при языковом моделировании мы предсказываем следующий токен, то есть `tokens` и `outputs` смещены друг относительно друга."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JOvbSEgnOBO5"},"outputs":[],"source":["loss = LMCrossEntropyLoss(reduction='none')\n","max_len_testing    = 3\n","batch_size_testing = 2\n","vocab_size_testing = 5\n","\n","logits = torch.zeros((max_len_testing, batch_size_testing, vocab_size_testing))\n","tokens = torch.zeros((max_len_testing, batch_size_testing)).long()\n","lens   = torch.tensor([2, 3])\n","\n","logits[:, 0, 0] = torch.tensor([1, -1, 0])\n","logits[:, 0, 1] = torch.tensor([2, 3,  0])\n","logits[:, 0, 2] = torch.tensor([3, 2,  0])\n","logits[:, 0, 3] = torch.tensor([4, 2,  0])\n","logits[:, 0, 4] = torch.tensor([5, 2,  0])\n","\n","\n","logits[:, 1, 0] = torch.tensor([-1, 10, 2])\n","logits[:, 1, 1] = torch.tensor([2, 30,  1])\n","logits[:, 1, 2] = torch.tensor([4, 20,  1])\n","logits[:, 1, 3] = torch.tensor([5, -10, 4])\n","logits[:, 1, 4] = torch.tensor([1, 7,  13])\n","\n","tokens[:, 0]    = torch.tensor([1, 4, 0])\n","tokens[:, 1]    = torch.tensor([3, 1, 4])\n","\n","\n","loss(outputs=logits, tokens=tokens, tokens_lens=lens)"]},{"cell_type":"markdown","metadata":{"id":"iSf_ABaROBO5"},"source":["Для оценки качества нам также необходимо вычислять долю правильно предсказанных токенов. Реализуйте класс для вычисления точности."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"091RbwH1OBO7"},"outputs":[],"source":["class LMAccuracy(torch.nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","\n","    def forward(self, outputs, tokens, tokens_lens):\n","        \"\"\"\n","        :param torch.Tensor outputs: Output from RNNLM.forward. Shape: [T, B, V]\n","        :param torch.Tensor tokens: Batch of tokens. Shape: [T, B]\n","        :param torch.Tensor tokens_lens: Length of each sequence in batch\n","        :return torch.Tensor: Accuracy for given logits and tokens\n","        \"\"\"\n","        # Use torch.nn.utils.rnn.pack_padded_sequence().data to remove padding and flatten logits and tokens\n","        # Do not forget specify enforce_sorted=False and correct value of batch_first\n","        # YOUR CODE HERE\n","        packed_outputs = ...\n","        packed_tokens = ...\n","\n","        ..."]},{"cell_type":"markdown","metadata":{"id":"Em4Cq1WcOBO7"},"source":["Проверим как работает класс `LMAccuracy`."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PWT3mQ0TOBO7"},"outputs":[],"source":["metric = LMAccuracy()\n","max_len_testing    = 3\n","batch_size_testing = 2\n","vocab_size_testing = 5\n","\n","logits = torch.zeros((max_len_testing, batch_size_testing, vocab_size_testing))\n","tokens = torch.zeros((max_len_testing, batch_size_testing)).long()\n","lens   = torch.tensor([2, 3])\n","\n","logits[:, 0, 0] = torch.tensor([1, -1, 0])\n","logits[:, 0, 1] = torch.tensor([2, 3,  0])\n","logits[:, 0, 2] = torch.tensor([3, 2,  0])\n","logits[:, 0, 3] = torch.tensor([4, 2,  0])\n","logits[:, 0, 4] = torch.tensor([5, 2,  0])\n","\n","\n","logits[:, 1, 0] = torch.tensor([-1, 10, 2])\n","logits[:, 1, 1] = torch.tensor([2, 30,  1])\n","logits[:, 1, 2] = torch.tensor([4, 20,  1])\n","logits[:, 1, 3] = torch.tensor([5, -10, 4])\n","logits[:, 1, 4] = torch.tensor([1, 7,  13])\n","\n","tokens[:, 0]    = torch.tensor([1, 4, 0])\n","tokens[:, 1]    = torch.tensor([3, 1, 4])\n","\n","\n","metric(outputs=logits, tokens=tokens, tokens_lens=lens)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"E_d5BWXiOBO8"},"outputs":[],"source":["metric = LMAccuracy()\n","max_len_testing    = 10\n","batch_size_testing = 3\n","vocab_size_testing = 200\n","\n","set_global_seed(42)\n","logits = torch.randn((max_len_testing, batch_size_testing, vocab_size_testing))\n","logits[:, :, 1] = 1000\n","\n","tokens = torch.randint(low=0, high=vocab_size_testing, size=(max_len_testing, batch_size_testing))\n","tokens[:5, :] = 1\n","lens   = torch.tensor([10, 4, 9])\n","\n","assert metric(outputs=logits, tokens=tokens, tokens_lens=lens) == (4 + 3 + 4) / (lens - 1).sum()"]},{"cell_type":"markdown","metadata":{"id":"nrsijUUOOBO8"},"source":["Модифицируйте функции `train_epoch`, `evaluate`, `train` для обучения LM.\n","\n","**При вычислении точности, обратите внимание на то, что мы не предсказываем первый токен в каждой последовательности и токены, относящиеся к паддингу.**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gZC7JymHOBO8"},"outputs":[],"source":["def train_epoch_lm(dataloader, model, loss_fn, optimizer, device):\n","    model.train()\n","    for idx, data in enumerate(dataloader):\n","        # 1. Take data from batch\n","        # 2. Perform forward pass\n","        # 3. Evaluate loss\n","        # 4. Make optimizer step\n","        # YOUR CODE HERE\n","        ...\n","\n","def evaluate_lm(dataloader, model, loss_fn, device):\n","    model.eval()\n","\n","    total_tokens = 0\n","    total_loss = 0.0\n","    total_accuracy = 0.0\n","\n","    accuracy_fn = LMAccuracy()\n","    with torch.no_grad():\n","        for idx, data in enumerate(dataloader):\n","            # 1. Take data from batch\n","            # 2. Perform forward pass\n","            # 3. Evaluate loss\n","            # 4. Evaluate accuracy\n","            # YOUR CODE HERE\n","            ...\n","\n","    return total_loss / total_tokens, total_accuracy / total_tokens\n","\n","def train_lm(\n","    train_loader, test_loader, model, loss_fn, optimizer, device, num_epochs\n","):\n","    test_losses = []\n","    train_losses = []\n","    test_accuracies = []\n","    train_accuracies = []\n","    for epoch in range(num_epochs):\n","        train_epoch_lm(train_loader, model, loss_fn, optimizer, device)\n","\n","        train_loss, train_acc = evaluate_lm(train_loader, model, loss_fn, device)\n","        train_accuracies.append(train_acc)\n","        train_losses.append(train_loss)\n","\n","        test_loss, test_acc = evaluate_lm(test_loader, model, loss_fn, device)\n","        test_accuracies.append(test_acc)\n","        test_losses.append(test_loss)\n","\n","        print(\n","            'Epoch: {0:d}/{1:d}. Loss (Train/Test): {2:.3f}/{3:.3f}. Accuracy (Train/Test): {4:.3f}/{5:.3f}'.format(\n","                epoch + 1, num_epochs, train_losses[-1], test_losses[-1], train_accuracies[-1], test_accuracies[-1]\n","            )\n","        )\n","    return train_losses, train_accuracies, test_losses, test_accuracies"]},{"cell_type":"markdown","metadata":{"id":"01IG55lCOBO8"},"source":["Теперь у нас всё готово для обучения модели."]},{"cell_type":"markdown","metadata":{"id":"cCgia2fwOBO8"},"source":["Создадим токенизатор с `<sos>`, `<eos>` токенами.\n","\n","Обратите внимание, что в отличие от классификации текстов нам необходимо значительно увеличить размер словаря, чтобы доля `<unk>` токенов была не велика.\n","\n","Так же, так как задача генерации значительно сложнее задачи классификации текстов будем обучать модель только на префиксах рецензий длины $20$. Это позволяет значительно ускорить обучение."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"brflTMOmOBO8"},"outputs":[],"source":["# min_freq=8 is approximately equivalent to max_size=30000.\n","#   You can lower min_freq in order to make model vocabulary more diverse\n","trainer = trainers.WordLevelTrainer(\n","    min_frequency  = 8,\n","    special_tokens = ['<pad>', '<unk>', '<sos>', '<eos>'],\n",")\n","\n","tokenizer = tokenizers.Tokenizer(\n","    model = tokenizers.models.WordLevel(unk_token=\"<unk>\")\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"S_KbOKutOBO8"},"outputs":[],"source":["tokenizer.train_from_iterator(tqdm(get_data_iterator(), total=50_000), trainer=trainer)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"U0piAfIqOBO8"},"outputs":[],"source":["assert tokenizer.get_vocab_size() == 30000\n","\n","for i in range(10):\n","    token = tokenizer.id_to_token(i)\n","    print(f\"ID = {i}, token = {token}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2shnBqU2OBO8"},"outputs":[],"source":["lm_test_dataset = LargeMovieReviewDataset(test_data_path, tokenizer, max_len=20, pad_sos=True, pad_eos=True)\n","lm_train_dataset = LargeMovieReviewDataset(train_data_path, tokenizer, max_len=20, pad_sos=True, pad_eos=True)"]},{"cell_type":"markdown","metadata":{"id":"DT7EySpLOBO9"},"source":["Создадим даталоадеры для тестовой и обучающей выборок:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aQBaMcCNOBO9"},"outputs":[],"source":["lm_test_dataloader = DataLoader(\n","    lm_test_dataset, batch_size=196, shuffle=False, num_workers=4,\n","    collate_fn=partial(collate_fn, padding_value=tokenizer.token_to_id('<pad>'))\n",")\n","lm_train_dataloader = DataLoader(\n","    lm_train_dataset, batch_size=196, shuffle=True, num_workers=4,\n","    collate_fn=partial(collate_fn, padding_value=tokenizer.token_to_id('<pad>'))\n",")"]},{"cell_type":"markdown","metadata":{"id":"sTQ7PLKNOBO9"},"source":["Убедитесь, что все предложения имеют в начале `<sos>` токен, а в конце — `<eos>` токен."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fqxq4EUCOBO9"},"outputs":[],"source":["batch = next(iter(lm_train_dataloader))\n","batch['tokens'], batch['tokens_lens']"]},{"cell_type":"markdown","metadata":{"id":"bs9XRcNEOBO9"},"source":["Создадим модель, функцию потерь и оптимизатор:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DgSzP6kGOBO9"},"outputs":[],"source":["lm_model = RNNLM(\n","    embedding_dim=512, hidden_dim=512, tokenizer=tokenizer, dropout=0.6, layers_dropout=0.6, num_layers=2\n",").to(device=device)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9DP25Q0jOBO9"},"outputs":[],"source":["lm_loss_fn = LMCrossEntropyLoss(reduction='mean')\n","lm_optimizer = torch.optim.Adam(lm_model.parameters(), lr=0.005, weight_decay=1.2e-6)"]},{"cell_type":"markdown","metadata":{"id":"VtO2YiONOBO-"},"source":["Обучим модель:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KZfwIHxwOBO-"},"outputs":[],"source":["%%time\n","lm_model = torch.compile(lm_model)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NDKPDRhOOBO-"},"outputs":[],"source":["lm_train_losses, lm_train_accuracies, lm_test_losses, lm_test_accuracies = train_lm(\n","    lm_train_dataloader, lm_test_dataloader, lm_model, lm_loss_fn, lm_optimizer, device, 10\n",")"]},{"cell_type":"markdown","metadata":{"id":"ooU0jTTjOBO-"},"source":["## `Реализация декодера (1 балл)`"]},{"cell_type":"markdown","metadata":{"id":"P1oA-gqmOBO-"},"source":["Теперь, реализуем последнюю деталь — декодирование с использованием обученной модели.\n","Есть несколько вариантов. Рассмотрим два самых простых:\n","1. **Жадное декодирование.** На каждом шаге мы выбираем токен с максимальной вероятностью и используем его для обновления скрытого состояния RNN.\n","2. **Top-k sampling.** На очередном шаге рассматриваются $k$ токенов с самыми большими вероятностями. Остальные токены игнорируются. Из выбранных токенов семплируется следующий токен пропорционально их вероятностям.\n","\n","Прочитать подробнее про разные варианты декодирования можно по ссылкам:\n","1. [От huggingface](https://huggingface.co/blog/how-to-generate)\n","2. [На towardsdatascience](https://towardsdatascience.com/decoding-strategies-that-you-need-to-know-for-response-generation-ba95ee0faadc)"]},{"cell_type":"markdown","metadata":{"id":"d8D9-M6POBO-"},"source":["Существенным в процессе декодирования является критерий останова. Как только очередной самый вероятный символ оказался `<eos>`, то данная последовательность считается сгенерированной. Однако, может так оказаться, что `<eos>` никогда не будет выбран, тогда необходимо прекратить генерацию, как только длина последовательности перейдёт порог `max_generated_len`."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"I56d2POEOBO-"},"outputs":[],"source":["@torch.no_grad()\n","def decode(\n","    model, start_tokens, start_tokens_lens,\n","    max_generated_len=20, top_k=None, eos_idx=tokenizer.token_to_id('<eos>')\n","):\n","    \"\"\"\n","    :param RNNLM model: Model\n","    :param torch.Tensor start_tokens: Batch of seed tokens. Shape: [T, B]\n","    :param torch.Tensor start_tokens_lens: Length of each sequence in batch. Shape: [B]\n","    :param int max_generated_len: Maximum lenght of generated samples\n","    :param Optional[int] top_k: Number of tokens with the largest probability to sample from\n","    :return Tuple[torch.Tensor, torch.Tensor].\n","        Newly predicted tokens and length of generated part. Shape [T*, B], [B]\n","    \"\"\"\n","    # Get embedding for start_tokens\n","    # YOUR CODE HERE\n","    embedding = ...\n","    # Pass embedding through rnn and collect hidden states and cell states for each time moment\n","    all_h, all_c = [], []\n","    h = embedding.new_zeros([model.rnn.num_layers, start_tokens.shape[1], model.hidden_dim])\n","    c = embedding.new_zeros([model.rnn.num_layers, start_tokens.shape[1], model.hidden_dim])\n","    for time_step in range(start_tokens.shape[0]):\n","        # YOUR CODE HERE\n","        ...\n","\n","    all_h = torch.stack(all_h, dim=1)\n","    all_c = torch.stack(all_c, dim=1)\n","    # Take final hidden state and cell state for each start sequence in batch\n","    # We will use them as h_0, c_0 for generation new tokens\n","    h = all_h[:, start_tokens_lens - 1, torch.arange(start_tokens_lens.shape[0])]\n","    c = all_c[:, start_tokens_lens - 1, torch.arange(start_tokens_lens.shape[0])]\n","\n","    # List of predicted tokens for each time step\n","    predicted_tokens = []\n","    # Length of generated part for each object in the batch\n","    decoded_lens = torch.zeros_like(start_tokens_lens, dtype=torch.long)\n","    # Boolean mask where we store if the sequence has already generated\n","    # i.e. `<eos>` was selected on any step\n","    is_finished_decoding = torch.zeros_like(start_tokens_lens, dtype=torch.bool)\n","\n","    # Stop when all sequences in the batch are finished\n","    while not torch.all(is_finished_decoding) and torch.max(decoded_lens) < max_generated_len:\n","        # Evaluate next token distribution using hidden state h.\n","        # Note. Over first dimension h has hidden states for each layer of LSTM.\n","        #     We must use hidden state from the last layer\n","        # YOUR CODE HERE\n","        logits = ...\n","        if top_k is not None:\n","            # Top-k sampling. Use only top-k most probable logits to sample next token\n","            indices_to_remove = logits < torch.topk(logits, top_k)[0][..., -1, None]\n","            # Mask non top-k logits\n","            logits[indices_to_remove] = -1e10\n","            # Sample next_token.\n","            # YOUR CODE HERE\n","            next_token = ...\n","        else:\n","            # Select most probable token\n","            # YOUR CODE HERE\n","            next_token = ...\n","        predicted_tokens.append(next_token)\n","\n","        decoded_lens += (~is_finished_decoding)\n","        is_finished_decoding |= (next_token == torch.tensor(eos_idx))\n","\n","        # Compute embedding for next token\n","        # YOUR CODE HERE\n","        embedding = ...\n","\n","        # Update hidden and cell states\n","        # YOUR CODE HERE\n","        _, (h, c) = ...\n","\n","    return torch.stack(predicted_tokens), decoded_lens"]},{"cell_type":"markdown","metadata":{"id":"jNQcbQJkOBO-"},"source":["Для тестирования создадим удобный класс `FakeLM`, который будет реализовывать весь необходимый функционал, а именно:\n","\n","- `word_embeddings` - по токенам возвращает их эмбеддинги;\n","\n","- `output` - по вектору контекста (h) возвращает вероятности следующих токенов;\n","\n","- `rnn` - обновляет контекст. Будем использовать класс `FakeRNN`.\n","\n","Для простоты будем считать, что эмбеддинг токена и есть сам токен, а процесс генерации является марковским, то есть все переходы можно описать матрицей.\n","\n","Такая постановка поможет нам удобно задать все переходы и нарисовать их на бумаге (если возникнет необходимость в отладке). Кроме того, мы можем не думать об обновлении контекста, так как контекст и есть текущее слово (его эмбеддинг)."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"E3gjheGpOBO_"},"outputs":[],"source":["class FakeRNN:\n","\n","    def __init__(self):\n","\n","        self.num_layers = 1\n","\n","    def __call__(self, embedding, h_c):\n","        \"\"\"\n","        :param torch.Tensor embedding: Batch of embedding. Shape: [T, B, E]\n","        :param Optional[Tuple[torch.Tensor, torch.Tensor]] h_c: initial hidden state and initial cell state\n","        \"\"\"\n","\n","        return None, (embedding, torch.zeros_like(embedding))\n","\n","\n","class FakeLM:\n","\n","    def __init__(self, rnn, transition_matrix):\n","        self.rnn = rnn\n","        self.transition_matrix = transition_matrix\n","        self.hidden_dim = 1\n","\n","    def word_embeddings(self, tokens):\n","        \"\"\"\n","        :param torch.Tensor tokens: Batch of seed tokens. Shape: [T, B] or [B]\n","        :return torch.Tensor\n","            Batch of tokens embeddings. Shape: [T, BS, E] or [B, E]\n","        \"\"\"\n","\n","        return tokens[..., None].float()\n","\n","    def output(self, h):\n","        \"\"\"\n","        :param torch.Tensor h: Batch of seed tokens. Shape: [B, E]\n","        :return torch.Tensor.\n","            Batch of new_tokens logits. Shape: [B, V]\n","        \"\"\"\n","\n","        idx  = h.long().ravel().cpu().numpy()\n","        logits = list(self.transition_matrix[i] for i in idx)\n","        logits = torch.stack(logits, dim=0).float()\n","        return logits\n","\n"]},{"cell_type":"markdown","metadata":{"id":"1c6jCCcyOBO_"},"source":["#### `Тест 1`\n","\n","Зададим переходную матрицу `transitions` так, чтобы после токена $i$ вероятней всего следовал токен $i + 1$ mod $V$, где $V$ размер словаря. Тогда мы ожидаем получить циклические последовательности."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bvJivY2NOBO_"},"outputs":[],"source":["transitions = {\n","    0: torch.tensor([4, 5, 0, 0, 0]),\n","    1: torch.tensor([0, 4, 5, 0, 0]),\n","    2: torch.tensor([0, 0, 4, 5, 0]),\n","    3: torch.tensor([0, 0, 0, 4, 5]),\n","    4: torch.tensor([5, 0, 0, 0, 4]),\n","}\n","\n","fake_lm = FakeLM(FakeRNN(), transitions)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mnYjg5U3OBO_"},"outputs":[],"source":["decoded_tokens, decoded_lens = decode(\n","    model             = fake_lm,\n","    start_tokens      = torch.zeros((4, 3)),\n","    start_tokens_lens = torch.tensor([1, 2, 3]),\n","    eos_idx           = 10,\n","    max_generated_len = 8\n",")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0JLuzSkfOBO_"},"outputs":[],"source":["assert decoded_tokens.shape == (8, 3), f\"Shape = {decoded_tokens.shape}\"\n","assert (decoded_tokens[:, 0] == torch.tensor([1, 2, 3, 4, 0, 1, 2, 3])).all()\n","assert (decoded_tokens[:, 1] == torch.tensor([1, 2, 3, 4, 0, 1, 2, 3])).all()\n","assert (decoded_tokens[:, 2] == torch.tensor([1, 2, 3, 4, 0, 1, 2, 3])).all()"]},{"cell_type":"markdown","metadata":{"id":"Pf5bMQBVOBO_"},"source":["#### `Тест 2`\n","\n","Усложним и зададим разные начальные токены."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8VwhkC_tOBO_"},"outputs":[],"source":["start_tokens = torch.tensor(\n","    [\n","        [0, 0, 0],\n","        [0, 1, 1],\n","        [0, 0, 2],\n","        [0, 0, 0]\n","    ]\n",")\n","\n","decoded_tokens, decoded_lens = decode(\n","    model             = fake_lm,\n","    start_tokens      = start_tokens,\n","    start_tokens_lens = torch.tensor([1, 2, 3]),\n","    eos_idx           = 10,\n","    max_generated_len = 8\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KWW_YqcZOBO_"},"outputs":[],"source":["assert decoded_tokens.shape == (8, 3), f\"Shape = {decoded_tokens.shape}\"\n","assert (decoded_tokens[:, 0] == torch.tensor([1, 2, 3, 4, 0, 1, 2, 3])).all()\n","assert (decoded_tokens[:, 1] == torch.tensor([2, 3, 4, 0, 1, 2, 3, 4])).all()\n","assert (decoded_tokens[:, 2] == torch.tensor([3, 4, 0, 1, 2, 3, 4, 0])).all()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kH2TNzKXOBO_"},"outputs":[],"source":["decoded_tokens, decoded_lens = decode(\n","    model             = fake_lm,\n","    start_tokens      = start_tokens,\n","    start_tokens_lens = torch.tensor([1, 2, 3]),\n","    eos_idx           = 4,\n","    max_generated_len = 8\n",")\n","assert (decoded_lens == torch.tensor([4, 3, 2])).all()\n","\n","assert (decoded_tokens[:, 0] == torch.tensor([1, 2, 3, 4])).all()\n","assert (decoded_tokens[:, 1] == torch.tensor([2, 3, 4, 0])).all()\n","assert (decoded_tokens[:, 2] == torch.tensor([3, 4, 0, 1])).all()"]},{"cell_type":"markdown","metadata":{"id":"HpjgBiEXOBO_"},"source":["#### `Тест 3`\n","\n","Перейдем к тестированию `top_k`. Благодаря этому параметру мы можем увеличить разнообразие текстов. Поскольку проверять недетерминированную генерацию достаточно трудно, мы проверим, что в среднем генерируются адекватные последовательности.\n","\n","При заданной нами переходной матрице мы ожидаем:\n","\n","- При `top_k = 1` получим детерминированную генерацию;\n","\n","- При `top_k = 2` получим последовательности, где в почти в половине случаев будем стоять на месте;\n","\n","- При `top_k > 2` получим похожее на `top_k = 2`."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GK8UsbSvOBPA"},"outputs":[],"source":["set_global_seed(42)\n","\n","decoded_tokens, decoded_lens = decode(\n","    model             = fake_lm,\n","    start_tokens      = torch.zeros((4, 3)),\n","    start_tokens_lens = torch.tensor([1, 2, 3]),\n","    eos_idx           = 10,\n","    max_generated_len = 8,\n","    top_k             = 1\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cr_KEdgvOBPA"},"outputs":[],"source":["assert decoded_tokens.shape == (8, 3), f\"Shape = {decoded_tokens.shape}\"\n","assert (decoded_tokens[:, 0] == torch.tensor([1, 2, 3, 4, 0, 1, 2, 3])).all()\n","assert (decoded_tokens[:, 1] == torch.tensor([1, 2, 3, 4, 0, 1, 2, 3])).all()\n","assert (decoded_tokens[:, 2] == torch.tensor([1, 2, 3, 4, 0, 1, 2, 3])).all()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4AEFflOxOBPA"},"outputs":[],"source":["set_global_seed(42)\n","\n","decoded_tokens_k2, decoded_lens = decode(\n","    model             = fake_lm,\n","    start_tokens      = torch.zeros((4, 3)),\n","    start_tokens_lens = torch.tensor([1, 2, 3]),\n","    eos_idx           = 10,\n","    max_generated_len = 8,\n","    top_k             = 2\n",")\n","\n","decoded_tokens_k2"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0KL_r4L3OBPA"},"outputs":[],"source":["set_global_seed(42)\n","\n","decoded_tokens_k3, decoded_lens = decode(\n","    model             = fake_lm,\n","    start_tokens      = torch.zeros((4, 3)),\n","    start_tokens_lens = torch.tensor([1, 2, 3]),\n","    eos_idx           = 10,\n","    max_generated_len = 8,\n","    top_k             = 3\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JCfB4yYHOBPA"},"outputs":[],"source":["assert (decoded_tokens_k3 == decoded_tokens_k2).all()"]},{"cell_type":"markdown","metadata":{"id":"FwIJVDvAOBPA"},"source":["Попробуем сгенерировать продолжения для нескольких префиксов:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"V6u241iCOBPA"},"outputs":[],"source":["start_tokens = torch.tensor([\n","    lm_model.tokenizer.encode(['<sos>', '<pad>', '<pad>', '<pad>'], is_pretokenized=True).ids,\n","    lm_model.tokenizer.encode(['<sos>', 'my', 'favorite', 'movie'], is_pretokenized=True).ids,\n","    lm_model.tokenizer.encode(['<sos>', 'the', 'best', 'movie'],    is_pretokenized=True).ids,\n","    lm_model.tokenizer.encode(['<sos>', 'the', 'worst', 'movie'],   is_pretokenized=True).ids,\n","]).T\n","\n","start_tokens_lens = torch.tensor([1, 4, 4, 4])\n","start_tokens"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VyXT9q90OBPA"},"outputs":[],"source":["set_global_seed(42)\n","\n","lm_model = lm_model.cpu()\n","lm_model.eval()\n","decoded_tokens, decoded_lens = decode(lm_model, start_tokens, start_tokens_lens, max_generated_len=10, top_k=5)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MmywjAVKOBPB"},"outputs":[],"source":["for text_idx in range(start_tokens.shape[1]):\n","    decoded_text_tokens = decoded_tokens[:decoded_lens[text_idx], text_idx]\n","    tokens = start_tokens[:start_tokens_lens[text_idx], text_idx].tolist() + decoded_text_tokens.tolist()\n","    words = lm_model.tokenizer.decode(tokens, skip_special_tokens=False).split(' ')\n","\n","    text = ' '.join(words).replace('<', '&lt;').replace('>', '&gt;')\n","    display(Markdown(f'<div class=\"alert alert-block alert-info\"> <b>{text}</b></div>'))"]},{"cell_type":"markdown","metadata":{"id":"fkT3ecjdOBPB"},"source":["Попробуйте выполнить семплирование для разных $k$. Сравните результаты top-k семплирования с жадным декодированием. Опишите ваши наблюдения."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LpZ70IoXOBPB"},"outputs":[],"source":["# YOUR CODE HERE"]},{"cell_type":"markdown","metadata":{"id":"Z9DcGWybOBPB"},"source":["**Ответ:**"]},{"cell_type":"markdown","metadata":{"id":"iTgOs7VMOBPB"},"source":["## `Beam Search (2 балла)`"]},{"cell_type":"markdown","metadata":{"id":"hvzn2-LMOBPB"},"source":["Рассмотрим более продвинутый алгоритм для декодирования. Реализуйте алгоритм Beam Search.\n","\n","Прочитать подробнее про Beam Search можно по ссылкам:\n","1. [От huggingface](https://huggingface.co/blog/how-to-generate#beam-search)\n","2. [На wiki](https://en.wikipedia.org/w/index.php?title=Beam_search&oldid=1248868876)"]},{"cell_type":"markdown","metadata":{"id":"PG0JZTxUOBPB"},"source":["Несколько замечаний по имплементации:\n","\n","1. При больших размерах `beam_size` число гипотез ($B \\times \\text{beam\\_size}$) на очередном шаге может быть слишком большим. Поэтому может потребоваться разбить все гипотезы на отдельные батчи и делать forward-pass в несколько итераций. Используйте [`torch.split`](https://pytorch.org/docs/stable/generated/torch.split.html)\n","2. Для выбора лучших гипотез используйте [`torch.topk`](https://pytorch.org/docs/stable/generated/torch.topk.html). Обратите внимание на индексы, которые возвращает эта функция (может пригодиться метод [`torch.remainder`](https://pytorch.org/docs/stable/generated/torch.remainder.html))\n","3. Можно отслеживать, какие элементы в батче (или какие гипотезы) закончили генерацию. Делая forward-pass только для незавершённых гипотез, можно ускорить декодинг, однако, это усложнит реализацию"]},{"cell_type":"markdown","metadata":{"id":"Ew72FFqEOBPC"},"source":["Будем реализовывать в 2 части:\n","\n","- Получение всей необходимой информации из `start_tokens` в функции `beam_search_encode_start`.\n","\n","- Генерация и декодирования в функции `decode_beam_search`."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"64YiSTxhOBPC"},"outputs":[],"source":["@torch.no_grad()\n","def beam_search_encode_start(model, start_tokens, start_tokens_lens, beam_size):\n","    \"\"\"\n","    :param RNNLM model: Model\n","    :param torch.Tensor start_tokens: Batch of seed tokens. Shape: [T, B]\n","    :param torch.Tensor start_tokens_lens: Length of each sequence in batch. Shape: [B]\n","    :param int beam_size: Size of beam\n","    :return Tuple[torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor].\n","        Initialization h and c for each hypotheses, New tokens,\n","        Initialize log probabilities, Initialize hypothesis\n","        Shape [L, B * BS, H], [L, B * BS, H], [B * BS], [B * BS], [1, B * BS]\n","    \"\"\"\n","    # L — number of RNN layers in the model, H — hidden size, BS — beam size\n","    #\n","    # 1. Make forward pass of start_tokens through the model.\n","    #      Obtain the last cell and hidden state for each element in the batch\n","    #          (i.e. tensors of shape [L, B, H])\n","    #      Use those states as the initialization for each hypotheses in the beam\n","    #          (i.e. tensors of shape [L, B * BS, H])\n","    #      Initialize probabilities for each hypotheses in the beam with 1.0\n","    #          (i.e. tensor of shape [B * BS])\n","\n","    # Get embeddings for the start tokens\n","    # YOUR CODE HERE\n","    ...\n","\n","    # Make forward pass through the RNN and\n","    #   obtain the last cell and hidden state for each element in the batch\n","    # YOUR CODE HERE\n","    start_h = ... # [L, B, H]\n","    start_c = ... # [L, B, H]\n","\n","\n","    # Use those states as the initialization for each hypotheses in the beam\n","    # YOUR CODE HERE\n","    h = ... # [L, B * BS, H]\n","    c = ... # [L, B * BS, H]\n","\n","    # Select initial tokens for each hypotheses in the beam\n","    #   Compute log probabilities and select top-beam_size tokens for each element\n","    #   Use them to initialize beam search state\n","    # YOUR CODE HERE\n","    ...\n","\n","    new_tokens = ... # [B * BS]\n","    log_probas = ... # [B * BS]\n","    hypothesis = ... # [1, B * BS]\n","\n","    return h, c, new_tokens, log_probas, hypothesis"]},{"cell_type":"markdown","metadata":{"id":"TGxrnGWoOBPC"},"source":["Проверим функцию `beam_search_encode_start`. Ниже опишем матрицу перехода, в которой содержатся логиты вероятности перехода. `Beam size` отвечает за число гипотез, то есть сколько потенциально лучших токенов мы можем взять. Например, при `beam size = 4` и начальном токене $0$, мы будем рассматривать (создадим гипотезы) токены $[1, 0, 4, 3]$ (отсортированы в порядке убывания вероятности)."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xTAXox9mOBPC"},"outputs":[],"source":["transitions = {\n","    0: torch.tensor([4, 5, 1, 2, 3]),\n","    1: torch.tensor([3, 4, 5, 1, 2]),\n","    2: torch.tensor([2, 3, 4, 5, 1]),\n","    3: torch.tensor([1, 2, 3, 4, 5]),\n","    4: torch.tensor([5, 1, 2, 3, 4]),\n","}\n","\n","fake_lm = FakeLM(FakeRNN(), transitions)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Khjc8W8NOBPC"},"outputs":[],"source":["start_tokens = torch.tensor(\n","    [\n","        [0, 0, 0],\n","        [0, 1, 1],\n","        [0, 0, 2],\n","        [0, 0, 0]\n","    ]\n",")\n","\n","beam_size = 4\n","h, c, new_tokens, log_probas, hypothesis = beam_search_encode_start(\n","    model             = fake_lm,\n","    start_tokens      = start_tokens,\n","    start_tokens_lens = torch.tensor([1, 2, 3]),\n","    beam_size         = beam_size\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gek35czROBPC"},"outputs":[],"source":["assert h.shape == (1, 3 * beam_size, 1)\n","assert c.shape == (1, 3 * beam_size, 1)\n","assert new_tokens.shape[0] == (3 * beam_size)\n","assert log_probas.shape[0] == (3 * beam_size)\n","assert hypothesis.shape     == (1, 3 * beam_size)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xxtks41DOBPC"},"outputs":[],"source":["assert (h[0, :, 0] == torch.tensor([0] * beam_size + [1] * beam_size + [2] * beam_size)).all()\n","assert (new_tokens == torch.tensor([1, 0, 4, 3, 2, 1, 0, 4, 3, 2, 1, 0])).all()\n","assert torch.isclose(log_probas[:beam_size], torch.tensor([5, 4, 3, 2, 1]).float().log_softmax(0)[:-1]).all()\n","assert (hypothesis[0] == new_tokens).all()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cah3W9K2OBPC"},"outputs":[],"source":["@torch.no_grad()\n","def decode_beam_search(\n","    model, start_tokens, start_tokens_lens,\n","    max_generated_len=20, beam_size=5, eos_idx=tokenizer.token_to_id('<eos>')\n","):\n","    \"\"\"\n","    :param RNNLM model: Model\n","    :param torch.Tensor start_tokens: Batch of seed tokens. Shape: [T, B]\n","    :param torch.Tensor start_tokens_lens: Length of each sequence in batch. Shape: [B]\n","    :param int max_generated_len: Maximum length of generated samples\n","    :param int beam_size: Size of beam\n","    :return Tuple[torch.Tensor, torch.Tensor, torch.Tensor].\n","        Newly predicted tokens, lengths of generated parts and log probabilities for each hypotheses\n","        Shape [T*, B, beam_size], [T*, beam_size], [T*, beam_size]\n","    \"\"\"\n","\n","    # L — number of RNN layers in the model, H — hidden size, BS — beam size\n","    #\n","    # 1. Make forward pass of start_tokens through the model.\n","    #      Initialize vector that show whether hypothesis is finished\n","    #          (i.e. tensor of shape [B * BS])\n","    # 2. While all sequences do not end with <eos> and their length less than max_generated_len\n","    #      1. Get probabilities for the next token for each hypothesis\n","    #          (i.e. tensor of shape [B * BS, V])\n","    #      2. Use those probabilities to compute probability for each extension of each hypothesis\n","    #          (i.e. tensor of shape [B * BS, V])\n","    #      3. For each element in the batch select new BS best hypotheses\n","    #          Note, that some of the hypotheses on the previous step have been finished\n","    #            so their probability should not change. So you have to select BS best hypotheses\n","    #            among all extension of unfinished hypotheses and finished hypotheses\n","    #          As a result you will have a new token for best extensions of unfinished hypotheses\n","    #          For simplisity you can use <EOS> token if you select finished hypothesis in the beam\n","    #            i.e. tensor of shape [B * BS] of indices for selected hypotheses and\n","    #                 tensor of shape [B * BS] of extension tokens for each hypothesis\n","    #      4. Update probabilities for each hypotheses and is_finished state for each hypothesis\n","    #          Concat new tokens to the existing prefixes\n","    #      5. Update hidden and cell state to correspond to the selected hypothesis\n","\n","    #  Make forward pass of start_tokens through the model.\n","    h, c, new_tokens, log_probas, hypothesis = beam_search_encode_start(\n","        model             = model,\n","        start_tokens      = start_tokens,\n","        start_tokens_lens = start_tokens_lens,\n","        beam_size         = beam_size\n","    )\n","\n","    # Initialize vector that show whether hypothesis is finished\n","    is_finished = new_tokens == eos_idx # [B * BS]\n","    decoded_lens = torch.ones_like(is_finished, dtype=torch.long) # [B * BS]\n","\n","    while not torch.all(is_finished) and hypothesis.shape[0] < max_generated_len:\n","        # Get probabilities for the next token for each hypothesis\n","        # YOUR CODE HERE\n","        ...\n","\n","        next_token_log_probas = ... # [B * BS, V]\n","        # Use those probabilities to compute probability for each extension of each hypothesis\n","        # YOUR CODE HERE\n","        ...\n","        extension_log_probas = ... # [B * BS, V]\n","\n","        # For each element in the batch select new BS best hypotheses\n","        #   You can use loop over different beams\n","        # YOUR CODE HERE\n","        ...\n","\n","        # Update probabilities for each hypotheses and is_finished state and decoded_lens for each hypothesis\n","        # YOUR CODE HERE\n","        ...\n","\n","        # Concat new tokens to the existing prefixes\n","        # YOUR CODE HERE\n","        ...\n","\n","        # Update hidden and cell state to correspond to the selected hypothesis\n","        # YOUR CODE HERE\n","        ...\n","\n","\n","    return (\n","        hypothesis.view(-1, start_tokens.shape[1], beam_size),\n","        decoded_lens.view(start_tokens.shape[1], beam_size),\n","        log_probas.view(start_tokens.shape[1], beam_size)\n","    )"]},{"cell_type":"markdown","metadata":{"id":"ULTcWrqyOBPE"},"source":["Протестируем итоговую функцию `decode_beam_search`. Рассмотрим постановку, когда действовать жадно не выгодно для генерации."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0fQrEERzOBPE"},"outputs":[],"source":["transitions = {\n","    0: torch.tensor([-1e10, 1, -1e10, -1e10, 0.9]),\n","    1: torch.tensor([-1e10, 1, 1.1, 0.9, -1e10]),\n","    2: torch.tensor([-1e10, 0.9, 1, 1.1, -1e10]),\n","    3: torch.tensor([-1e10, 1.1, 0.9, 1, -1e10]),\n","    4: torch.tensor([-1e10, -1e10, -1e10, -1e10, 1]),\n","}\n","\n","fake_lm = FakeLM(FakeRNN(), transitions)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7W9oGe-pOBPE"},"outputs":[],"source":["for k, v in transitions.items():\n","    p = v.softmax(0).cpu().numpy()\n","    p = np.around(p, 3)\n","    print(f\"log p(next_token | {k}) = {p}\")"]},{"cell_type":"markdown","metadata":{"id":"zq5KZX4IOBPE"},"source":["Действуя жадно и начиная с токена $0$, мы перейдем в токен $1$, а дальше с вероятностью будем блуждать по цепочке $1 \\to 2 \\to 3 \\to 1$. Но при числе гипотез больше 2 мы рассмотрим возможность перехода в токен $4$, где зациклимся. В результате во втором случае у последовательности будет высокая итоговая вероятность, а у первого способа - низкая.\n","\n","Сначала проверим как работает `beam_size = 1`, так как этот случай проще отладить в случае ошибки.\n","\n","**Важно:** При `beam_size = 1` мы получаем жадное декодирование."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZPP2IN93OBPE"},"outputs":[],"source":["set_global_seed(42)\n","\n","decoded_tokens, decoded_lens, log_probas = decode_beam_search(\n","    model             = fake_lm,\n","    start_tokens      = torch.zeros((1, 3)),\n","    start_tokens_lens = torch.tensor([1, 1, 1]),\n","    eos_idx           = 10,\n","    max_generated_len = 8,\n","    beam_size         = 1\n",")\n","\n","p = transitions[1].log_softmax(0)[2] * 7 + transitions[0].log_softmax(0)[1]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HgC43Q2zOBPE"},"outputs":[],"source":["assert decoded_tokens.shape == (8, 3, 1)\n","assert decoded_lens.shape   == (3, 1)\n","assert log_probas.shape     == (3, 1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8CxCsgKSOBPE"},"outputs":[],"source":["decoded_tokens[:, :, 0]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"s-tJGtBLOBPF"},"outputs":[],"source":["assert torch.isclose(log_probas, p).all()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1fs2sWpjOBPF"},"outputs":[],"source":["set_global_seed(42)\n","\n","decoded_tokens, decoded_lens, log_probas = decode_beam_search(\n","    model             = fake_lm,\n","    start_tokens      = torch.zeros((1, 3)),\n","    start_tokens_lens = torch.tensor([1, 1, 1]),\n","    eos_idx           = 10,\n","    max_generated_len = 8,\n","    beam_size         = 2\n",")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XQNEXQGjOBPF"},"outputs":[],"source":["assert decoded_tokens.shape == (8, 3, 2)\n","assert decoded_lens.shape   == (3, 2)\n","assert log_probas.shape     == (3, 2)"]},{"cell_type":"markdown","metadata":{"id":"F81BYWvfOBPF"},"source":["Посмотрим на наиболее вероятную гипотезу для каждого батча:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"awmAxOXLOBPF"},"outputs":[],"source":["decoded_tokens[:, :, 0]"]},{"cell_type":"markdown","metadata":{"id":"lcdnFVNSOBPF"},"source":["Посмотрим на вторую гипотезу для каждого батча:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0EZbNKUtOBPF"},"outputs":[],"source":["decoded_tokens[:, :, 1]"]},{"cell_type":"markdown","metadata":{"id":"Af4f6JcIOBPF"},"source":["Подробнее, как это работает:\n","\n","1. На первом ходу мы берем 2 наиболее вероятных перехода: перейти в $1$, перейти в $4$.\n","\n","2. На следующих ходах мы рассматриваем для каждого \"луча\" 2 наиболее вероятных перехода (всего 4 случаев), из которых выбираем две наиболее вероятные гипотезы.\n","\n","- 1. Для случая, который перешел в $1$, мы рассматриваем 2 альтернативы: перейти в $2$ с вероятностью $0.367$, остаться в $1$ с вероятностью $0.332$)\n","- 2. Для случая, который перешел в $4$, мы рассматриваем 2 альтернативы: остаться в $4$ с вероятностью 1, или перейти в любое другое состояние с вероятностью $\\approx$ 0)\n","- 3. Из всех вариантов вероятней всего перейти из $1$ в $2$ и перейти из $4$ в $4$, то есть обновляем \"лучи\"\n","\n","3. Повторить пункт 2.\n","\n","**Важно:** Обратите внимание, что Beam Search детерминированный алгоритм"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jt9wzbr_OBPF"},"outputs":[],"source":["start_tokens = torch.tensor([\n","    lm_model.tokenizer.encode(['<sos>', '<pad>', '<pad>', '<pad>'], is_pretokenized=True).ids,\n","    lm_model.tokenizer.encode(['<sos>', 'my', 'favorite', 'movie'], is_pretokenized=True).ids,\n","    lm_model.tokenizer.encode(['<sos>', 'the', 'best', 'movie'],    is_pretokenized=True).ids,\n","    lm_model.tokenizer.encode(['<sos>', 'the', 'worst', 'movie'],   is_pretokenized=True).ids,\n","]).T\n","\n","start_tokens_lens = torch.tensor([1, 4, 4, 4])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"99INYIYQOBPF"},"outputs":[],"source":["lm_model.to(device).eval()\n","start_tokens = start_tokens.to(device)\n","start_tokens_lens = start_tokens_lens.to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"j6SOTAlTOBPF"},"outputs":[],"source":["beam_size = 100\n","decoded_tokens, decoded_lens, log_probas = decode_beam_search(\n","    lm_model, start_tokens, start_tokens_lens, max_generated_len=10, beam_size=beam_size\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KBXgE_U2OBPG","scrolled":false},"outputs":[],"source":["for start_tokens_elem, start_tokens_lens_elem, decoded_tokens_elem, decoded_lens_elem, log_probas_elem in zip(\n","    start_tokens.T, start_tokens_lens,\n","    decoded_tokens.permute(1, 2, 0), decoded_lens.permute(0, 1), log_probas.permute(0, 1)\n","):\n","    start_tokens_elem = start_tokens_elem[:start_tokens_lens_elem].tolist()\n","    start_words = lm_model.tokenizer.decode(start_tokens_elem, skip_special_tokens=False).split(' ')\n","\n","    start_text = ' '.join(start_words).replace('<', '&lt;').replace('>', '&gt;')\n","    display(Markdown(f'<div class=\"alert alert-block alert-info\"> <b>{start_text}</b></div>'))\n","\n","    for idx, (hyp, hyp_len, hyp_log_prob) in enumerate(zip(decoded_tokens_elem, decoded_lens_elem, log_probas_elem)):\n","        if idx >= 3:\n","            break\n","\n","        hyp = hyp[:hyp_len].tolist()\n","        hyp_words = lm_model.tokenizer.decode(hyp, skip_special_tokens=False).split(' ')\n","        hyp_text = ' '.join(hyp_words).replace('<', '&lt;').replace('>', '&gt;')\n","        display(Markdown(\n","            f'<div class=\"alert alert-block alert-success\"> <b>{hyp_log_prob:.3f}: {hyp_text}</b></div>'\n","        ))"]},{"cell_type":"markdown","metadata":{"id":"kUwsXD2WOBPG"},"source":["Попробуйте выполнить декодинг для разных `beam_size`. Убедитесь, что при `beam_search=1` семплирование совпадает с top-1 (greedy decoding) подходом.\n","\n","Сравните результаты Beam Search с top-k семплированием и жадным декодированием. Опишите ваши наблюдения."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LcHa93ACOBPG"},"outputs":[],"source":["# YOUR CODE HERE"]},{"cell_type":"markdown","metadata":{"id":"Ps6ieyR9OBPG"},"source":["## `Бонус. Существенное улучшение качества (до 6 баллов)`"]},{"cell_type":"markdown","metadata":{"id":"dDuhUs-5OBPG"},"source":["Та модель, которая использовалась в предыдущей части во многом заимствует улучшения LSTM из статьи [Regularizing and Optimizing LSTM Language Models](https://arxiv.org/pdf/1708.02182.pdf). Вы можете попробовать применить другие варианты регуляризации из данной статьи для существенного улучшения качества LM.\n","\n","Например:\n","1. Dropout для эмбеддингов **(+0.25)**\n","2. Dropout входов и выходов RNN **(+0.25)**\n","3. Регуляризация активаций (AR/TAR) **(+1.0)**\n","4. NT-ASGD **(+1.5)**\n","5. Tied веса эмбеддингов и софтмакса **(+1.0)**\n","6. Attention **(+2.0)**\n","\n","**Полные баллы ставятся только при наличии качественного и количественного сравнения с бейзлайном.**\n","\n","**Для эксперимента с Attention необходимо изобразить Attention Maps для нескольких примеров.**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MffqJL66OBPG"},"outputs":[],"source":[]}],"metadata":{"accelerator":"TPU","colab":{"gpuType":"V28","machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.16"},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":false,"sideBar":true,"skip_h1_title":false,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{"height":"804px","left":"148px","top":"50px","width":"555.391px"},"toc_section_display":true,"toc_window_display":false},"varInspector":{"cols":{"lenName":16,"lenType":16,"lenVar":40},"kernels_config":{"python":{"delete_cmd_postfix":"","delete_cmd_prefix":"del ","library":"var_list.py","varRefreshCmd":"print(var_dic_list())"},"r":{"delete_cmd_postfix":") ","delete_cmd_prefix":"rm(","library":"var_list.r","varRefreshCmd":"cat(var_dic_list()) "}},"position":{"height":"313px","left":"926px","right":"27px","top":"120px","width":"343px"},"types_to_exclude":["module","function","builtin_function_or_method","instance","_Feature"],"window_display":false}},"nbformat":4,"nbformat_minor":0}